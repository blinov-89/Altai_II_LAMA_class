{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blinov-89/Altay_II_LAMA_class/blob/main/Score_%3D_0_764449_AutoML_%D0%90%D0%BB%D1%82%D0%B0%D0%B9_notebook_Multi_class_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pip"
      ],
      "metadata": {
        "id": "CZ18NFIzRAoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id3KhpLgdDuc",
        "outputId": "1c8de575-26ca-43c5-8e27-becf337f3241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U lightautoml"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-12T09:42:46.326729Z",
          "iopub.execute_input": "2022-09-12T09:42:46.327281Z",
          "iopub.status.idle": "2022-09-12T09:44:45.884593Z",
          "shell.execute_reply.started": "2022-09-12T09:42:46.327242Z",
          "shell.execute_reply": "2022-09-12T09:44:45.882333Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "-tQZAFBIPSIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
        "from lightautoml.tasks import Task"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-12T09:44:45.887889Z",
          "iopub.execute_input": "2022-09-12T09:44:45.888449Z",
          "iopub.status.idle": "2022-09-12T09:44:48.891548Z",
          "shell.execute_reply.started": "2022-09-12T09:44:45.888394Z",
          "shell.execute_reply": "2022-09-12T09:44:48.890708Z"
        },
        "trusted": true,
        "id": "x9MffE3YPSIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#autoML"
      ],
      "metadata": {
        "id": "MZG143swPjgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/Алтай/train_dataset_train.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Алтай/test_dataset_test.csv')"
      ],
      "metadata": {
        "id": "mU4J5x7vQlSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.Статус.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rir2jsLRcpSL",
        "outputId": "1ad8ac2b-1f5a-4b1b-96d2-9be4895b53d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 4    8249\n",
              " 3    4721\n",
              "-1     614\n",
              "Name: Статус, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#train"
      ],
      "metadata": {
        "id": "bFjjllgJ_rx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(3)"
      ],
      "metadata": {
        "id": "Jicw8XVgRWjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_THREADS = 4\n",
        "N_FOLDS = 5\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.20\n",
        "TIMEOUT = 8 * 3600 # equal to 8 hours\n",
        "TARGET_NAME = 'Статус'"
      ],
      "metadata": {
        "id": "wRkYcYQysI58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "E5dYU0U1sb5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(RANDOM_STATE)\n",
        "torch.set_num_threads(N_THREADS)"
      ],
      "metadata": {
        "id": "VuIjltiosYI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for col in df_train.columns:\n",
        "#     if df_train[col].dtype=='float16':\n",
        "#         df_train[col] = df_train[col].astype('float32').round(decimals=2).astype('float16')\n",
        "# for col in df_test.columns:\n",
        "#     if df_test[col].dtype=='float16':\n",
        "#         df_test[col] = df_test[col].astype('float32').round(decimals=2).astype('float16')"
      ],
      "metadata": {
        "id": "HhfTSpeEsrqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = Task('multiclass', metric = 'crossentropy')"
      ],
      "metadata": {
        "id": "ra115r0DPNoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roles = {\n",
        "    'target': TARGET_NAME,\n",
        "    'drop': ['ID']\n",
        "}"
      ],
      "metadata": {
        "id": "GSPuXFgptUDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "automl = TabularAutoML(\n",
        "    task = task, \n",
        "    timeout = TIMEOUT,\n",
        "    cpu_limit = N_THREADS,\n",
        "    # general_params = {'use_algos': [['linear_l2', 'lgb', 'cb']]},\n",
        "    reader_params = {'n_jobs': 1, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
        "    selection_params = {'mode': 0}\n",
        ")"
      ],
      "metadata": {
        "id": "TbFoC5F_tUG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof_pred = automl.fit_predict(df_train, roles = roles, verbose = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4LvWR_zAEXP",
        "outputId": "0279fd5c-5b74-430e-da9c-8cf8d3a2778a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:51] Stdout logging level is INFO3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:51] Task: multiclass\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: multiclass\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:51] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:51] - time: 28800.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 28800.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:51] - CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:51] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:51] \u001b[1mTrain data shape: (13584, 24)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (13584, 24)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:52] Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:52] Layer \u001b[1m1\u001b[0m train process start. Time left 28799.01 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 28799.01 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:53] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [66, 67, 68, 69, 70], 'embed_sizes': array([36, 20, 42, 13,  8], dtype=int32), 'data_size': 71}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:53] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:53] Linear model: C = 1e-05 score = -0.6701168325463331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.6701168325463331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:53] Linear model: C = 5e-05 score = -0.5539604372080631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.5539604372080631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:54] Linear model: C = 0.0001 score = -0.510010317970927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.510010317970927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:54] Linear model: C = 0.0005 score = -0.4427872219413963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.4427872219413963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:55] Linear model: C = 0.001 score = -0.4248352010115583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.4248352010115583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:55] Linear model: C = 0.005 score = -0.3993322875014879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.3993322875014879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:56] Linear model: C = 0.01 score = -0.3940910638248658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.3940910638248658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:56] Linear model: C = 0.05 score = -0.3895856988329898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.3895856988329898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:57] Linear model: C = 0.1 score = -0.3897223184743228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.3897223184743228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:58] Linear model: C = 0.5 score = -0.39196958478735694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.39196958478735694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:58] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:59] Linear model: C = 1e-05 score = -0.670648205143742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.670648205143742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:59] Linear model: C = 5e-05 score = -0.5595512951521651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.5595512951521651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:33:59] Linear model: C = 0.0001 score = -0.5196237914352638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.5196237914352638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:00] Linear model: C = 0.0005 score = -0.46141802792212516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.46141802792212516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:00] Linear model: C = 0.001 score = -0.44570678224503296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.44570678224503296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:01] Linear model: C = 0.005 score = -0.42068014368289336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.42068014368289336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:01] Linear model: C = 0.01 score = -0.4145111954894553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.4145111954894553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:02] Linear model: C = 0.05 score = -0.4086516119569109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.4086516119569109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:03] Linear model: C = 0.1 score = -0.4086596691038067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.4086596691038067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:04] Linear model: C = 0.5 score = -0.4110893369911555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.4110893369911555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:04] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:05] Linear model: C = 1e-05 score = -0.6644435048015582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.6644435048015582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:05] Linear model: C = 5e-05 score = -0.5498568891058478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.5498568891058478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:05] Linear model: C = 0.0001 score = -0.5090231132605495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.5090231132605495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:06] Linear model: C = 0.0005 score = -0.4498904719249505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.4498904719249505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:06] Linear model: C = 0.001 score = -0.4340672638988994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.4340672638988994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:07] Linear model: C = 0.005 score = -0.40872647794643363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.40872647794643363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:07] Linear model: C = 0.01 score = -0.40283415149573415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.40283415149573415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:08] Linear model: C = 0.05 score = -0.39683223005492524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.39683223005492524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:09] Linear model: C = 0.1 score = -0.3964216112537146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.3964216112537146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:10] Linear model: C = 0.5 score = -0.3964726333108035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.3964726333108035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:10] Linear model: C = 1 score = -0.3964726333108035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.3964726333108035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:10] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:10] Linear model: C = 1e-05 score = -0.6671504683499174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.6671504683499174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:11] Linear model: C = 5e-05 score = -0.5497993843689599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.5497993843689599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:11] Linear model: C = 0.0001 score = -0.5054309786320347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.5054309786320347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:11] Linear model: C = 0.0005 score = -0.4373437210737173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.4373437210737173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:12] Linear model: C = 0.001 score = -0.4200104901475923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.4200104901475923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:12] Linear model: C = 0.005 score = -0.3954275612333991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.3954275612333991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:13] Linear model: C = 0.01 score = -0.3895317547329738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.3895317547329738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:14] Linear model: C = 0.05 score = -0.38418343249037173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.38418343249037173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:14] Linear model: C = 0.1 score = -0.3842421874499631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.3842421874499631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:15] Linear model: C = 0.5 score = -0.3857433858374078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.3857433858374078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:15] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:16] Linear model: C = 1e-05 score = -0.666497119698284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.666497119698284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:16] Linear model: C = 5e-05 score = -0.5535663470834362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.5535663470834362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:16] Linear model: C = 0.0001 score = -0.5124461074175919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.5124461074175919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:17] Linear model: C = 0.0005 score = -0.4506607954878983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.4506607954878983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:17] Linear model: C = 0.001 score = -0.4338339011365902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.4338339011365902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:18] Linear model: C = 0.005 score = -0.40714432724897437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.40714432724897437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:18] Linear model: C = 0.01 score = -0.4003593759547255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.4003593759547255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:19] Linear model: C = 0.05 score = -0.39248787207297575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.39248787207297575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:20] Linear model: C = 0.1 score = -0.3911782782101179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.3911782782101179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:21] Linear model: C = 0.5 score = -0.3903036328540033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.3903036328540033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:21] Linear model: C = 1 score = -0.3903036328540033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.3903036328540033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:21] Linear model: C = 5 score = -0.3903036328540033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = -0.3903036328540033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:21] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.3938294570156299\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.3938294570156299\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:21] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:21] Time left 28769.60 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 28769.60 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:22] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.02, 'num_leaves': 64, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.2, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:22] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:22] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.358293\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.301692\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.288468\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.285967\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.287068\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.290013\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[425]\tvalid's multi_logloss: 0.2859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:39] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:39] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.371926\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.322424\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.314422\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.315164\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.317942\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[355]\tvalid's multi_logloss: 0.314154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:57] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:34:57] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.370415\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.323422\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.317006\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.319086\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[298]\tvalid's multi_logloss: 0.31699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:35:11] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:35:11] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.355489\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.300883\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.290219\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.288759\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.290392\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[393]\tvalid's multi_logloss: 0.288339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:35:27] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:35:27] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.363136\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.306957\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.296105\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.295888\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.298888\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[345]\tvalid's multi_logloss: 0.29488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:35:42] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.30005278999716534\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.30005278999716534\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:35:42] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:35:42] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
            "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-0ea8f172-cf75-4ee3-910c-879c12cae8d3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:35:42] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.351202\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.29598\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.29344\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.305625\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[266]\tvalid's multi_logloss: 0.29131\n",
            "INFO:optuna.study.study:Trial 0 finished with value: -0.29131034479048384 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: -0.29131034479048384.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:14] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -0.29131034479048384 in 0:00:32.050165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -0.29131034479048384 in 0:00:32.050165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:14] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.383777\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.315798\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.296431\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.29042\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.28965\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.291068\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[453]\tvalid's multi_logloss: 0.289324\n",
            "INFO:optuna.study.study:Trial 1 finished with value: -0.2893242040650942 and parameters: {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285}. Best is trial 1 with value: -0.2893242040650942.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:34] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -0.2893242040650942 in 0:00:20.728906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -0.2893242040650942 in 0:00:20.728906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:35] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.347898\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.299689\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.291262\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.291194\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.294978\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[337]\tvalid's multi_logloss: 0.290134\n",
            "INFO:optuna.study.study:Trial 2 finished with value: -0.2901342415735352 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323}. Best is trial 1 with value: -0.2893242040650942.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -0.2901342415735352 in 0:00:17.617315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -0.2901342415735352 in 0:00:17.617315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.353404\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.298289\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.289667\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.290963\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.296536\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[303]\tvalid's multi_logloss: 0.28958\n",
            "INFO:optuna.study.study:Trial 3 finished with value: -0.2895802765893402 and parameters: {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 1 with value: -0.2893242040650942.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:10] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -0.2895802765893402 in 0:00:17.619826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -0.2895802765893402 in 0:00:17.619826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:10] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.350796\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.297792\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.292297\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.300112\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[275]\tvalid's multi_logloss: 0.29181\n",
            "INFO:optuna.study.study:Trial 4 finished with value: -0.29180976343545123 and parameters: {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08}. Best is trial 1 with value: -0.2893242040650942.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:31] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -0.29180976343545123 in 0:00:21.459046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -0.29180976343545123 in 0:00:21.459046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:31] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.380464\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.322766\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.308496\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.30387\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.300807\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.299641\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.298195\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.298139\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.297881\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's multi_logloss: 0.297915\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's multi_logloss: 0.297573\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's multi_logloss: 0.297913\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1056]\tvalid's multi_logloss: 0.297414\n",
            "INFO:optuna.study.study:Trial 5 finished with value: -0.2974135379838618 and parameters: {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936}. Best is trial 1 with value: -0.2893242040650942.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:48] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -0.2974135379838618 in 0:00:16.839117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -0.2974135379838618 in 0:00:16.839117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:48] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.367127\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.30595\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.291997\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.28821\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.287197\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.287276\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.289147\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[511]\tvalid's multi_logloss: 0.286766\n",
            "INFO:optuna.study.study:Trial 6 finished with value: -0.28676570043303545 and parameters: {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574}. Best is trial 6 with value: -0.28676570043303545.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:38:03] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -0.28676570043303545 in 0:00:14.640389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -0.28676570043303545 in 0:00:14.640389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:38:03] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.37302\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.307238\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.294114\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.298134\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.306943\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[330]\tvalid's multi_logloss: 0.293447\n",
            "INFO:optuna.study.study:Trial 7 finished with value: -0.2934474895588634 and parameters: {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 6 with value: -0.28676570043303545.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:38:24] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -0.2934474895588634 in 0:00:21.379825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -0.2934474895588634 in 0:00:21.379825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:38:24] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.361179\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.306644\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.295395\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.290109\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.28853\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.288466\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.288717\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[545]\tvalid's multi_logloss: 0.288346\n",
            "INFO:optuna.study.study:Trial 8 finished with value: -0.2883462194432352 and parameters: {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483}. Best is trial 6 with value: -0.28676570043303545.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:38:43] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -0.2883462194432352 in 0:00:18.484046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -0.2883462194432352 in 0:00:18.484046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:38:43] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.348945\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.298586\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.29268\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.29925\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[286]\tvalid's multi_logloss: 0.292592\n",
            "INFO:optuna.study.study:Trial 9 finished with value: -0.2925916055060908 and parameters: {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06}. Best is trial 6 with value: -0.28676570043303545.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:39:11] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -0.2925916055060908 in 0:00:28.488573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -0.2925916055060908 in 0:00:28.488573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:39:11] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.383927\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.321087\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.303906\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.296994\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.293525\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.290875\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.289861\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.288303\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.287416\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's multi_logloss: 0.287197\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's multi_logloss: 0.286858\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's multi_logloss: 0.286874\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's multi_logloss: 0.287283\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1138]\tvalid's multi_logloss: 0.286597\n",
            "INFO:optuna.study.study:Trial 10 finished with value: -0.28659653345877556 and parameters: {'feature_fraction': 0.6229610028762618, 'num_leaves': 17, 'bagging_fraction': 0.9515481201295128, 'min_sum_hessian_in_leaf': 0.024400771927662247, 'reg_alpha': 0.0025077894820478342, 'reg_lambda': 0.016301353379407572}. Best is trial 10 with value: -0.28659653345877556.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:39:28] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.6229610028762618, 'num_leaves': 17, 'bagging_fraction': 0.9515481201295128, 'min_sum_hessian_in_leaf': 0.024400771927662247, 'reg_alpha': 0.0025077894820478342, 'reg_lambda': 0.016301353379407572} scored -0.28659653345877556 in 0:00:16.620182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.6229610028762618, 'num_leaves': 17, 'bagging_fraction': 0.9515481201295128, 'min_sum_hessian_in_leaf': 0.024400771927662247, 'reg_alpha': 0.0025077894820478342, 'reg_lambda': 0.016301353379407572} scored -0.28659653345877556 in 0:00:16.620182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:39:28] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.38361\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.319788\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.302622\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.295589\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.292191\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.289777\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.288568\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.287821\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.287171\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's multi_logloss: 0.286936\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's multi_logloss: 0.286906\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's multi_logloss: 0.287185\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1035]\tvalid's multi_logloss: 0.286734\n",
            "INFO:optuna.study.study:Trial 11 finished with value: -0.2867339165171901 and parameters: {'feature_fraction': 0.6104881284818561, 'num_leaves': 18, 'bagging_fraction': 0.9559213589718202, 'min_sum_hessian_in_leaf': 0.03299263281612611, 'reg_alpha': 0.005849052891051126, 'reg_lambda': 0.018810618912109483}. Best is trial 10 with value: -0.28659653345877556.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:39:43] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.6104881284818561, 'num_leaves': 18, 'bagging_fraction': 0.9559213589718202, 'min_sum_hessian_in_leaf': 0.03299263281612611, 'reg_alpha': 0.005849052891051126, 'reg_lambda': 0.018810618912109483} scored -0.2867339165171901 in 0:00:15.618857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.6104881284818561, 'num_leaves': 18, 'bagging_fraction': 0.9559213589718202, 'min_sum_hessian_in_leaf': 0.03299263281612611, 'reg_alpha': 0.005849052891051126, 'reg_lambda': 0.018810618912109483} scored -0.2867339165171901 in 0:00:15.618857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:39:43] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.360728\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.300536\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.289258\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.293588\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.303414\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[315]\tvalid's multi_logloss: 0.289115\n",
            "INFO:optuna.study.study:Trial 12 finished with value: -0.28911473740375215 and parameters: {'feature_fraction': 0.5962024646862834, 'num_leaves': 120, 'bagging_fraction': 0.9969644644458301, 'min_sum_hessian_in_leaf': 0.01875620628228738, 'reg_alpha': 0.008072013455146746, 'reg_lambda': 0.019364859164517505}. Best is trial 10 with value: -0.28659653345877556.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:40:04] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.5962024646862834, 'num_leaves': 120, 'bagging_fraction': 0.9969644644458301, 'min_sum_hessian_in_leaf': 0.01875620628228738, 'reg_alpha': 0.008072013455146746, 'reg_lambda': 0.019364859164517505} scored -0.28911473740375215 in 0:00:20.972489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.5962024646862834, 'num_leaves': 120, 'bagging_fraction': 0.9969644644458301, 'min_sum_hessian_in_leaf': 0.01875620628228738, 'reg_alpha': 0.008072013455146746, 'reg_lambda': 0.019364859164517505} scored -0.28911473740375215 in 0:00:20.972489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:40:04] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.385318\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.32175\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.304403\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.297857\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.293393\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.290986\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.289467\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.288034\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.287528\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's multi_logloss: 0.287411\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's multi_logloss: 0.287229\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's multi_logloss: 0.287165\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's multi_logloss: 0.287539\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1128]\tvalid's multi_logloss: 0.286983\n",
            "INFO:optuna.study.study:Trial 13 finished with value: -0.2869831426625616 and parameters: {'feature_fraction': 0.6072934458713503, 'num_leaves': 17, 'bagging_fraction': 0.9165899714644768, 'min_sum_hessian_in_leaf': 0.0012748888933395578, 'reg_alpha': 0.08810028012678817, 'reg_lambda': 0.017638528224983827}. Best is trial 10 with value: -0.28659653345877556.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:40:21] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.6072934458713503, 'num_leaves': 17, 'bagging_fraction': 0.9165899714644768, 'min_sum_hessian_in_leaf': 0.0012748888933395578, 'reg_alpha': 0.08810028012678817, 'reg_lambda': 0.017638528224983827} scored -0.2869831426625616 in 0:00:16.475238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.6072934458713503, 'num_leaves': 17, 'bagging_fraction': 0.9165899714644768, 'min_sum_hessian_in_leaf': 0.0012748888933395578, 'reg_alpha': 0.08810028012678817, 'reg_lambda': 0.017638528224983827} scored -0.2869831426625616 in 0:00:16.475238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:40:21] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.361613\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.301318\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.291753\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.296301\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.307476\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[303]\tvalid's multi_logloss: 0.291652\n",
            "INFO:optuna.study.study:Trial 14 finished with value: -0.2916522207826734 and parameters: {'feature_fraction': 0.5963157283532504, 'num_leaves': 149, 'bagging_fraction': 0.7117688691366333, 'min_sum_hessian_in_leaf': 0.023506997063237167, 'reg_alpha': 0.0002005388893206717, 'reg_lambda': 0.010120698664942694}. Best is trial 10 with value: -0.28659653345877556.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:40:41] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.5963157283532504, 'num_leaves': 149, 'bagging_fraction': 0.7117688691366333, 'min_sum_hessian_in_leaf': 0.023506997063237167, 'reg_alpha': 0.0002005388893206717, 'reg_lambda': 0.010120698664942694} scored -0.2916522207826734 in 0:00:20.216515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.5963157283532504, 'num_leaves': 149, 'bagging_fraction': 0.7117688691366333, 'min_sum_hessian_in_leaf': 0.023506997063237167, 'reg_alpha': 0.0002005388893206717, 'reg_lambda': 0.010120698664942694} scored -0.2916522207826734 in 0:00:20.216515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:40:41] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.367688\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.316203\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.30207\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.296001\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.292959\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.291032\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.289449\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.289269\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.289163\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[745]\tvalid's multi_logloss: 0.289121\n",
            "INFO:optuna.study.study:Trial 15 finished with value: -0.28912085098934104 and parameters: {'feature_fraction': 0.9996812193207758, 'num_leaves': 17, 'bagging_fraction': 0.9220041256117634, 'min_sum_hessian_in_leaf': 0.029882656996049188, 'reg_alpha': 0.08057531040551845, 'reg_lambda': 0.2573972470665263}. Best is trial 10 with value: -0.28659653345877556.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:40:58] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.9996812193207758, 'num_leaves': 17, 'bagging_fraction': 0.9220041256117634, 'min_sum_hessian_in_leaf': 0.029882656996049188, 'reg_alpha': 0.08057531040551845, 'reg_lambda': 0.2573972470665263} scored -0.28912085098934104 in 0:00:16.488684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.9996812193207758, 'num_leaves': 17, 'bagging_fraction': 0.9220041256117634, 'min_sum_hessian_in_leaf': 0.029882656996049188, 'reg_alpha': 0.08057531040551845, 'reg_lambda': 0.2573972470665263} scored -0.28912085098934104 in 0:00:16.488684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:40:58] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:40:58] The set of hyperparameters \u001b[1m{'feature_fraction': 0.6229610028762618, 'num_leaves': 17, 'bagging_fraction': 0.9515481201295128, 'min_sum_hessian_in_leaf': 0.024400771927662247, 'reg_alpha': 0.0025077894820478342, 'reg_lambda': 0.016301353379407572}\u001b[0m\n",
            " achieve -0.2866 crossentropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.6229610028762618, 'num_leaves': 17, 'bagging_fraction': 0.9515481201295128, 'min_sum_hessian_in_leaf': 0.024400771927662247, 'reg_alpha': 0.0025077894820478342, 'reg_lambda': 0.016301353379407572}\u001b[0m\n",
            " achieve -0.2866 crossentropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:40:58] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 17, 'feature_fraction': 0.6229610028762618, 'bagging_fraction': 0.9515481201295128, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.0025077894820478342, 'reg_lambda': 0.016301353379407572, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'min_sum_hessian_in_leaf': 0.024400771927662247}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:40:58] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:40:58] Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.311532\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.293526\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.290347\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.289326\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[399]\tvalid's multi_logloss: 0.289316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:04] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:04] Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.332887\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.317532\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.31365\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.313875\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[355]\tvalid's multi_logloss: 0.312936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:10] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:10] Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.330587\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.327362\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[137]\tvalid's multi_logloss: 0.324313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:13] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:13] Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.306809\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.291718\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.287723\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.286396\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.286402\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[429]\tvalid's multi_logloss: 0.285944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:20] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:20] Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.31405\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.297648\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.295819\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.295682\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[361]\tvalid's multi_logloss: 0.295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-0.30150240417151186\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-0.30150240417151186\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:26] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:26] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:26] 0:\tlearn: 1.0669739\ttest: 1.0668370\tbest: 1.0668370 (0)\ttotal: 8.8ms\tremaining: 26.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0669739\ttest: 1.0668370\tbest: 1.0668370 (0)\ttotal: 8.8ms\tremaining: 26.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3924528\ttest: 0.3885274\tbest: 0.3885274 (100)\ttotal: 934ms\tremaining: 26.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3352409\ttest: 0.3399295\tbest: 0.3399295 (200)\ttotal: 1.8s\tremaining: 25.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3110822\ttest: 0.3272925\tbest: 0.3272925 (300)\ttotal: 2.65s\tremaining: 23.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2875080\ttest: 0.3154789\tbest: 0.3154566 (399)\ttotal: 3.48s\tremaining: 22.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2695651\ttest: 0.3089657\tbest: 0.3089657 (500)\ttotal: 4.32s\tremaining: 21.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2554181\ttest: 0.3047791\tbest: 0.3047716 (599)\ttotal: 5.2s\tremaining: 20.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2432115\ttest: 0.3017048\tbest: 0.3017048 (700)\ttotal: 6.05s\tremaining: 19.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2314304\ttest: 0.2986636\tbest: 0.2986636 (800)\ttotal: 6.94s\tremaining: 19.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2216933\ttest: 0.2976502\tbest: 0.2976436 (896)\ttotal: 7.81s\tremaining: 18.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2119599\ttest: 0.2958814\tbest: 0.2958814 (1000)\ttotal: 10s\tremaining: 20s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2028369\ttest: 0.2949915\tbest: 0.2949915 (1100)\ttotal: 12s\tremaining: 20.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1945454\ttest: 0.2945305\tbest: 0.2944064 (1189)\ttotal: 12.8s\tremaining: 19.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1865855\ttest: 0.2936719\tbest: 0.2936719 (1300)\ttotal: 13.6s\tremaining: 17.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1788467\ttest: 0.2932132\tbest: 0.2929732 (1382)\ttotal: 14.5s\tremaining: 16.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1718189\ttest: 0.2924037\tbest: 0.2924037 (1500)\ttotal: 15.4s\tremaining: 15.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.1650948\ttest: 0.2919746\tbest: 0.2919746 (1600)\ttotal: 16.2s\tremaining: 14.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.1588247\ttest: 0.2921221\tbest: 0.2917694 (1658)\ttotal: 17.1s\tremaining: 13.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.1527888\ttest: 0.2916232\tbest: 0.2914139 (1779)\ttotal: 17.9s\tremaining: 11.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:44] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:44] bestTest = 0.291413895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.291413895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:44] bestIteration = 1779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:44] Shrink model to first 1780 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1780 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:45] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:45] 0:\tlearn: 1.0668685\ttest: 1.0664215\tbest: 1.0664215 (0)\ttotal: 8.27ms\tremaining: 24.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0668685\ttest: 1.0664215\tbest: 1.0664215 (0)\ttotal: 8.27ms\tremaining: 24.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3852490\ttest: 0.4064661\tbest: 0.4064661 (100)\ttotal: 904ms\tremaining: 25.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3273094\ttest: 0.3624388\tbest: 0.3624388 (200)\ttotal: 1.77s\tremaining: 24.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3035620\ttest: 0.3487510\tbest: 0.3487510 (300)\ttotal: 2.62s\tremaining: 23.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2804926\ttest: 0.3352031\tbest: 0.3352031 (400)\ttotal: 3.49s\tremaining: 22.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2632078\ttest: 0.3276857\tbest: 0.3276857 (500)\ttotal: 4.36s\tremaining: 21.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2482008\ttest: 0.3233500\tbest: 0.3233500 (600)\ttotal: 5.21s\tremaining: 20.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2359508\ttest: 0.3195128\tbest: 0.3195128 (700)\ttotal: 6.06s\tremaining: 19.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2250342\ttest: 0.3172866\tbest: 0.3172866 (800)\ttotal: 6.89s\tremaining: 18.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2148430\ttest: 0.3156370\tbest: 0.3156245 (899)\ttotal: 7.7s\tremaining: 17.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2054061\ttest: 0.3140199\tbest: 0.3140199 (1000)\ttotal: 8.54s\tremaining: 17s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1965631\ttest: 0.3130680\tbest: 0.3130680 (1100)\ttotal: 9.38s\tremaining: 16.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1880476\ttest: 0.3121848\tbest: 0.3120878 (1193)\ttotal: 10.3s\tremaining: 15.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1799278\ttest: 0.3113032\tbest: 0.3112414 (1283)\ttotal: 11.1s\tremaining: 14.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1727481\ttest: 0.3110806\tbest: 0.3108957 (1369)\ttotal: 11.9s\tremaining: 13.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1659113\ttest: 0.3109986\tbest: 0.3108935 (1444)\ttotal: 12.8s\tremaining: 12.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.1593658\ttest: 0.3111715\tbest: 0.3107794 (1529)\ttotal: 13.7s\tremaining: 11.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:59] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:59] bestTest = 0.310779376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.310779376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:59] bestIteration = 1529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:59] Shrink model to first 1530 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1530 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:59] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:41:59] 0:\tlearn: 1.0655484\ttest: 1.0664369\tbest: 1.0664369 (0)\ttotal: 8.63ms\tremaining: 25.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0655484\ttest: 1.0664369\tbest: 1.0664369 (0)\ttotal: 8.63ms\tremaining: 25.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3871539\ttest: 0.4061889\tbest: 0.4061889 (100)\ttotal: 915ms\tremaining: 26.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3303035\ttest: 0.3609208\tbest: 0.3609067 (199)\ttotal: 1.78s\tremaining: 24.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3059795\ttest: 0.3477048\tbest: 0.3477048 (300)\ttotal: 2.64s\tremaining: 23.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2819446\ttest: 0.3377427\tbest: 0.3377427 (400)\ttotal: 3.48s\tremaining: 22.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2641761\ttest: 0.3343228\tbest: 0.3342732 (498)\ttotal: 4.33s\tremaining: 21.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2502555\ttest: 0.3337044\tbest: 0.3332291 (594)\ttotal: 5.15s\tremaining: 20.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2376916\ttest: 0.3331211\tbest: 0.3326819 (659)\ttotal: 5.97s\tremaining: 19.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2260888\ttest: 0.3320210\tbest: 0.3320058 (799)\ttotal: 6.8s\tremaining: 18.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2156633\ttest: 0.3322193\tbest: 0.3315445 (851)\ttotal: 7.62s\tremaining: 17.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:07] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:07] bestTest = 0.3315444884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.3315444884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:07] bestIteration = 851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:07] Shrink model to first 852 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 852 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:07] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:07] 0:\tlearn: 1.0671232\ttest: 1.0663920\tbest: 1.0663920 (0)\ttotal: 8.64ms\tremaining: 25.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0671232\ttest: 1.0663920\tbest: 1.0663920 (0)\ttotal: 8.64ms\tremaining: 25.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3948003\ttest: 0.3832817\tbest: 0.3832817 (100)\ttotal: 890ms\tremaining: 25.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3381769\ttest: 0.3342867\tbest: 0.3342867 (200)\ttotal: 1.75s\tremaining: 24.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3118178\ttest: 0.3184876\tbest: 0.3184876 (300)\ttotal: 2.59s\tremaining: 23.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2884129\ttest: 0.3072681\tbest: 0.3072681 (400)\ttotal: 3.45s\tremaining: 22.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2709439\ttest: 0.3014738\tbest: 0.3014629 (499)\ttotal: 4.29s\tremaining: 21.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2563998\ttest: 0.2987194\tbest: 0.2986150 (596)\ttotal: 5.08s\tremaining: 20.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2428713\ttest: 0.2966870\tbest: 0.2966870 (700)\ttotal: 5.9s\tremaining: 19.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2312266\ttest: 0.2951486\tbest: 0.2950509 (782)\ttotal: 6.72s\tremaining: 18.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2204345\ttest: 0.2941022\tbest: 0.2941022 (900)\ttotal: 7.55s\tremaining: 17.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2102917\ttest: 0.2933501\tbest: 0.2933496 (998)\ttotal: 8.38s\tremaining: 16.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2011813\ttest: 0.2923593\tbest: 0.2923070 (1088)\ttotal: 9.22s\tremaining: 15.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1927384\ttest: 0.2918165\tbest: 0.2917681 (1199)\ttotal: 10.1s\tremaining: 15.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1853027\ttest: 0.2912181\tbest: 0.2911991 (1298)\ttotal: 10.9s\tremaining: 14.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1778439\ttest: 0.2908442\tbest: 0.2907740 (1357)\ttotal: 11.7s\tremaining: 13.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1712232\ttest: 0.2905129\tbest: 0.2904683 (1449)\ttotal: 12.6s\tremaining: 12.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.1645742\ttest: 0.2900651\tbest: 0.2900533 (1599)\ttotal: 13.4s\tremaining: 11.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.1585546\ttest: 0.2899156\tbest: 0.2898400 (1694)\ttotal: 14.2s\tremaining: 10.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.1525079\ttest: 0.2896314\tbest: 0.2896205 (1796)\ttotal: 15.1s\tremaining: 10s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.1468669\ttest: 0.2894845\tbest: 0.2890547 (1819)\ttotal: 15.9s\tremaining: 9.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:23] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:23] bestTest = 0.2890546583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2890546583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:23] bestIteration = 1819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:23] Shrink model to first 1820 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1820 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:23] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:23] 0:\tlearn: 1.0668632\ttest: 1.0672046\tbest: 1.0672046 (0)\ttotal: 8.87ms\tremaining: 26.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0668632\ttest: 1.0672046\tbest: 1.0672046 (0)\ttotal: 8.87ms\tremaining: 26.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3882455\ttest: 0.4005609\tbest: 0.4005609 (100)\ttotal: 881ms\tremaining: 25.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3337117\ttest: 0.3517802\tbest: 0.3517802 (200)\ttotal: 1.75s\tremaining: 24.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3104756\ttest: 0.3368476\tbest: 0.3368476 (300)\ttotal: 2.58s\tremaining: 23.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2868204\ttest: 0.3232554\tbest: 0.3232554 (400)\ttotal: 3.41s\tremaining: 22.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2677445\ttest: 0.3146194\tbest: 0.3145450 (495)\ttotal: 4.25s\tremaining: 21.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2536239\ttest: 0.3109221\tbest: 0.3109041 (597)\ttotal: 5.05s\tremaining: 20.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2412460\ttest: 0.3085829\tbest: 0.3085145 (699)\ttotal: 5.84s\tremaining: 19.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2295721\ttest: 0.3054802\tbest: 0.3054787 (797)\ttotal: 6.66s\tremaining: 18.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2186608\ttest: 0.3035882\tbest: 0.3035882 (900)\ttotal: 7.5s\tremaining: 17.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2092038\ttest: 0.3031371\tbest: 0.3030661 (989)\ttotal: 8.31s\tremaining: 16.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1999787\ttest: 0.3028783\tbest: 0.3028333 (1080)\ttotal: 9.16s\tremaining: 15.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1915520\ttest: 0.3021334\tbest: 0.3020982 (1199)\ttotal: 9.96s\tremaining: 14.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1838107\ttest: 0.3016238\tbest: 0.3015294 (1288)\ttotal: 10.8s\tremaining: 14.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1768174\ttest: 0.3012307\tbest: 0.3012307 (1400)\ttotal: 11.6s\tremaining: 13.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1697342\ttest: 0.3012101\tbest: 0.3008577 (1423)\ttotal: 12.5s\tremaining: 12.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:36] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:36] bestTest = 0.3008576592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.3008576592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:36] bestIteration = 1423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:36] Shrink model to first 1424 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1424 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.3047302934938532\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.3047302934938532\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:36] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:36] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
            "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-66caa66d-5ccc-447f-a1e3-7a94da44cab0\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:36] 0:\tlearn: 1.0669940\ttest: 1.0668895\tbest: 1.0668895 (0)\ttotal: 7.08ms\tremaining: 21.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0669940\ttest: 1.0668895\tbest: 1.0668895 (0)\ttotal: 7.08ms\tremaining: 21.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4103669\ttest: 0.4039928\tbest: 0.4039928 (100)\ttotal: 742ms\tremaining: 21.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3539377\ttest: 0.3522967\tbest: 0.3522967 (200)\ttotal: 1.46s\tremaining: 20.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3303166\ttest: 0.3363098\tbest: 0.3363098 (300)\ttotal: 2.16s\tremaining: 19.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3106312\ttest: 0.3246132\tbest: 0.3246132 (400)\ttotal: 2.83s\tremaining: 18.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2958442\ttest: 0.3164892\tbest: 0.3164892 (500)\ttotal: 3.5s\tremaining: 17.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2846952\ttest: 0.3122933\tbest: 0.3122933 (600)\ttotal: 4.18s\tremaining: 16.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2744657\ttest: 0.3074905\tbest: 0.3074787 (698)\ttotal: 4.85s\tremaining: 15.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2654855\ttest: 0.3040515\tbest: 0.3040515 (800)\ttotal: 5.53s\tremaining: 15.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2575148\ttest: 0.3016684\tbest: 0.3016684 (900)\ttotal: 6.2s\tremaining: 14.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2496585\ttest: 0.2998242\tbest: 0.2998122 (999)\ttotal: 6.87s\tremaining: 13.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2430920\ttest: 0.2987164\tbest: 0.2985225 (1096)\ttotal: 7.54s\tremaining: 13s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2366318\ttest: 0.2980009\tbest: 0.2979736 (1198)\ttotal: 8.2s\tremaining: 12.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2302868\ttest: 0.2970190\tbest: 0.2970190 (1300)\ttotal: 8.87s\tremaining: 11.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2241547\ttest: 0.2966409\tbest: 0.2965395 (1395)\ttotal: 9.55s\tremaining: 10.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2182471\ttest: 0.2956841\tbest: 0.2956581 (1499)\ttotal: 10.2s\tremaining: 10.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2126793\ttest: 0.2954973\tbest: 0.2953305 (1591)\ttotal: 10.9s\tremaining: 9.53s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2075674\ttest: 0.2949501\tbest: 0.2949178 (1696)\ttotal: 11.6s\tremaining: 8.88s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.2027359\ttest: 0.2944936\tbest: 0.2944367 (1794)\ttotal: 12.3s\tremaining: 8.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.1980574\ttest: 0.2938406\tbest: 0.2938220 (1899)\ttotal: 13s\tremaining: 7.52s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.1935729\ttest: 0.2930071\tbest: 0.2929538 (1999)\ttotal: 13.7s\tremaining: 6.83s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.1890173\ttest: 0.2926482\tbest: 0.2925212 (2058)\ttotal: 14.4s\tremaining: 6.16s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:51] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:51] bestTest = 0.2925212267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2925212267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:51] bestIteration = 2058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:51] Shrink model to first 2059 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2059 iterations.\n",
            "INFO:optuna.study.study:Trial 0 finished with value: -0.29252121823127597 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: -0.29252121823127597.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:51] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -0.29252121823127597 in 0:00:15.168293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -0.29252121823127597 in 0:00:15.168293\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:42:52] 0:\tlearn: 1.0670395\ttest: 1.0667675\tbest: 1.0667675 (0)\ttotal: 6.2ms\tremaining: 18.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0670395\ttest: 1.0667675\tbest: 1.0667675 (0)\ttotal: 6.2ms\tremaining: 18.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4311745\ttest: 0.4217234\tbest: 0.4217234 (100)\ttotal: 652ms\tremaining: 18.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3752008\ttest: 0.3698200\tbest: 0.3698200 (200)\ttotal: 1.26s\tremaining: 17.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3513661\ttest: 0.3500920\tbest: 0.3500920 (300)\ttotal: 1.84s\tremaining: 16.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3333347\ttest: 0.3370032\tbest: 0.3370032 (400)\ttotal: 2.43s\tremaining: 15.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.3206291\ttest: 0.3297056\tbest: 0.3296971 (498)\ttotal: 3.02s\tremaining: 15.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.3111645\ttest: 0.3241048\tbest: 0.3241014 (599)\ttotal: 3.59s\tremaining: 14.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.3028230\ttest: 0.3196586\tbest: 0.3196586 (700)\ttotal: 4.18s\tremaining: 13.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2965737\ttest: 0.3171362\tbest: 0.3171362 (800)\ttotal: 4.74s\tremaining: 13s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2903677\ttest: 0.3139859\tbest: 0.3139314 (896)\ttotal: 5.3s\tremaining: 12.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2846940\ttest: 0.3122010\tbest: 0.3121919 (996)\ttotal: 5.88s\tremaining: 11.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2799205\ttest: 0.3105163\tbest: 0.3104776 (1097)\ttotal: 6.44s\tremaining: 11.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2750683\ttest: 0.3086284\tbest: 0.3085905 (1199)\ttotal: 7s\tremaining: 10.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2704575\ttest: 0.3070139\tbest: 0.3070139 (1300)\ttotal: 7.58s\tremaining: 9.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2662501\ttest: 0.3058666\tbest: 0.3058469 (1397)\ttotal: 8.14s\tremaining: 9.29s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2617480\ttest: 0.3039324\tbest: 0.3039324 (1500)\ttotal: 8.73s\tremaining: 8.72s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2576090\ttest: 0.3030384\tbest: 0.3030235 (1597)\ttotal: 9.3s\tremaining: 8.13s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2538319\ttest: 0.3018351\tbest: 0.3018351 (1700)\ttotal: 9.86s\tremaining: 7.53s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.2502007\ttest: 0.3011344\tbest: 0.3011344 (1800)\ttotal: 10.4s\tremaining: 6.95s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.2468044\ttest: 0.3004206\tbest: 0.3004147 (1898)\ttotal: 11s\tremaining: 6.36s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.2433125\ttest: 0.2996509\tbest: 0.2995924 (1990)\ttotal: 11.6s\tremaining: 5.78s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.2399892\ttest: 0.2988144\tbest: 0.2988015 (2087)\ttotal: 12.1s\tremaining: 5.19s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.2368738\ttest: 0.2986924\tbest: 0.2986717 (2187)\ttotal: 12.7s\tremaining: 4.62s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.2338222\ttest: 0.2981413\tbest: 0.2981301 (2261)\ttotal: 13.3s\tremaining: 4.04s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\tlearn: 0.2307292\ttest: 0.2978107\tbest: 0.2977989 (2348)\ttotal: 13.9s\tremaining: 3.46s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\tlearn: 0.2275657\ttest: 0.2970323\tbest: 0.2970098 (2499)\ttotal: 14.5s\tremaining: 2.89s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\tlearn: 0.2246668\ttest: 0.2967690\tbest: 0.2967532 (2597)\ttotal: 15s\tremaining: 2.31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\tlearn: 0.2219226\ttest: 0.2965458\tbest: 0.2965300 (2691)\ttotal: 15.6s\tremaining: 1.73s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\tlearn: 0.2192081\ttest: 0.2966018\tbest: 0.2963009 (2779)\ttotal: 16.2s\tremaining: 1.15s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2900:\tlearn: 0.2165349\ttest: 0.2964436\tbest: 0.2962883 (2877)\ttotal: 16.8s\tremaining: 573ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:09] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:09] bestTest = 0.2962883373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2962883373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:09] bestIteration = 2877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:09] Shrink model to first 2878 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2878 iterations.\n",
            "INFO:optuna.study.study:Trial 1 finished with value: -0.29628832893252677 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 0 with value: -0.29252121823127597.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:09] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -0.29628832893252677 in 0:00:17.639641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -0.29628832893252677 in 0:00:17.639641\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:09] 0:\tlearn: 1.0670393\ttest: 1.0667673\tbest: 1.0667673 (0)\ttotal: 6.12ms\tremaining: 18.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0670393\ttest: 1.0667673\tbest: 1.0667673 (0)\ttotal: 6.12ms\tremaining: 18.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4312218\ttest: 0.4217663\tbest: 0.4217663 (100)\ttotal: 625ms\tremaining: 17.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3752382\ttest: 0.3698601\tbest: 0.3698601 (200)\ttotal: 1.25s\tremaining: 17.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3513071\ttest: 0.3502422\tbest: 0.3502422 (300)\ttotal: 1.85s\tremaining: 16.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3333231\ttest: 0.3379593\tbest: 0.3379593 (400)\ttotal: 2.44s\tremaining: 15.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.3201664\ttest: 0.3300227\tbest: 0.3300100 (498)\ttotal: 3.02s\tremaining: 15s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.3102358\ttest: 0.3241820\tbest: 0.3241820 (600)\ttotal: 3.57s\tremaining: 14.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.3017149\ttest: 0.3193437\tbest: 0.3193437 (700)\ttotal: 4.14s\tremaining: 13.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2953893\ttest: 0.3171821\tbest: 0.3171821 (800)\ttotal: 4.69s\tremaining: 12.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2894068\ttest: 0.3143562\tbest: 0.3143562 (900)\ttotal: 5.27s\tremaining: 12.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2837446\ttest: 0.3123832\tbest: 0.3123765 (999)\ttotal: 5.86s\tremaining: 11.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2791446\ttest: 0.3109202\tbest: 0.3109085 (1099)\ttotal: 6.42s\tremaining: 11.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2744141\ttest: 0.3091923\tbest: 0.3091541 (1199)\ttotal: 7s\tremaining: 10.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2696039\ttest: 0.3074272\tbest: 0.3074058 (1296)\ttotal: 7.58s\tremaining: 9.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2652811\ttest: 0.3061560\tbest: 0.3061491 (1398)\ttotal: 8.16s\tremaining: 9.31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2609833\ttest: 0.3045336\tbest: 0.3044840 (1495)\ttotal: 8.73s\tremaining: 8.71s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2569417\ttest: 0.3038089\tbest: 0.3037902 (1597)\ttotal: 9.31s\tremaining: 8.14s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2532223\ttest: 0.3024764\tbest: 0.3024764 (1700)\ttotal: 9.89s\tremaining: 7.55s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.2497183\ttest: 0.3016944\tbest: 0.3016893 (1788)\ttotal: 10.5s\tremaining: 6.97s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.2463778\ttest: 0.3009988\tbest: 0.3009905 (1898)\ttotal: 11s\tremaining: 6.38s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.2430535\ttest: 0.3006474\tbest: 0.3005160 (1988)\ttotal: 11.6s\tremaining: 5.79s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.2396294\ttest: 0.2999658\tbest: 0.2999652 (2099)\ttotal: 12.2s\tremaining: 5.21s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.2366622\ttest: 0.2997819\tbest: 0.2996966 (2187)\ttotal: 12.7s\tremaining: 4.63s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.2336786\ttest: 0.2994407\tbest: 0.2994031 (2255)\ttotal: 13.3s\tremaining: 4.05s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\tlearn: 0.2303909\ttest: 0.2989405\tbest: 0.2989405 (2400)\ttotal: 13.9s\tremaining: 3.47s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\tlearn: 0.2272623\ttest: 0.2983181\tbest: 0.2982945 (2499)\ttotal: 14.5s\tremaining: 2.89s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\tlearn: 0.2242598\ttest: 0.2979398\tbest: 0.2979363 (2597)\ttotal: 15.1s\tremaining: 2.31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\tlearn: 0.2213921\ttest: 0.2975257\tbest: 0.2975058 (2691)\ttotal: 15.7s\tremaining: 1.73s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\tlearn: 0.2186900\ttest: 0.2976313\tbest: 0.2974458 (2779)\ttotal: 16.2s\tremaining: 1.15s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:26] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:26] bestTest = 0.297445817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.297445817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:26] bestIteration = 2779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:26] Shrink model to first 2780 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2780 iterations.\n",
            "INFO:optuna.study.study:Trial 2 finished with value: -0.2974458087477903 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 0 with value: -0.29252121823127597.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:26] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -0.2974458087477903 in 0:00:17.031419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -0.2974458087477903 in 0:00:17.031419\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:26] 0:\tlearn: 1.0670393\ttest: 1.0667673\tbest: 1.0667673 (0)\ttotal: 6.18ms\tremaining: 18.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0670393\ttest: 1.0667673\tbest: 1.0667673 (0)\ttotal: 6.18ms\tremaining: 18.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4311728\ttest: 0.4217220\tbest: 0.4217220 (100)\ttotal: 638ms\tremaining: 18.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3751910\ttest: 0.3698201\tbest: 0.3698201 (200)\ttotal: 1.25s\tremaining: 17.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3513519\ttest: 0.3500934\tbest: 0.3500934 (300)\ttotal: 1.82s\tremaining: 16.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3333164\ttest: 0.3370057\tbest: 0.3370057 (400)\ttotal: 2.41s\tremaining: 15.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.3206128\ttest: 0.3296642\tbest: 0.3296549 (498)\ttotal: 2.98s\tremaining: 14.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.3111245\ttest: 0.3244296\tbest: 0.3244296 (600)\ttotal: 3.55s\tremaining: 14.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.3023338\ttest: 0.3193044\tbest: 0.3193044 (700)\ttotal: 4.15s\tremaining: 13.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2961549\ttest: 0.3170692\tbest: 0.3170692 (800)\ttotal: 4.71s\tremaining: 12.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2898718\ttest: 0.3138338\tbest: 0.3137689 (896)\ttotal: 5.28s\tremaining: 12.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2842499\ttest: 0.3119244\tbest: 0.3119011 (996)\ttotal: 5.86s\tremaining: 11.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2794765\ttest: 0.3105299\tbest: 0.3105173 (1099)\ttotal: 6.44s\tremaining: 11.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2747951\ttest: 0.3086792\tbest: 0.3086380 (1196)\ttotal: 7.01s\tremaining: 10.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2699221\ttest: 0.3068458\tbest: 0.3068458 (1300)\ttotal: 7.59s\tremaining: 9.91s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2657297\ttest: 0.3055798\tbest: 0.3055615 (1397)\ttotal: 8.19s\tremaining: 9.35s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2613870\ttest: 0.3039898\tbest: 0.3039898 (1500)\ttotal: 8.75s\tremaining: 8.74s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2572786\ttest: 0.3031987\tbest: 0.3031507 (1597)\ttotal: 9.32s\tremaining: 8.14s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2532695\ttest: 0.3018761\tbest: 0.3018761 (1700)\ttotal: 9.9s\tremaining: 7.56s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.2497002\ttest: 0.3013649\tbest: 0.3013649 (1800)\ttotal: 10.5s\tremaining: 6.99s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.2463104\ttest: 0.3005860\tbest: 0.3005750 (1898)\ttotal: 11.1s\tremaining: 6.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.2427607\ttest: 0.2998797\tbest: 0.2997768 (1988)\ttotal: 11.7s\tremaining: 5.82s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.2393309\ttest: 0.2993683\tbest: 0.2993436 (2087)\ttotal: 12.2s\tremaining: 5.23s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.2363460\ttest: 0.2991369\tbest: 0.2990987 (2187)\ttotal: 12.8s\tremaining: 4.65s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.2332804\ttest: 0.2986597\tbest: 0.2985911 (2261)\ttotal: 13.4s\tremaining: 4.06s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\tlearn: 0.2300047\ttest: 0.2981193\tbest: 0.2981193 (2400)\ttotal: 14s\tremaining: 3.48s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\tlearn: 0.2268266\ttest: 0.2974589\tbest: 0.2974093 (2486)\ttotal: 14.5s\tremaining: 2.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\tlearn: 0.2238942\ttest: 0.2971901\tbest: 0.2971551 (2566)\ttotal: 15.1s\tremaining: 2.32s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\tlearn: 0.2211543\ttest: 0.2969686\tbest: 0.2969686 (2700)\ttotal: 15.7s\tremaining: 1.74s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\tlearn: 0.2184443\ttest: 0.2969999\tbest: 0.2967719 (2778)\ttotal: 16.3s\tremaining: 1.16s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:43] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:43] bestTest = 0.2967718667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2967718667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:43] bestIteration = 2778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:43] Shrink model to first 2779 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2779 iterations.\n",
            "INFO:optuna.study.study:Trial 3 finished with value: -0.2967718595183922 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}. Best is trial 0 with value: -0.29252121823127597.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:43] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -0.2967718595183922 in 0:00:17.094347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -0.2967718595183922 in 0:00:17.094347\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:43] 0:\tlearn: 1.0663811\ttest: 1.0662041\tbest: 1.0662041 (0)\ttotal: 10.2ms\tremaining: 30.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0663811\ttest: 1.0662041\tbest: 1.0662041 (0)\ttotal: 10.2ms\tremaining: 30.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3767798\ttest: 0.3748261\tbest: 0.3748261 (100)\ttotal: 1.15s\tremaining: 33.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3182057\ttest: 0.3318451\tbest: 0.3318451 (200)\ttotal: 2.26s\tremaining: 31.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2892329\ttest: 0.3193196\tbest: 0.3193196 (300)\ttotal: 3.34s\tremaining: 30s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2612961\ttest: 0.3076600\tbest: 0.3076536 (399)\ttotal: 4.44s\tremaining: 28.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2390332\ttest: 0.3014345\tbest: 0.3014168 (499)\ttotal: 5.51s\tremaining: 27.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2219694\ttest: 0.2977957\tbest: 0.2977501 (598)\ttotal: 6.58s\tremaining: 26.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2065539\ttest: 0.2950417\tbest: 0.2950417 (700)\ttotal: 7.64s\tremaining: 25.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1917109\ttest: 0.2935213\tbest: 0.2932096 (796)\ttotal: 8.72s\tremaining: 23.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1784079\ttest: 0.2918404\tbest: 0.2918403 (898)\ttotal: 9.8s\tremaining: 22.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1667178\ttest: 0.2919431\tbest: 0.2915720 (987)\ttotal: 10.9s\tremaining: 21.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:55] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:55] bestTest = 0.2915720326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2915720326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:55] bestIteration = 987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:55] Shrink model to first 988 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 988 iterations.\n",
            "INFO:optuna.study.study:Trial 4 finished with value: -0.29157202547308714 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10}. Best is trial 4 with value: -0.29157202547308714.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:55] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -0.29157202547308714 in 0:00:12.089601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -0.29157202547308714 in 0:00:12.089601\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:43:56] 0:\tlearn: 1.0663817\ttest: 1.0662049\tbest: 1.0662049 (0)\ttotal: 11.9ms\tremaining: 35.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0663817\ttest: 1.0662049\tbest: 1.0662049 (0)\ttotal: 11.9ms\tremaining: 35.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3767986\ttest: 0.3748343\tbest: 0.3748343 (100)\ttotal: 1.13s\tremaining: 32.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3182566\ttest: 0.3318566\tbest: 0.3318566 (200)\ttotal: 2.21s\tremaining: 30.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2891461\ttest: 0.3187356\tbest: 0.3187356 (300)\ttotal: 3.27s\tremaining: 29.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2611963\ttest: 0.3069508\tbest: 0.3069453 (399)\ttotal: 4.32s\tremaining: 28s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2389490\ttest: 0.3013255\tbest: 0.3013058 (499)\ttotal: 5.39s\tremaining: 26.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2211429\ttest: 0.2986501\tbest: 0.2984207 (591)\ttotal: 6.49s\tremaining: 25.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2064660\ttest: 0.2964436\tbest: 0.2964436 (700)\ttotal: 7.55s\tremaining: 24.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1917740\ttest: 0.2935465\tbest: 0.2935066 (798)\ttotal: 8.62s\tremaining: 23.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1789448\ttest: 0.2925801\tbest: 0.2924295 (876)\ttotal: 9.7s\tremaining: 22.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1670020\ttest: 0.2919322\tbest: 0.2917598 (985)\ttotal: 10.8s\tremaining: 21.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1567188\ttest: 0.2913237\tbest: 0.2911964 (1096)\ttotal: 11.9s\tremaining: 20.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1467804\ttest: 0.2908303\tbest: 0.2908303 (1200)\ttotal: 12.9s\tremaining: 19.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1374676\ttest: 0.2908742\tbest: 0.2904595 (1228)\ttotal: 14s\tremaining: 18.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:10] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:10] bestTest = 0.2904594655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2904594655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:10] bestIteration = 1228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:10] Shrink model to first 1229 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1229 iterations.\n",
            "INFO:optuna.study.study:Trial 5 finished with value: -0.2904594579329061 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1}. Best is trial 5 with value: -0.2904594579329061.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:10] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -0.2904594579329061 in 0:00:14.637726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -0.2904594579329061 in 0:00:14.637726\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:10] 0:\tlearn: 1.0670338\ttest: 1.0670168\tbest: 1.0670168 (0)\ttotal: 10.7ms\tremaining: 32.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0670338\ttest: 1.0670168\tbest: 1.0670168 (0)\ttotal: 10.7ms\tremaining: 32.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3874177\ttest: 0.3833677\tbest: 0.3833677 (100)\ttotal: 1.14s\tremaining: 32.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3336905\ttest: 0.3389167\tbest: 0.3389167 (200)\ttotal: 2.22s\tremaining: 30.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3113306\ttest: 0.3255526\tbest: 0.3255526 (300)\ttotal: 3.27s\tremaining: 29.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2912746\ttest: 0.3142112\tbest: 0.3142112 (400)\ttotal: 4.32s\tremaining: 28s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2769801\ttest: 0.3086279\tbest: 0.3086279 (500)\ttotal: 5.36s\tremaining: 26.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2661761\ttest: 0.3058571\tbest: 0.3058571 (600)\ttotal: 6.41s\tremaining: 25.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2557155\ttest: 0.3019430\tbest: 0.3019173 (696)\ttotal: 7.65s\tremaining: 25.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2456882\ttest: 0.2993833\tbest: 0.2993321 (798)\ttotal: 10.4s\tremaining: 28.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2377625\ttest: 0.2981839\tbest: 0.2981544 (898)\ttotal: 11.9s\tremaining: 27.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2288574\ttest: 0.2961485\tbest: 0.2961329 (999)\ttotal: 13s\tremaining: 25.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2210678\ttest: 0.2950846\tbest: 0.2950846 (1100)\ttotal: 14s\tremaining: 24.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2140574\ttest: 0.2943025\tbest: 0.2943001 (1181)\ttotal: 15.1s\tremaining: 22.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2071161\ttest: 0.2935683\tbest: 0.2935193 (1293)\ttotal: 16.1s\tremaining: 21s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2002338\ttest: 0.2927533\tbest: 0.2926627 (1386)\ttotal: 17.2s\tremaining: 19.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1936855\ttest: 0.2919726\tbest: 0.2918417 (1489)\ttotal: 18.2s\tremaining: 18.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.1874158\ttest: 0.2911478\tbest: 0.2910535 (1596)\ttotal: 19.2s\tremaining: 16.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.1816981\ttest: 0.2907558\tbest: 0.2907267 (1689)\ttotal: 20.3s\tremaining: 15.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.1759790\ttest: 0.2904726\tbest: 0.2904115 (1756)\ttotal: 21.4s\tremaining: 14.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.1704458\ttest: 0.2904908\tbest: 0.2903219 (1869)\ttotal: 22.5s\tremaining: 13s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:34] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:34] bestTest = 0.2903218806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2903218806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:34] bestIteration = 1869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:34] Shrink model to first 1870 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1870 iterations.\n",
            "INFO:optuna.study.study:Trial 6 finished with value: -0.2903218738582872 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20}. Best is trial 6 with value: -0.2903218738582872.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:34] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -0.2903218738582872 in 0:00:23.562112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -0.2903218738582872 in 0:00:23.562112\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:34] 0:\tlearn: 1.0659608\ttest: 1.0658663\tbest: 1.0658663 (0)\ttotal: 14.2ms\tremaining: 42.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0659608\ttest: 1.0658663\tbest: 1.0658663 (0)\ttotal: 14.2ms\tremaining: 42.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3631629\ttest: 0.3691691\tbest: 0.3691691 (100)\ttotal: 1.58s\tremaining: 45.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2989875\ttest: 0.3268984\tbest: 0.3268984 (200)\ttotal: 3.1s\tremaining: 43.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2647564\ttest: 0.3158693\tbest: 0.3158693 (300)\ttotal: 4.56s\tremaining: 40.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2320800\ttest: 0.3049527\tbest: 0.3049527 (400)\ttotal: 6.06s\tremaining: 39.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2042667\ttest: 0.2987950\tbest: 0.2987090 (499)\ttotal: 7.57s\tremaining: 37.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1838588\ttest: 0.2952261\tbest: 0.2952261 (600)\ttotal: 9.04s\tremaining: 36.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1656476\ttest: 0.2923122\tbest: 0.2923122 (700)\ttotal: 10.5s\tremaining: 34.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1493764\ttest: 0.2914380\tbest: 0.2912704 (790)\ttotal: 12s\tremaining: 33s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1352344\ttest: 0.2910589\tbest: 0.2907924 (884)\ttotal: 13.5s\tremaining: 31.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:49] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:49] bestTest = 0.2907924272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2907924272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:49] bestIteration = 884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:49] Shrink model to first 885 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 885 iterations.\n",
            "INFO:optuna.study.study:Trial 7 finished with value: -0.2907924205390518 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9}. Best is trial 6 with value: -0.2903218738582872.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:49] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -0.2907924205390518 in 0:00:15.050887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -0.2907924205390518 in 0:00:15.050887\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:44:49] 0:\tlearn: 1.0671394\ttest: 1.0668921\tbest: 1.0668921 (0)\ttotal: 6.42ms\tremaining: 19.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0671394\ttest: 1.0668921\tbest: 1.0668921 (0)\ttotal: 6.42ms\tremaining: 19.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4319660\ttest: 0.4223553\tbest: 0.4223553 (100)\ttotal: 635ms\tremaining: 18.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3764793\ttest: 0.3708072\tbest: 0.3708072 (200)\ttotal: 1.24s\tremaining: 17.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3530877\ttest: 0.3507543\tbest: 0.3507543 (300)\ttotal: 1.85s\tremaining: 16.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3368476\ttest: 0.3385046\tbest: 0.3385046 (400)\ttotal: 2.44s\tremaining: 15.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.3253211\ttest: 0.3309108\tbest: 0.3309008 (498)\ttotal: 3.02s\tremaining: 15.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.3175434\ttest: 0.3257719\tbest: 0.3257665 (599)\ttotal: 3.58s\tremaining: 14.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.3102573\ttest: 0.3212341\tbest: 0.3212341 (700)\ttotal: 4.2s\tremaining: 13.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.3052907\ttest: 0.3192915\tbest: 0.3192915 (800)\ttotal: 4.77s\tremaining: 13.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.3001958\ttest: 0.3166248\tbest: 0.3165945 (897)\ttotal: 5.34s\tremaining: 12.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2948597\ttest: 0.3144207\tbest: 0.3144054 (997)\ttotal: 5.94s\tremaining: 11.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2910041\ttest: 0.3128827\tbest: 0.3127951 (1096)\ttotal: 6.51s\tremaining: 11.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2868778\ttest: 0.3111969\tbest: 0.3111595 (1196)\ttotal: 7.07s\tremaining: 10.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2828241\ttest: 0.3095606\tbest: 0.3095606 (1300)\ttotal: 7.64s\tremaining: 9.98s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2794064\ttest: 0.3080883\tbest: 0.3080883 (1400)\ttotal: 8.22s\tremaining: 9.38s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2756642\ttest: 0.3064423\tbest: 0.3064423 (1500)\ttotal: 8.79s\tremaining: 8.78s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2724486\ttest: 0.3055820\tbest: 0.3055607 (1597)\ttotal: 9.37s\tremaining: 8.19s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2692272\ttest: 0.3044610\tbest: 0.3044610 (1700)\ttotal: 9.93s\tremaining: 7.58s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.2662955\ttest: 0.3036372\tbest: 0.3036212 (1788)\ttotal: 10.5s\tremaining: 6.99s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.2634767\ttest: 0.3029558\tbest: 0.3029558 (1900)\ttotal: 11.1s\tremaining: 6.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.2605301\ttest: 0.3021081\tbest: 0.3020567 (1988)\ttotal: 11.7s\tremaining: 5.82s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.2578217\ttest: 0.3014909\tbest: 0.3014909 (2100)\ttotal: 12.2s\tremaining: 5.23s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.2552171\ttest: 0.3010203\tbest: 0.3010050 (2181)\ttotal: 12.8s\tremaining: 4.65s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.2527344\ttest: 0.3001696\tbest: 0.3001696 (2300)\ttotal: 13.4s\tremaining: 4.07s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\tlearn: 0.2499950\ttest: 0.2996170\tbest: 0.2996170 (2400)\ttotal: 14s\tremaining: 3.48s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\tlearn: 0.2472276\ttest: 0.2989854\tbest: 0.2989630 (2499)\ttotal: 14.6s\tremaining: 2.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\tlearn: 0.2445677\ttest: 0.2982270\tbest: 0.2982270 (2600)\ttotal: 15.1s\tremaining: 2.32s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\tlearn: 0.2424062\ttest: 0.2978958\tbest: 0.2978766 (2686)\ttotal: 15.7s\tremaining: 1.74s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\tlearn: 0.2401214\ttest: 0.2977402\tbest: 0.2977115 (2778)\ttotal: 16.3s\tremaining: 1.16s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2900:\tlearn: 0.2378595\ttest: 0.2975708\tbest: 0.2974688 (2886)\ttotal: 16.8s\tremaining: 575ms\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2999:\tlearn: 0.2356227\ttest: 0.2973024\tbest: 0.2972630 (2989)\ttotal: 17.4s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:06] bestTest = 0.2972629988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2972629988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:06] bestIteration = 2989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:06] Shrink model to first 2990 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2990 iterations.\n",
            "INFO:optuna.study.study:Trial 8 finished with value: -0.2972629922431855 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6}. Best is trial 6 with value: -0.2903218738582872.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:06] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -0.2972629922431855 in 0:00:17.798740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -0.2972629922431855 in 0:00:17.798740\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:07] 0:\tlearn: 1.0663814\ttest: 1.0662044\tbest: 1.0662044 (0)\ttotal: 10ms\tremaining: 30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0663814\ttest: 1.0662044\tbest: 1.0662044 (0)\ttotal: 10ms\tremaining: 30s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3767870\ttest: 0.3748293\tbest: 0.3748293 (100)\ttotal: 1.14s\tremaining: 32.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3182252\ttest: 0.3318496\tbest: 0.3318496 (200)\ttotal: 2.23s\tremaining: 31.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2892691\ttest: 0.3193266\tbest: 0.3193266 (300)\ttotal: 3.3s\tremaining: 29.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2613422\ttest: 0.3076613\tbest: 0.3076549 (399)\ttotal: 4.39s\tremaining: 28.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2390858\ttest: 0.3014167\tbest: 0.3013989 (499)\ttotal: 5.46s\tremaining: 27.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2220269\ttest: 0.2977757\tbest: 0.2977302 (598)\ttotal: 6.52s\tremaining: 26s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2066166\ttest: 0.2950173\tbest: 0.2950173 (700)\ttotal: 7.55s\tremaining: 24.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1917782\ttest: 0.2936914\tbest: 0.2933804 (796)\ttotal: 8.64s\tremaining: 23.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1785731\ttest: 0.2923373\tbest: 0.2923373 (900)\ttotal: 9.75s\tremaining: 22.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1667507\ttest: 0.2918177\tbest: 0.2915621 (984)\ttotal: 10.8s\tremaining: 21.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:18] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:18] bestTest = 0.2915621318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2915621318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:18] bestIteration = 984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:19] Shrink model to first 985 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 985 iterations.\n",
            "INFO:optuna.study.study:Trial 9 finished with value: -0.29156212496530237 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4}. Best is trial 6 with value: -0.2903218738582872.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:19] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -0.29156212496530237 in 0:00:12.059209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -0.29156212496530237 in 0:00:12.059209\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:19] 0:\tlearn: 1.0677147\ttest: 1.0677659\tbest: 1.0677659 (0)\ttotal: 8.6ms\tremaining: 25.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0677147\ttest: 1.0677659\tbest: 1.0677659 (0)\ttotal: 8.6ms\tremaining: 25.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3998529\ttest: 0.3949087\tbest: 0.3949087 (100)\ttotal: 913ms\tremaining: 26.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3474322\ttest: 0.3473798\tbest: 0.3473798 (200)\ttotal: 1.75s\tremaining: 24.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3275412\ttest: 0.3337402\tbest: 0.3337402 (300)\ttotal: 2.58s\tremaining: 23.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3096912\ttest: 0.3220258\tbest: 0.3220135 (399)\ttotal: 3.4s\tremaining: 22.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2980246\ttest: 0.3155292\tbest: 0.3155292 (500)\ttotal: 4.22s\tremaining: 21.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2888689\ttest: 0.3113813\tbest: 0.3113795 (599)\ttotal: 5.03s\tremaining: 20.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2813858\ttest: 0.3082254\tbest: 0.3082254 (700)\ttotal: 5.82s\tremaining: 19.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2741001\ttest: 0.3057365\tbest: 0.3057365 (800)\ttotal: 6.62s\tremaining: 18.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2686475\ttest: 0.3044968\tbest: 0.3044968 (900)\ttotal: 7.39s\tremaining: 17.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2620739\ttest: 0.3025819\tbest: 0.3025600 (999)\ttotal: 8.21s\tremaining: 16.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2560264\ttest: 0.3011188\tbest: 0.3011188 (1100)\ttotal: 9.03s\tremaining: 15.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2505345\ttest: 0.2999925\tbest: 0.2999925 (1200)\ttotal: 9.85s\tremaining: 14.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2451978\ttest: 0.2986557\tbest: 0.2986557 (1300)\ttotal: 10.6s\tremaining: 13.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2398981\ttest: 0.2970857\tbest: 0.2970857 (1400)\ttotal: 11.5s\tremaining: 13.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2350896\ttest: 0.2959995\tbest: 0.2959903 (1498)\ttotal: 12.3s\tremaining: 12.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2298427\ttest: 0.2951180\tbest: 0.2951171 (1599)\ttotal: 13.1s\tremaining: 11.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2253661\ttest: 0.2944215\tbest: 0.2944215 (1700)\ttotal: 14s\tremaining: 10.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.2208386\ttest: 0.2940619\tbest: 0.2940530 (1799)\ttotal: 14.8s\tremaining: 9.87s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.2163341\ttest: 0.2934804\tbest: 0.2934736 (1891)\ttotal: 15.7s\tremaining: 9.05s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.2117779\ttest: 0.2930822\tbest: 0.2930547 (1965)\ttotal: 16.5s\tremaining: 8.24s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.2074013\ttest: 0.2924619\tbest: 0.2924619 (2100)\ttotal: 17.3s\tremaining: 7.42s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.2032600\ttest: 0.2918800\tbest: 0.2918800 (2200)\ttotal: 18.2s\tremaining: 6.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.1991685\ttest: 0.2916655\tbest: 0.2916633 (2299)\ttotal: 19s\tremaining: 5.78s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\tlearn: 0.1952122\ttest: 0.2910730\tbest: 0.2910730 (2400)\ttotal: 19.9s\tremaining: 4.97s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\tlearn: 0.1912302\ttest: 0.2906606\tbest: 0.2906597 (2498)\ttotal: 20.7s\tremaining: 4.14s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\tlearn: 0.1876046\ttest: 0.2902417\tbest: 0.2902386 (2599)\ttotal: 21.6s\tremaining: 3.31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\tlearn: 0.1841107\ttest: 0.2898517\tbest: 0.2898098 (2664)\ttotal: 22.4s\tremaining: 2.48s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\tlearn: 0.1807683\ttest: 0.2897429\tbest: 0.2896689 (2784)\ttotal: 23.2s\tremaining: 1.65s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2900:\tlearn: 0.1774380\ttest: 0.2897174\tbest: 0.2895475 (2839)\ttotal: 24.1s\tremaining: 821ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:43] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:43] bestTest = 0.289547525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.289547525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:43] bestIteration = 2839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:43] Shrink model to first 2840 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2840 iterations.\n",
            "INFO:optuna.study.study:Trial 10 finished with value: -0.2895475176389378 and parameters: {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 5.319049072944658, 'min_data_in_leaf': 20}. Best is trial 10 with value: -0.2895475176389378.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:43] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 5.319049072944658, 'min_data_in_leaf': 20} scored -0.2895475176389378 in 0:00:24.819596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 5.319049072944658, 'min_data_in_leaf': 20} scored -0.2895475176389378 in 0:00:24.819596\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:45:44] 0:\tlearn: 1.0679522\ttest: 1.0680352\tbest: 1.0680352 (0)\ttotal: 8.26ms\tremaining: 24.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0679522\ttest: 1.0680352\tbest: 1.0680352 (0)\ttotal: 8.26ms\tremaining: 24.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4013681\ttest: 0.3952108\tbest: 0.3952108 (100)\ttotal: 901ms\tremaining: 25.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3487201\ttest: 0.3469966\tbest: 0.3469966 (200)\ttotal: 1.76s\tremaining: 24.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3292493\ttest: 0.3336873\tbest: 0.3336873 (300)\ttotal: 2.6s\tremaining: 23.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3129841\ttest: 0.3230091\tbest: 0.3230091 (400)\ttotal: 3.43s\tremaining: 22.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.3016628\ttest: 0.3170275\tbest: 0.3170275 (500)\ttotal: 4.27s\tremaining: 21.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2929711\ttest: 0.3127898\tbest: 0.3127890 (599)\ttotal: 5.12s\tremaining: 20.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2857727\ttest: 0.3096666\tbest: 0.3096666 (700)\ttotal: 5.96s\tremaining: 19.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2795133\ttest: 0.3072731\tbest: 0.3072731 (800)\ttotal: 6.8s\tremaining: 18.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2744209\ttest: 0.3060231\tbest: 0.3060231 (900)\ttotal: 7.62s\tremaining: 17.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2686330\ttest: 0.3041347\tbest: 0.3041217 (996)\ttotal: 8.44s\tremaining: 16.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2630293\ttest: 0.3025578\tbest: 0.3025578 (1100)\ttotal: 9.24s\tremaining: 15.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2580125\ttest: 0.3015942\tbest: 0.3015731 (1199)\ttotal: 10.1s\tremaining: 15.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2530112\ttest: 0.3001836\tbest: 0.3001569 (1297)\ttotal: 10.9s\tremaining: 14.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2483228\ttest: 0.2989062\tbest: 0.2989062 (1400)\ttotal: 11.7s\tremaining: 13.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2436672\ttest: 0.2975814\tbest: 0.2975714 (1498)\ttotal: 12.6s\tremaining: 12.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2389778\ttest: 0.2968019\tbest: 0.2968019 (1600)\ttotal: 13.4s\tremaining: 11.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2346204\ttest: 0.2963353\tbest: 0.2962536 (1683)\ttotal: 14.2s\tremaining: 10.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.2303531\ttest: 0.2956446\tbest: 0.2956442 (1799)\ttotal: 15.1s\tremaining: 10s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.2260247\ttest: 0.2951910\tbest: 0.2951910 (1900)\ttotal: 15.9s\tremaining: 9.21s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.2218365\ttest: 0.2947480\tbest: 0.2947480 (2000)\ttotal: 16.8s\tremaining: 8.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.2178721\ttest: 0.2942476\tbest: 0.2941983 (2095)\ttotal: 17.7s\tremaining: 7.57s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.2139588\ttest: 0.2932391\tbest: 0.2932218 (2197)\ttotal: 18.6s\tremaining: 6.74s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.2101413\ttest: 0.2928064\tbest: 0.2927285 (2295)\ttotal: 19.4s\tremaining: 5.89s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\tlearn: 0.2064114\ttest: 0.2924002\tbest: 0.2923890 (2397)\ttotal: 20.2s\tremaining: 5.04s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\tlearn: 0.2026438\ttest: 0.2923046\tbest: 0.2922000 (2409)\ttotal: 21.1s\tremaining: 4.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:05] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:05] bestTest = 0.2921999943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2921999943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:05] bestIteration = 2409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:05] Shrink model to first 2410 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2410 iterations.\n",
            "INFO:optuna.study.study:Trial 11 finished with value: -0.29219998734703073 and parameters: {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 7.6545382002097115, 'min_data_in_leaf': 20}. Best is trial 10 with value: -0.2895475176389378.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:05] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 7.6545382002097115, 'min_data_in_leaf': 20} scored -0.29219998734703073 in 0:00:21.575760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 7.6545382002097115, 'min_data_in_leaf': 20} scored -0.29219998734703073 in 0:00:21.575760\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:05] 0:\tlearn: 1.0670097\ttest: 1.0668833\tbest: 1.0668833 (0)\ttotal: 9.42ms\tremaining: 28.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0670097\ttest: 1.0668833\tbest: 1.0668833 (0)\ttotal: 9.42ms\tremaining: 28.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3929686\ttest: 0.3890566\tbest: 0.3890566 (100)\ttotal: 906ms\tremaining: 26s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3368155\ttest: 0.3407542\tbest: 0.3407542 (200)\ttotal: 1.76s\tremaining: 24.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3126056\ttest: 0.3272342\tbest: 0.3272342 (300)\ttotal: 2.58s\tremaining: 23.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2916233\ttest: 0.3166998\tbest: 0.3166750 (399)\ttotal: 3.41s\tremaining: 22.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2742040\ttest: 0.3094189\tbest: 0.3093982 (499)\ttotal: 4.24s\tremaining: 21.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2610348\ttest: 0.3050567\tbest: 0.3050567 (599)\ttotal: 5.07s\tremaining: 20.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2491491\ttest: 0.3013307\tbest: 0.3013307 (700)\ttotal: 5.87s\tremaining: 19.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2384674\ttest: 0.2975707\tbest: 0.2975707 (800)\ttotal: 6.7s\tremaining: 18.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2293699\ttest: 0.2972744\tbest: 0.2972744 (900)\ttotal: 7.5s\tremaining: 17.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2200834\ttest: 0.2958693\tbest: 0.2958693 (1000)\ttotal: 8.31s\tremaining: 16.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2118165\ttest: 0.2944441\tbest: 0.2944441 (1100)\ttotal: 9.13s\tremaining: 15.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2038867\ttest: 0.2938562\tbest: 0.2936956 (1189)\ttotal: 9.95s\tremaining: 14.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1966411\ttest: 0.2927159\tbest: 0.2927159 (1300)\ttotal: 10.8s\tremaining: 14.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1892639\ttest: 0.2924868\tbest: 0.2922458 (1382)\ttotal: 11.6s\tremaining: 13.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1823384\ttest: 0.2914307\tbest: 0.2914307 (1500)\ttotal: 12.5s\tremaining: 12.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.1758695\ttest: 0.2909185\tbest: 0.2908763 (1599)\ttotal: 13.3s\tremaining: 11.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.1696886\ttest: 0.2908947\tbest: 0.2905458 (1651)\ttotal: 14.2s\tremaining: 10.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:20] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:20] bestTest = 0.2905457873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2905457873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:20] bestIteration = 1651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:20] Shrink model to first 1652 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1652 iterations.\n",
            "INFO:optuna.study.study:Trial 12 finished with value: -0.29054578040523776 and parameters: {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.1811958043617717, 'min_data_in_leaf': 20}. Best is trial 10 with value: -0.2895475176389378.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:20] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.1811958043617717, 'min_data_in_leaf': 20} scored -0.29054578040523776 in 0:00:14.952427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.1811958043617717, 'min_data_in_leaf': 20} scored -0.29054578040523776 in 0:00:14.952427\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:20] 0:\tlearn: 1.0660323\ttest: 1.0659760\tbest: 1.0659760 (0)\ttotal: 14.5ms\tremaining: 43.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0660323\ttest: 1.0659760\tbest: 1.0659760 (0)\ttotal: 14.5ms\tremaining: 43.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3645582\ttest: 0.3698490\tbest: 0.3698490 (100)\ttotal: 1.6s\tremaining: 45.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3027523\ttest: 0.3281872\tbest: 0.3281872 (200)\ttotal: 3.12s\tremaining: 43.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2712412\ttest: 0.3164634\tbest: 0.3164634 (300)\ttotal: 4.59s\tremaining: 41.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2394980\ttest: 0.3045491\tbest: 0.3045491 (400)\ttotal: 6.1s\tremaining: 39.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2134451\ttest: 0.2986341\tbest: 0.2986341 (500)\ttotal: 7.61s\tremaining: 38s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1936686\ttest: 0.2951457\tbest: 0.2951457 (600)\ttotal: 9.09s\tremaining: 36.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1760501\ttest: 0.2920351\tbest: 0.2920351 (700)\ttotal: 10.6s\tremaining: 34.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1610333\ttest: 0.2905646\tbest: 0.2905291 (791)\ttotal: 12.2s\tremaining: 33.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1475242\ttest: 0.2899885\tbest: 0.2898385 (890)\ttotal: 13.7s\tremaining: 31.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:35] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:35] bestTest = 0.2898384952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2898384952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:35] bestIteration = 890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:35] Shrink model to first 891 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 891 iterations.\n",
            "INFO:optuna.study.study:Trial 13 finished with value: -0.2898384884643515 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.16505863700695894, 'min_data_in_leaf': 16}. Best is trial 10 with value: -0.2895475176389378.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:35] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.16505863700695894, 'min_data_in_leaf': 16} scored -0.2898384884643515 in 0:00:15.336958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.16505863700695894, 'min_data_in_leaf': 16} scored -0.2898384884643515 in 0:00:15.336958\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:36] 0:\tlearn: 1.0660109\ttest: 1.0659440\tbest: 1.0659440 (0)\ttotal: 14.2ms\tremaining: 42.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0660109\ttest: 1.0659440\tbest: 1.0659440 (0)\ttotal: 14.2ms\tremaining: 42.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3640564\ttest: 0.3695944\tbest: 0.3695944 (100)\ttotal: 1.57s\tremaining: 45s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3017044\ttest: 0.3282690\tbest: 0.3282690 (200)\ttotal: 3.07s\tremaining: 42.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2700351\ttest: 0.3172748\tbest: 0.3172748 (300)\ttotal: 4.54s\tremaining: 40.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2372973\ttest: 0.3059520\tbest: 0.3059520 (400)\ttotal: 6.05s\tremaining: 39.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2109638\ttest: 0.2995293\tbest: 0.2994592 (499)\ttotal: 7.53s\tremaining: 37.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1910014\ttest: 0.2954942\tbest: 0.2954942 (600)\ttotal: 9.03s\tremaining: 36s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1733387\ttest: 0.2932791\tbest: 0.2932791 (700)\ttotal: 10.5s\tremaining: 34.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1575065\ttest: 0.2916230\tbest: 0.2916230 (800)\ttotal: 12s\tremaining: 32.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1434002\ttest: 0.2905732\tbest: 0.2903959 (892)\ttotal: 13.5s\tremaining: 31.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1303745\ttest: 0.2908102\tbest: 0.2903632 (916)\ttotal: 15.1s\tremaining: 30.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:51] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:51] bestTest = 0.2903631778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2903631778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:51] bestIteration = 916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:51] Shrink model to first 917 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 917 iterations.\n",
            "INFO:optuna.study.study:Trial 14 finished with value: -0.29036316987347555 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.11807211632529634, 'min_data_in_leaf': 15}. Best is trial 10 with value: -0.2895475176389378.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:51] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.11807211632529634, 'min_data_in_leaf': 15} scored -0.29036316987347555 in 0:00:15.608031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.11807211632529634, 'min_data_in_leaf': 15} scored -0.29036316987347555 in 0:00:15.608031\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:46:51] 0:\tlearn: 1.0670081\ttest: 1.0669046\tbest: 1.0669046 (0)\ttotal: 7.18ms\tremaining: 21.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0670081\ttest: 1.0669046\tbest: 1.0669046 (0)\ttotal: 7.18ms\tremaining: 21.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4105005\ttest: 0.4040955\tbest: 0.4040955 (100)\ttotal: 744ms\tremaining: 21.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3542463\ttest: 0.3523710\tbest: 0.3523710 (200)\ttotal: 1.46s\tremaining: 20.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3312021\ttest: 0.3364336\tbest: 0.3364336 (300)\ttotal: 2.15s\tremaining: 19.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3126922\ttest: 0.3258548\tbest: 0.3258548 (400)\ttotal: 2.83s\tremaining: 18.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2981692\ttest: 0.3174850\tbest: 0.3174841 (499)\ttotal: 3.54s\tremaining: 17.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2870848\ttest: 0.3131374\tbest: 0.3131374 (600)\ttotal: 4.22s\tremaining: 16.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2774016\ttest: 0.3089310\tbest: 0.3089310 (700)\ttotal: 4.9s\tremaining: 16.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2684150\ttest: 0.3050376\tbest: 0.3050275 (796)\ttotal: 5.58s\tremaining: 15.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2604870\ttest: 0.3024397\tbest: 0.3024397 (900)\ttotal: 6.28s\tremaining: 14.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2529540\ttest: 0.3009413\tbest: 0.3009380 (999)\ttotal: 6.96s\tremaining: 13.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2464674\ttest: 0.2995635\tbest: 0.2995305 (1096)\ttotal: 7.62s\tremaining: 13.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2398732\ttest: 0.2985054\tbest: 0.2984837 (1198)\ttotal: 8.28s\tremaining: 12.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2338026\ttest: 0.2971361\tbest: 0.2971268 (1298)\ttotal: 8.95s\tremaining: 11.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2280056\ttest: 0.2964262\tbest: 0.2963699 (1395)\ttotal: 9.64s\tremaining: 11s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2224352\ttest: 0.2953543\tbest: 0.2953309 (1495)\ttotal: 10.3s\tremaining: 10.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2169359\ttest: 0.2945533\tbest: 0.2945533 (1600)\ttotal: 11.7s\tremaining: 10.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2118575\ttest: 0.2942381\tbest: 0.2942163 (1697)\ttotal: 13.6s\tremaining: 10.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.2069044\ttest: 0.2931402\tbest: 0.2931214 (1794)\ttotal: 14.9s\tremaining: 9.93s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.2021404\ttest: 0.2925095\tbest: 0.2924686 (1899)\ttotal: 15.6s\tremaining: 9.04s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.1977599\ttest: 0.2921288\tbest: 0.2921288 (2000)\ttotal: 16.3s\tremaining: 8.15s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.1935697\ttest: 0.2918633\tbest: 0.2917442 (2085)\ttotal: 17s\tremaining: 7.28s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.1892970\ttest: 0.2916348\tbest: 0.2916348 (2200)\ttotal: 17.7s\tremaining: 6.42s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.1852902\ttest: 0.2916867\tbest: 0.2915444 (2228)\ttotal: 18.4s\tremaining: 5.59s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:10] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:10] bestTest = 0.2915443957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2915443957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:10] bestIteration = 2228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:10] Shrink model to first 2229 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2229 iterations.\n",
            "INFO:optuna.study.study:Trial 15 finished with value: -0.2915443894577603 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.10130492013778493, 'min_data_in_leaf': 16}. Best is trial 10 with value: -0.2895475176389378.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:10] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.10130492013778493, 'min_data_in_leaf': 16} scored -0.2915443894577603 in 0:00:18.982847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.10130492013778493, 'min_data_in_leaf': 16} scored -0.2915443894577603 in 0:00:18.982847\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:10] 0:\tlearn: 1.0669936\ttest: 1.0668891\tbest: 1.0668891 (0)\ttotal: 7.11ms\tremaining: 21.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0669936\ttest: 1.0668891\tbest: 1.0668891 (0)\ttotal: 7.11ms\tremaining: 21.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4103635\ttest: 0.4039902\tbest: 0.4039902 (100)\ttotal: 745ms\tremaining: 21.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3539209\ttest: 0.3522949\tbest: 0.3522949 (200)\ttotal: 1.47s\tremaining: 20.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3302628\ttest: 0.3363119\tbest: 0.3363119 (300)\ttotal: 2.16s\tremaining: 19.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3105183\ttest: 0.3245548\tbest: 0.3245548 (400)\ttotal: 2.85s\tremaining: 18.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2957302\ttest: 0.3164504\tbest: 0.3164504 (500)\ttotal: 3.52s\tremaining: 17.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2845598\ttest: 0.3122606\tbest: 0.3122606 (600)\ttotal: 4.18s\tremaining: 16.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2743622\ttest: 0.3074458\tbest: 0.3074348 (698)\ttotal: 4.85s\tremaining: 15.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2653578\ttest: 0.3043095\tbest: 0.3043095 (800)\ttotal: 5.52s\tremaining: 15.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2574696\ttest: 0.3021197\tbest: 0.3020996 (897)\ttotal: 6.21s\tremaining: 14.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2496817\ttest: 0.3003959\tbest: 0.3002923 (974)\ttotal: 6.91s\tremaining: 13.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2427458\ttest: 0.2991316\tbest: 0.2989200 (1096)\ttotal: 7.6s\tremaining: 13.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2361102\ttest: 0.2981306\tbest: 0.2981306 (1200)\ttotal: 8.27s\tremaining: 12.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2296883\ttest: 0.2968178\tbest: 0.2968112 (1299)\ttotal: 8.95s\tremaining: 11.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2235849\ttest: 0.2961338\tbest: 0.2960916 (1397)\ttotal: 9.64s\tremaining: 11s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2179174\ttest: 0.2953646\tbest: 0.2953570 (1498)\ttotal: 10.3s\tremaining: 10.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2125095\ttest: 0.2950936\tbest: 0.2950000 (1561)\ttotal: 11s\tremaining: 9.62s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2073248\ttest: 0.2943339\tbest: 0.2942432 (1696)\ttotal: 11.7s\tremaining: 8.94s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.2025139\ttest: 0.2936767\tbest: 0.2936748 (1798)\ttotal: 12.4s\tremaining: 8.25s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.1979339\ttest: 0.2934407\tbest: 0.2934202 (1899)\ttotal: 13.1s\tremaining: 7.56s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.1934355\ttest: 0.2927098\tbest: 0.2927098 (2000)\ttotal: 13.8s\tremaining: 6.88s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.1890248\ttest: 0.2926730\tbest: 0.2925027 (2036)\ttotal: 14.5s\tremaining: 6.19s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:25] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:25] bestTest = 0.2925026883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2925026883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:25] bestIteration = 2036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:25] Shrink model to first 2037 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2037 iterations.\n",
            "INFO:optuna.study.study:Trial 16 finished with value: -0.2925026806758324 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.024798179655788e-07, 'min_data_in_leaf': 13}. Best is trial 10 with value: -0.2895475176389378.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:25] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.024798179655788e-07, 'min_data_in_leaf': 13} scored -0.2925026806758324 in 0:00:15.073241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.024798179655788e-07, 'min_data_in_leaf': 13} scored -0.2925026806758324 in 0:00:15.073241\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:25] 0:\tlearn: 1.0662054\ttest: 1.0662170\tbest: 1.0662170 (0)\ttotal: 13.8ms\tremaining: 41.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0662054\ttest: 1.0662170\tbest: 1.0662170 (0)\ttotal: 13.8ms\tremaining: 41.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3681755\ttest: 0.3712973\tbest: 0.3712973 (100)\ttotal: 1.56s\tremaining: 44.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3091511\ttest: 0.3296431\tbest: 0.3296431 (200)\ttotal: 3.04s\tremaining: 42.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2813805\ttest: 0.3186722\tbest: 0.3186722 (300)\ttotal: 4.52s\tremaining: 40.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2528331\ttest: 0.3069500\tbest: 0.3069500 (400)\ttotal: 6.04s\tremaining: 39.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2289879\ttest: 0.3005367\tbest: 0.3005367 (500)\ttotal: 7.57s\tremaining: 37.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2112349\ttest: 0.2974019\tbest: 0.2974019 (600)\ttotal: 9.03s\tremaining: 36.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1951421\ttest: 0.2946166\tbest: 0.2946166 (700)\ttotal: 10.5s\tremaining: 34.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1810251\ttest: 0.2922408\tbest: 0.2921981 (797)\ttotal: 12s\tremaining: 32.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1685279\ttest: 0.2916425\tbest: 0.2914623 (857)\ttotal: 13.4s\tremaining: 31.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1563155\ttest: 0.2912353\tbest: 0.2911093 (993)\ttotal: 14.9s\tremaining: 29.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1453151\ttest: 0.2908465\tbest: 0.2907260 (1071)\ttotal: 16.4s\tremaining: 28.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1351838\ttest: 0.2906358\tbest: 0.2905519 (1155)\ttotal: 17.9s\tremaining: 26.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1265166\ttest: 0.2900542\tbest: 0.2900344 (1299)\ttotal: 19.4s\tremaining: 25.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1177970\ttest: 0.2903953\tbest: 0.2899783 (1306)\ttotal: 20.9s\tremaining: 23.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:46] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:46] bestTest = 0.2899783347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2899783347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:46] bestIteration = 1306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:46] Shrink model to first 1307 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1307 iterations.\n",
            "INFO:optuna.study.study:Trial 17 finished with value: -0.2899783283630188 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.5937223439378795, 'min_data_in_leaf': 17}. Best is trial 10 with value: -0.2895475176389378.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:46] \u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.5937223439378795, 'min_data_in_leaf': 17} scored -0.2899783283630188 in 0:00:21.319128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.5937223439378795, 'min_data_in_leaf': 17} scored -0.2899783283630188 in 0:00:21.319128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:46] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:46] The set of hyperparameters \u001b[1m{'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 5.319049072944658, 'min_data_in_leaf': 20}\u001b[0m\n",
            " achieve -0.2895 crossentropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 5.319049072944658, 'min_data_in_leaf': 20}\u001b[0m\n",
            " achieve -0.2895 crossentropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:46] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 5.319049072944658, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 20, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Max', 'verbose': 100, 'allow_writing_files': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:46] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:47:47] 0:\tlearn: 1.0677147\ttest: 1.0677659\tbest: 1.0677659 (0)\ttotal: 9.68ms\tremaining: 29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0677147\ttest: 1.0677659\tbest: 1.0677659 (0)\ttotal: 9.68ms\tremaining: 29s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3998529\ttest: 0.3949087\tbest: 0.3949087 (100)\ttotal: 892ms\tremaining: 25.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3474322\ttest: 0.3473798\tbest: 0.3473798 (200)\ttotal: 1.76s\tremaining: 24.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3275412\ttest: 0.3337402\tbest: 0.3337402 (300)\ttotal: 2.59s\tremaining: 23.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3096912\ttest: 0.3220258\tbest: 0.3220135 (399)\ttotal: 3.43s\tremaining: 22.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2980246\ttest: 0.3155292\tbest: 0.3155292 (500)\ttotal: 4.25s\tremaining: 21.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2888689\ttest: 0.3113813\tbest: 0.3113795 (599)\ttotal: 5.07s\tremaining: 20.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2813858\ttest: 0.3082254\tbest: 0.3082254 (700)\ttotal: 5.86s\tremaining: 19.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2741001\ttest: 0.3057365\tbest: 0.3057365 (800)\ttotal: 6.7s\tremaining: 18.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2686475\ttest: 0.3044968\tbest: 0.3044968 (900)\ttotal: 7.49s\tremaining: 17.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2620739\ttest: 0.3025819\tbest: 0.3025600 (999)\ttotal: 8.31s\tremaining: 16.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2560264\ttest: 0.3011188\tbest: 0.3011188 (1100)\ttotal: 9.13s\tremaining: 15.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2505345\ttest: 0.2999925\tbest: 0.2999925 (1200)\ttotal: 9.93s\tremaining: 14.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2451978\ttest: 0.2986557\tbest: 0.2986557 (1300)\ttotal: 10.7s\tremaining: 14s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2398981\ttest: 0.2970857\tbest: 0.2970857 (1400)\ttotal: 11.5s\tremaining: 13.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2350896\ttest: 0.2959995\tbest: 0.2959903 (1498)\ttotal: 12.3s\tremaining: 12.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2298427\ttest: 0.2951180\tbest: 0.2951171 (1599)\ttotal: 13.2s\tremaining: 11.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2253661\ttest: 0.2944215\tbest: 0.2944215 (1700)\ttotal: 14s\tremaining: 10.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.2208386\ttest: 0.2940619\tbest: 0.2940530 (1799)\ttotal: 14.8s\tremaining: 9.86s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.2163341\ttest: 0.2934804\tbest: 0.2934736 (1891)\ttotal: 15.6s\tremaining: 9.05s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.2117779\ttest: 0.2930822\tbest: 0.2930547 (1965)\ttotal: 16.5s\tremaining: 8.22s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.2074013\ttest: 0.2924619\tbest: 0.2924619 (2100)\ttotal: 17.3s\tremaining: 7.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.2032600\ttest: 0.2918800\tbest: 0.2918800 (2200)\ttotal: 18.1s\tremaining: 6.58s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.1991685\ttest: 0.2916655\tbest: 0.2916633 (2299)\ttotal: 19s\tremaining: 5.77s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\tlearn: 0.1952122\ttest: 0.2910730\tbest: 0.2910730 (2400)\ttotal: 19.8s\tremaining: 4.95s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\tlearn: 0.1912302\ttest: 0.2906606\tbest: 0.2906597 (2498)\ttotal: 20.7s\tremaining: 4.13s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\tlearn: 0.1876046\ttest: 0.2902417\tbest: 0.2902386 (2599)\ttotal: 21.5s\tremaining: 3.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\tlearn: 0.1841107\ttest: 0.2898517\tbest: 0.2898098 (2664)\ttotal: 22.3s\tremaining: 2.47s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\tlearn: 0.1807683\ttest: 0.2897429\tbest: 0.2896689 (2784)\ttotal: 23.1s\tremaining: 1.64s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2900:\tlearn: 0.1774380\ttest: 0.2897174\tbest: 0.2895475 (2839)\ttotal: 24s\tremaining: 817ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:11] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:11] bestTest = 0.289547525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.289547525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:11] bestIteration = 2839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:11] Shrink model to first 2840 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2840 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:11] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:11] 0:\tlearn: 1.0676376\ttest: 1.0674337\tbest: 1.0674337 (0)\ttotal: 11.1ms\tremaining: 33.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0676376\ttest: 1.0674337\tbest: 1.0674337 (0)\ttotal: 11.1ms\tremaining: 33.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3926423\ttest: 0.4129320\tbest: 0.4129320 (100)\ttotal: 889ms\tremaining: 25.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3375093\ttest: 0.3675332\tbest: 0.3675332 (200)\ttotal: 1.74s\tremaining: 24.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3182251\ttest: 0.3539029\tbest: 0.3539029 (300)\ttotal: 2.58s\tremaining: 23.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3012466\ttest: 0.3423996\tbest: 0.3423996 (400)\ttotal: 3.41s\tremaining: 22.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2891469\ttest: 0.3358742\tbest: 0.3358742 (500)\ttotal: 4.26s\tremaining: 21.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2796463\ttest: 0.3314580\tbest: 0.3314580 (600)\ttotal: 5.1s\tremaining: 20.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2718265\ttest: 0.3280877\tbest: 0.3280877 (700)\ttotal: 5.92s\tremaining: 19.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2650089\ttest: 0.3257761\tbest: 0.3257493 (796)\ttotal: 6.75s\tremaining: 18.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2587043\ttest: 0.3243095\tbest: 0.3243095 (900)\ttotal: 7.58s\tremaining: 17.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2529093\ttest: 0.3228712\tbest: 0.3228684 (999)\ttotal: 8.39s\tremaining: 16.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2474006\ttest: 0.3212337\tbest: 0.3212337 (1100)\ttotal: 9.2s\tremaining: 15.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2418063\ttest: 0.3201397\tbest: 0.3201397 (1200)\ttotal: 10s\tremaining: 15s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2365888\ttest: 0.3190366\tbest: 0.3190365 (1299)\ttotal: 10.8s\tremaining: 14.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2316198\ttest: 0.3183085\tbest: 0.3182923 (1396)\ttotal: 11.7s\tremaining: 13.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2265888\ttest: 0.3171573\tbest: 0.3170782 (1497)\ttotal: 12.5s\tremaining: 12.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2219825\ttest: 0.3165485\tbest: 0.3165203 (1597)\ttotal: 13.4s\tremaining: 11.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2173779\ttest: 0.3160902\tbest: 0.3160902 (1700)\ttotal: 14.2s\tremaining: 10.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.2125955\ttest: 0.3150785\tbest: 0.3150785 (1800)\ttotal: 15s\tremaining: 9.99s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.2082474\ttest: 0.3146536\tbest: 0.3145175 (1889)\ttotal: 15.8s\tremaining: 9.15s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.2042719\ttest: 0.3143285\tbest: 0.3143194 (1992)\ttotal: 16.6s\tremaining: 8.31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.2003032\ttest: 0.3138614\tbest: 0.3138614 (2100)\ttotal: 17.5s\tremaining: 7.47s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.1962710\ttest: 0.3134162\tbest: 0.3133572 (2191)\ttotal: 18.3s\tremaining: 6.63s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.1925202\ttest: 0.3130018\tbest: 0.3130018 (2300)\ttotal: 19.2s\tremaining: 5.82s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\tlearn: 0.1888322\ttest: 0.3128816\tbest: 0.3128147 (2392)\ttotal: 20s\tremaining: 4.99s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\tlearn: 0.1851216\ttest: 0.3126979\tbest: 0.3126512 (2467)\ttotal: 20.8s\tremaining: 4.16s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\tlearn: 0.1816425\ttest: 0.3127158\tbest: 0.3124573 (2548)\ttotal: 21.7s\tremaining: 3.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:34] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:34] bestTest = 0.3124572534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.3124572534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:34] bestIteration = 2548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:34] Shrink model to first 2549 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2549 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:34] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:34] 0:\tlearn: 1.0662821\ttest: 1.0669656\tbest: 1.0669656 (0)\ttotal: 9.01ms\tremaining: 27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0662821\ttest: 1.0669656\tbest: 1.0669656 (0)\ttotal: 9.01ms\tremaining: 27s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3946707\ttest: 0.4118779\tbest: 0.4118779 (100)\ttotal: 918ms\tremaining: 26.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3402727\ttest: 0.3647744\tbest: 0.3647744 (200)\ttotal: 1.77s\tremaining: 24.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3200474\ttest: 0.3510889\tbest: 0.3510889 (300)\ttotal: 2.62s\tremaining: 23.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3024882\ttest: 0.3405408\tbest: 0.3405408 (400)\ttotal: 3.46s\tremaining: 22.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2903687\ttest: 0.3353508\tbest: 0.3353508 (500)\ttotal: 4.27s\tremaining: 21.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2812021\ttest: 0.3326929\tbest: 0.3326871 (599)\ttotal: 5.08s\tremaining: 20.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2729780\ttest: 0.3308618\tbest: 0.3308560 (697)\ttotal: 5.87s\tremaining: 19.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2659480\ttest: 0.3302091\tbest: 0.3302046 (799)\ttotal: 6.7s\tremaining: 18.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2595900\ttest: 0.3295210\tbest: 0.3295068 (866)\ttotal: 7.53s\tremaining: 17.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2534665\ttest: 0.3287746\tbest: 0.3286469 (987)\ttotal: 8.34s\tremaining: 16.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2476486\ttest: 0.3281331\tbest: 0.3281042 (1091)\ttotal: 9.16s\tremaining: 15.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2421242\ttest: 0.3280935\tbest: 0.3278670 (1169)\ttotal: 9.96s\tremaining: 14.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2367037\ttest: 0.3276847\tbest: 0.3273296 (1285)\ttotal: 10.8s\tremaining: 14.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2318389\ttest: 0.3268203\tbest: 0.3266476 (1396)\ttotal: 11.6s\tremaining: 13.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2268029\ttest: 0.3266829\tbest: 0.3265961 (1462)\ttotal: 12.4s\tremaining: 12.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2220882\ttest: 0.3265854\tbest: 0.3265469 (1595)\ttotal: 13.2s\tremaining: 11.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2178066\ttest: 0.3260343\tbest: 0.3259055 (1677)\ttotal: 14s\tremaining: 10.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:48] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:49] bestTest = 0.3259054977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.3259054977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:49] bestIteration = 1677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:49] Shrink model to first 1678 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1678 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:49] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:48:49] 0:\tlearn: 1.0678906\ttest: 1.0671105\tbest: 1.0671105 (0)\ttotal: 8.35ms\tremaining: 25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0678906\ttest: 1.0671105\tbest: 1.0671105 (0)\ttotal: 8.35ms\tremaining: 25s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4026470\ttest: 0.3902457\tbest: 0.3902457 (100)\ttotal: 912ms\tremaining: 26.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3491363\ttest: 0.3403005\tbest: 0.3403005 (200)\ttotal: 1.79s\tremaining: 24.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3279043\ttest: 0.3238928\tbest: 0.3238928 (300)\ttotal: 2.65s\tremaining: 23.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3103153\ttest: 0.3135390\tbest: 0.3135390 (400)\ttotal: 3.48s\tremaining: 22.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2973729\ttest: 0.3072544\tbest: 0.3072364 (499)\ttotal: 4.32s\tremaining: 21.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2878310\ttest: 0.3045912\tbest: 0.3045402 (593)\ttotal: 5.12s\tremaining: 20.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2791066\ttest: 0.3023092\tbest: 0.3022909 (696)\ttotal: 5.96s\tremaining: 19.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2715608\ttest: 0.3004982\tbest: 0.3004699 (791)\ttotal: 6.76s\tremaining: 18.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2649718\ttest: 0.2992710\tbest: 0.2992451 (898)\ttotal: 7.58s\tremaining: 17.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2581168\ttest: 0.2980643\tbest: 0.2980579 (998)\ttotal: 8.41s\tremaining: 16.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2519668\ttest: 0.2970916\tbest: 0.2970916 (1100)\ttotal: 9.22s\tremaining: 15.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2464669\ttest: 0.2963352\tbest: 0.2962091 (1194)\ttotal: 10s\tremaining: 15s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2415443\ttest: 0.2958416\tbest: 0.2958373 (1298)\ttotal: 10.8s\tremaining: 14.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2364054\ttest: 0.2955149\tbest: 0.2955149 (1400)\ttotal: 11.7s\tremaining: 13.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2312827\ttest: 0.2944874\tbest: 0.2944874 (1500)\ttotal: 12.5s\tremaining: 12.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2260185\ttest: 0.2936356\tbest: 0.2935769 (1589)\ttotal: 13.3s\tremaining: 11.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2215027\ttest: 0.2934239\tbest: 0.2933681 (1694)\ttotal: 14.1s\tremaining: 10.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.2170201\ttest: 0.2931458\tbest: 0.2930913 (1767)\ttotal: 15s\tremaining: 9.96s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:04] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:04] bestTest = 0.2930912904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2930912904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:04] bestIteration = 1767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:04] Shrink model to first 1768 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1768 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:04] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:04] 0:\tlearn: 1.0680753\ttest: 1.0683299\tbest: 1.0683299 (0)\ttotal: 8.82ms\tremaining: 26.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0680753\ttest: 1.0683299\tbest: 1.0683299 (0)\ttotal: 8.82ms\tremaining: 26.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3943705\ttest: 0.4047434\tbest: 0.4047434 (100)\ttotal: 917ms\tremaining: 26.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3439011\ttest: 0.3572083\tbest: 0.3572083 (200)\ttotal: 1.77s\tremaining: 24.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3245969\ttest: 0.3420207\tbest: 0.3420207 (300)\ttotal: 2.58s\tremaining: 23.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.3078111\ttest: 0.3297679\tbest: 0.3297679 (400)\ttotal: 3.41s\tremaining: 22.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2941724\ttest: 0.3207772\tbest: 0.3207772 (500)\ttotal: 4.24s\tremaining: 21.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2846607\ttest: 0.3165906\tbest: 0.3165727 (598)\ttotal: 5.04s\tremaining: 20.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2773978\ttest: 0.3137414\tbest: 0.3137414 (700)\ttotal: 5.85s\tremaining: 19.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.2696671\ttest: 0.3112739\tbest: 0.3112478 (796)\ttotal: 6.64s\tremaining: 18.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.2630665\ttest: 0.3094236\tbest: 0.3094145 (885)\ttotal: 7.46s\tremaining: 17.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.2576285\ttest: 0.3086240\tbest: 0.3085893 (998)\ttotal: 8.27s\tremaining: 16.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.2520725\ttest: 0.3073870\tbest: 0.3073731 (1089)\ttotal: 9.06s\tremaining: 15.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.2466519\ttest: 0.3060682\tbest: 0.3060682 (1200)\ttotal: 9.86s\tremaining: 14.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.2417008\ttest: 0.3050939\tbest: 0.3050716 (1297)\ttotal: 10.6s\tremaining: 13.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.2363880\ttest: 0.3037487\tbest: 0.3037487 (1400)\ttotal: 11.5s\tremaining: 13.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.2312863\ttest: 0.3032527\tbest: 0.3031262 (1490)\ttotal: 12.3s\tremaining: 12.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.2265853\ttest: 0.3029976\tbest: 0.3029459 (1599)\ttotal: 13.2s\tremaining: 11.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.2220579\ttest: 0.3022631\tbest: 0.3022579 (1698)\ttotal: 14s\tremaining: 10.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.2175601\ttest: 0.3019170\tbest: 0.3016155 (1774)\ttotal: 14.8s\tremaining: 9.87s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.2133253\ttest: 0.3013440\tbest: 0.3013237 (1875)\ttotal: 15.6s\tremaining: 9.04s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.2095919\ttest: 0.3009428\tbest: 0.3009428 (2000)\ttotal: 16.4s\tremaining: 8.21s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.2052736\ttest: 0.3003011\tbest: 0.3002565 (2095)\ttotal: 17.3s\tremaining: 7.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.2012248\ttest: 0.2997597\tbest: 0.2997597 (2200)\ttotal: 18.1s\tremaining: 6.58s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.1972509\ttest: 0.2995376\tbest: 0.2995206 (2299)\ttotal: 19s\tremaining: 5.76s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\tlearn: 0.1932273\ttest: 0.2992220\tbest: 0.2991848 (2399)\ttotal: 19.8s\tremaining: 4.93s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\tlearn: 0.1894783\ttest: 0.2988644\tbest: 0.2988577 (2492)\ttotal: 20.6s\tremaining: 4.11s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\tlearn: 0.1856517\ttest: 0.2985739\tbest: 0.2984616 (2554)\ttotal: 21.4s\tremaining: 3.28s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\tlearn: 0.1822063\ttest: 0.2982595\tbest: 0.2982181 (2682)\ttotal: 22.2s\tremaining: 2.46s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\tlearn: 0.1789990\ttest: 0.2982325\tbest: 0.2980288 (2773)\ttotal: 23.1s\tremaining: 1.64s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2900:\tlearn: 0.1757020\ttest: 0.2979560\tbest: 0.2979166 (2864)\ttotal: 23.9s\tremaining: 815ms\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2999:\tlearn: 0.1724807\ttest: 0.2977750\tbest: 0.2977620 (2984)\ttotal: 24.7s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:29] bestTest = 0.2977619796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2977619796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:29] bestIteration = 2984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:29] Shrink model to first 2985 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2985 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.303753143520941\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.303753143520941\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:29] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:29] Time left 27861.26 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 27861.26 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:29] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:29] Layer \u001b[1m2\u001b[0m train process start. Time left 27861.21 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m2\u001b[0m train process start. Time left 27861.21 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:31] Start fitting \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [81, 82, 83, 84, 85], 'embed_sizes': array([36, 20, 42, 13,  8], dtype=int32), 'data_size': 86}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:31] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:31] Linear model: C = 1e-05 score = -0.5126651902455133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.5126651902455133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:31] Linear model: C = 5e-05 score = -0.37236408776948815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.37236408776948815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:32] Linear model: C = 0.0001 score = -0.33544516973941285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.33544516973941285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:32] Linear model: C = 0.0005 score = -0.2940731950972403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.2940731950972403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:32] Linear model: C = 0.001 score = -0.2877890603030644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.2877890603030644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:33] Linear model: C = 0.005 score = -0.2836111549855629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.2836111549855629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:33] Linear model: C = 0.01 score = -0.28333203904764986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.28333203904764986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:34] Linear model: C = 0.05 score = -0.28029433179568514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.28029433179568514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:35] Linear model: C = 0.1 score = -0.27678642614296767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.27678642614296767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:36] Linear model: C = 0.5 score = -0.2661112577912446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.2661112577912446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:36] Linear model: C = 1 score = -0.2661112577912446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.2661112577912446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:36] Linear model: C = 5 score = -0.2661112577912446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = -0.2661112577912446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:37] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:37] Linear model: C = 1e-05 score = -0.5220377572596534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.5220377572596534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:38] Linear model: C = 5e-05 score = -0.392112623961532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.392112623961532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:38] Linear model: C = 0.0001 score = -0.35851733704167155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.35851733704167155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:38] Linear model: C = 0.0005 score = -0.31958639053531873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.31958639053531873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:39] Linear model: C = 0.001 score = -0.3127342430137908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.3127342430137908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:39] Linear model: C = 0.005 score = -0.3083093614529741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.3083093614529741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:40] Linear model: C = 0.01 score = -0.30875900671060896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.30875900671060896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:40] Linear model: C = 0.05 score = -0.30844194167894856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.30844194167894856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:40] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:41] Linear model: C = 1e-05 score = -0.5266996311969208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.5266996311969208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:41] Linear model: C = 5e-05 score = -0.39755510556572254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.39755510556572254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:42] Linear model: C = 0.0001 score = -0.3641772961811624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.3641772961811624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:42] Linear model: C = 0.0005 score = -0.3263959063012749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.3263959063012749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:43] Linear model: C = 0.001 score = -0.3203891956322457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.3203891956322457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:43] Linear model: C = 0.005 score = -0.31731913427012143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.31731913427012143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:44] Linear model: C = 0.01 score = -0.31762339368220993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.31762339368220993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:44] Linear model: C = 0.05 score = -0.31501276192083844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.31501276192083844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:45] Linear model: C = 0.1 score = -0.31107543346398686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.31107543346398686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:47] Linear model: C = 0.5 score = -0.2983117151988638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.2983117151988638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:47] Linear model: C = 1 score = -0.2983117151988638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.2983117151988638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:47] Linear model: C = 5 score = -0.2983117151988638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = -0.2983117151988638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:47] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:50] Linear model: C = 1e-05 score = -0.5162681160802498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.5162681160802498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:51] Linear model: C = 5e-05 score = -0.3783686155800214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.3783686155800214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:51] Linear model: C = 0.0001 score = -0.3414139733120201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.3414139733120201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:52] Linear model: C = 0.0005 score = -0.29942893502625534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.29942893502625534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:52] Linear model: C = 0.001 score = -0.29337949559510623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.29337949559510623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:52] Linear model: C = 0.005 score = -0.29132458910347186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.29132458910347186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:53] Linear model: C = 0.01 score = -0.2923928014491132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.2923928014491132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:54] Linear model: C = 0.05 score = -0.2916989815131194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.2916989815131194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:54] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:54] Linear model: C = 1e-05 score = -0.5147415022811522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.5147415022811522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:55] Linear model: C = 5e-05 score = -0.3810102459926581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.3810102459926581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:55] Linear model: C = 0.0001 score = -0.34591112834118876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.34591112834118876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:56] Linear model: C = 0.0005 score = -0.30441735701613876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.30441735701613876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:56] Linear model: C = 0.001 score = -0.29686616327116727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.29686616327116727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:57] Linear model: C = 0.005 score = -0.2909307261125934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.2909307261125934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:57] Linear model: C = 0.01 score = -0.29037975729802107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.29037975729802107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:58] Linear model: C = 0.05 score = -0.2886990532396191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.2886990532396191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:49:59] Linear model: C = 0.1 score = -0.2868063702266125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.2868063702266125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:00] Linear model: C = 0.5 score = -0.28299829529105447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.28299829529105447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:00] Linear model: C = 1 score = -0.28299829529105447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.28299829529105447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:01] Linear model: C = 5 score = -0.288196720805266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = -0.288196720805266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:01] Fitting \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.2894115158485345\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.2894115158485345\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:01] \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:01] Time left 27829.26 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 27829.26 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:03] Start fitting \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.02, 'num_leaves': 64, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.2, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:03] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:03] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.329105\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.298906\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.302068\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.310492\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[222]\tvalid's multi_logloss: 0.298411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:16] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:16] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.342287\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.313704\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.317844\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.327887\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[227]\tvalid's multi_logloss: 0.313548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:30] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:30] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.352725\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.328422\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.341089\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[189]\tvalid's multi_logloss: 0.327854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:42] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:42] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.33242\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.300366\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.300955\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.307163\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[251]\tvalid's multi_logloss: 0.299005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:57] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:50:57] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.327513\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.294726\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.297689\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.30569\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[236]\tvalid's multi_logloss: 0.294124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:51:11] Fitting \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.3065895365685972\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.3065895365685972\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:51:11] \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:51:11] Time left 27760.13 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 27760.13 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:51:11] \u001b[1mLayer 2 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 2 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:51:11] Blending: optimization starts with equal weights and score \u001b[1m-0.29144329322242585\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.29144329322242585\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:51:11] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.2888553739483967\u001b[0m, weights = \u001b[1m[0.8518769  0.14812307]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.2888553739483967\u001b[0m, weights = \u001b[1m[0.8518769  0.14812307]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:51:11] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.2888553739483967\u001b[0m, weights = \u001b[1m[0.8518769  0.14812307]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.2888553739483967\u001b[0m, weights = \u001b[1m[0.8518769  0.14812307]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:51:11] Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:51:11] \u001b[1mAutoml preset training completed in 1040.07 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 1040.07 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:51:11] Model description:\n",
            "Models on level 0:\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost\n",
            "\n",
            "Final prediction for new objects (level 1) = \n",
            "\t 0.85188 * (5 averaged models Lvl_1_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.14812 * (5 averaged models Lvl_1_Pipe_1_Mod_0_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Models on level 0:\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost\n",
            "\n",
            "Final prediction for new objects (level 1) = \n",
            "\t 0.85188 * (5 averaged models Lvl_1_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.14812 * (5 averaged models Lvl_1_Pipe_1_Mod_0_LightGBM) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oof_pred = automl.fit_predict(df_train, roles = roles, verbose = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXwnusJptyXT",
        "outputId": "3f288e61-b4b7-4124-b121-151545810a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:05] Stdout logging level is INFO3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:05] Task: multiclass\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: multiclass\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:05] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:06] - time: 28800.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 28800.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:06] - CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:06] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:06] \u001b[1mTrain data shape: (13768, 24)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (13768, 24)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:07] Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:07] Layer \u001b[1m1\u001b[0m train process start. Time left 28798.92 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 28798.92 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:08] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [64, 65, 66, 67, 68, 69, 70, 71, 72], 'embed_sizes': array([ 9,  4, 20, 11,  9, 34, 44, 13,  8], dtype=int32), 'data_size': 73}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:08] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:08] Linear model: C = 1e-05 score = -0.8409495833414399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.8409495833414399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:09] Linear model: C = 5e-05 score = -0.6200961045888385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.6200961045888385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:09] Linear model: C = 0.0001 score = -0.5384400215685725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.5384400215685725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:10] Linear model: C = 0.0005 score = -0.4078141575587539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.4078141575587539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:10] Linear model: C = 0.001 score = -0.37345453125766065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.37345453125766065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:11] Linear model: C = 0.005 score = -0.32524927715631846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.32524927715631846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:12] Linear model: C = 0.01 score = -0.31410511847530465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.31410511847530465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:13] Linear model: C = 0.05 score = -0.29955841765257923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.29955841765257923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:14] Linear model: C = 0.1 score = -0.2967703838021539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.2967703838021539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:16] Linear model: C = 0.5 score = -0.2956660211189656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.2956660211189656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:16] Linear model: C = 1 score = -0.2956660211189656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.2956660211189656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:16] Linear model: C = 5 score = -0.29567252103306996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = -0.29567252103306996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:16] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:16] Linear model: C = 1e-05 score = -0.8397167389840429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.8397167389840429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:17] Linear model: C = 5e-05 score = -0.6198985048379687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.6198985048379687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:17] Linear model: C = 0.0001 score = -0.5389056298205428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.5389056298205428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:18] Linear model: C = 0.0005 score = -0.40992152243018176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.40992152243018176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:18] Linear model: C = 0.001 score = -0.3768448654342043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.3768448654342043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:19] Linear model: C = 0.005 score = -0.3321520914167884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.3321520914167884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:20] Linear model: C = 0.01 score = -0.32250116181137345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.32250116181137345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:23] Linear model: C = 0.05 score = -0.31020556869736754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.31020556869736754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:24] Linear model: C = 0.1 score = -0.30744829029772375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.30744829029772375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:26] Linear model: C = 0.5 score = -0.3051043715841095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.3051043715841095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:26] Linear model: C = 1 score = -0.3051043715841095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.3051043715841095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:26] Linear model: C = 5 score = -0.3051043715841095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = -0.3051043715841095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:26] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:26] Linear model: C = 1e-05 score = -0.8445382534094106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.8445382534094106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:26] Linear model: C = 5e-05 score = -0.6341999973263118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.6341999973263118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:27] Linear model: C = 0.0001 score = -0.5576879785909502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.5576879785909502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:28] Linear model: C = 0.0005 score = -0.436264043016976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.436264043016976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:28] Linear model: C = 0.001 score = -0.4048643757020358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.4048643757020358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:29] Linear model: C = 0.005 score = -0.3626508894687838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.3626508894687838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:30] Linear model: C = 0.01 score = -0.35410972065699636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.35410972065699636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:31] Linear model: C = 0.05 score = -0.345464675426104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.345464675426104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:32] Linear model: C = 0.1 score = -0.3443500447785899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.3443500447785899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:33] Linear model: C = 0.5 score = -0.34543161720401583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.34543161720401583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:33] Linear model: C = 1 score = -0.34543161720401583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.34543161720401583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:33] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:34] Linear model: C = 1e-05 score = -0.8383918925064328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.8383918925064328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:34] Linear model: C = 5e-05 score = -0.618950012601747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.618950012601747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:35] Linear model: C = 0.0001 score = -0.538925309554879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.538925309554879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:36] Linear model: C = 0.0005 score = -0.4134702087592102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.4134702087592102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:36] Linear model: C = 0.001 score = -0.38178841583151674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.38178841583151674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:37] Linear model: C = 0.005 score = -0.3395330909858177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.3395330909858177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:37] Linear model: C = 0.01 score = -0.3304086636232747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.3304086636232747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:38] Linear model: C = 0.05 score = -0.3210796679048285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.3210796679048285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:39] Linear model: C = 0.1 score = -0.3204807652845858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.3204807652845858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:41] Linear model: C = 0.5 score = -0.323581681965459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.323581681965459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:41] Linear model: C = 1 score = -0.323581681965459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.323581681965459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:41] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:41] Linear model: C = 1e-05 score = -0.8416845294624253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.8416845294624253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:42] Linear model: C = 5e-05 score = -0.6223468234349154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.6223468234349154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:42] Linear model: C = 0.0001 score = -0.5407060988892183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.5407060988892183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:43] Linear model: C = 0.0005 score = -0.41028514000637234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.41028514000637234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:44] Linear model: C = 0.001 score = -0.3767416988283124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.3767416988283124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:44] Linear model: C = 0.005 score = -0.3313378658795465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.3313378658795465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:45] Linear model: C = 0.01 score = -0.32143235259625197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.32143235259625197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:46] Linear model: C = 0.05 score = -0.30957431384874756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.30957431384874756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:47] Linear model: C = 0.1 score = -0.3073181663928133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.3073181663928133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:49] Linear model: C = 0.5 score = -0.3054061683634495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.3054061683634495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:49] Linear model: C = 1 score = -0.3054061683634495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.3054061683634495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:49] Linear model: C = 5 score = -0.3054061683634495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = -0.3054061683634495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:49] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.31420165696960684\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.31420165696960684\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:49] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:49] Time left 28756.75 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 28756.75 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:08:49] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.456763\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.340397\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.292788\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.267766\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.253432\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.245144\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.23966\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.237469\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.236801\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's multi_logloss: 0.236993\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's multi_logloss: 0.238296\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[917]\tvalid's multi_logloss: 0.236438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:09:09] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:09:10] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.02, 'num_leaves': 64, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.2, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:09:10] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:09:10] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.30338\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.207843\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.191629\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.187924\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.187356\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.189153\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[488]\tvalid's multi_logloss: 0.187164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:09:26] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:09:26] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.297187\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.200536\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.181889\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.177735\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.17835\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.180565\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[440]\tvalid's multi_logloss: 0.177107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:09:40] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:09:40] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.30535\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.208093\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.189522\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.186393\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.186572\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.187832\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[441]\tvalid's multi_logloss: 0.185876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:09:54] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:09:54] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.301236\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.206015\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.188776\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.185464\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.186098\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.188199\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[419]\tvalid's multi_logloss: 0.185233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:10:08] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:10:08] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.297517\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.201975\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.183593\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.178615\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.177375\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.178233\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[487]\tvalid's multi_logloss: 0.177175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:10:23] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.18251124682227582\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.18251124682227582\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:10:23] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:10:23] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
            "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-ce30008e-7534-45d3-9a06-f5f4c549743d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:10:23] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.296466\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.200698\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.18899\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.194274\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.204041\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[310]\tvalid's multi_logloss: 0.188851\n",
            "INFO:optuna.study.study:Trial 0 finished with value: -0.18885061582421903 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: -0.18885061582421903.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:10:52] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -0.18885061582421903 in 0:00:28.582770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -0.18885061582421903 in 0:00:28.582770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:10:52] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.3246\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.215596\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.19286\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.186906\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.185944\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.186478\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.187709\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[511]\tvalid's multi_logloss: 0.185825\n",
            "INFO:optuna.study.study:Trial 1 finished with value: -0.18582527777753274 and parameters: {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285}. Best is trial 1 with value: -0.18582527777753274.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:11:09] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -0.18582527777753274 in 0:00:17.052397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -0.18582527777753274 in 0:00:17.052397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:11:09] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.296807\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.208386\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.194614\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.192337\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.193447\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.196603\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[411]\tvalid's multi_logloss: 0.192102\n",
            "INFO:optuna.study.study:Trial 2 finished with value: -0.19210237424392496 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323}. Best is trial 1 with value: -0.18582527777753274.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:11:26] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -0.19210237424392496 in 0:00:16.872550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -0.19210237424392496 in 0:00:16.872550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:11:26] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.298731\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.203616\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.189249\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.187869\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.189863\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[352]\tvalid's multi_logloss: 0.187639\n",
            "INFO:optuna.study.study:Trial 3 finished with value: -0.18763913050062783 and parameters: {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 1 with value: -0.18582527777753274.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:11:43] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -0.18763913050062783 in 0:00:17.398074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -0.18763913050062783 in 0:00:17.398074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:11:43] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.299394\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.206168\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.193432\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.194698\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.19987\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[330]\tvalid's multi_logloss: 0.192661\n",
            "INFO:optuna.study.study:Trial 4 finished with value: -0.1926614162712067 and parameters: {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08}. Best is trial 1 with value: -0.18582527777753274.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:12:05] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -0.1926614162712067 in 0:00:21.871340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -0.1926614162712067 in 0:00:21.871340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:12:05] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.324755\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.225611\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.205918\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.198738\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.196061\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.194009\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.19309\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.192581\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.191743\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's multi_logloss: 0.191513\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's multi_logloss: 0.191127\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's multi_logloss: 0.19083\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's multi_logloss: 0.19077\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1400]\tvalid's multi_logloss: 0.190608\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1500]\tvalid's multi_logloss: 0.190567\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1600]\tvalid's multi_logloss: 0.190871\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1432]\tvalid's multi_logloss: 0.190411\n",
            "INFO:optuna.study.study:Trial 5 finished with value: -0.19041130046851643 and parameters: {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936}. Best is trial 1 with value: -0.18582527777753274.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:12:22] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -0.19041130046851643 in 0:00:17.034229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -0.19041130046851643 in 0:00:17.034229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:12:22] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.308664\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.21039\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.19242\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.187616\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.1864\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.187123\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.188215\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[511]\tvalid's multi_logloss: 0.186394\n",
            "INFO:optuna.study.study:Trial 6 finished with value: -0.1863936249476428 and parameters: {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574}. Best is trial 1 with value: -0.18582527777753274.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:12:35] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -0.1863936249476428 in 0:00:13.491826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -0.1863936249476428 in 0:00:13.491826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:12:36] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.316421\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.209967\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.190229\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.189051\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.19276\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[370]\tvalid's multi_logloss: 0.188417\n",
            "INFO:optuna.study.study:Trial 7 finished with value: -0.18841669412831807 and parameters: {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 1 with value: -0.18582527777753274.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:12:52] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -0.18841669412831807 in 0:00:17.087277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -0.18841669412831807 in 0:00:17.087277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:12:53] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.308685\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.212302\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.195108\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.189476\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.187989\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.187326\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.187371\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[575]\tvalid's multi_logloss: 0.187236\n",
            "INFO:optuna.study.study:Trial 8 finished with value: -0.18723553921269423 and parameters: {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483}. Best is trial 1 with value: -0.18582527777753274.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:13:08] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -0.18723553921269423 in 0:00:15.857073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -0.18723553921269423 in 0:00:15.857073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:13:09] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.298492\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.206857\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.193886\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.195294\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.20067\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[324]\tvalid's multi_logloss: 0.193583\n",
            "INFO:optuna.study.study:Trial 9 finished with value: -0.19358302377514033 and parameters: {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06}. Best is trial 1 with value: -0.18582527777753274.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:13:32] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -0.19358302377514033 in 0:00:23.561116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -0.19358302377514033 in 0:00:23.561116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:13:32] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.317147\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.211441\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.191452\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.187395\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.186705\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.187397\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[489]\tvalid's multi_logloss: 0.186581\n",
            "INFO:optuna.study.study:Trial 10 finished with value: -0.186580738970828 and parameters: {'feature_fraction': 0.5102651048435158, 'num_leaves': 155, 'bagging_fraction': 0.7149885992524333, 'min_sum_hessian_in_leaf': 5.376638637951075, 'reg_alpha': 0.005764962972197511, 'reg_lambda': 0.03969950572380459}. Best is trial 1 with value: -0.18582527777753274.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:13:46] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.5102651048435158, 'num_leaves': 155, 'bagging_fraction': 0.7149885992524333, 'min_sum_hessian_in_leaf': 5.376638637951075, 'reg_alpha': 0.005764962972197511, 'reg_lambda': 0.03969950572380459} scored -0.186580738970828 in 0:00:14.182027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.5102651048435158, 'num_leaves': 155, 'bagging_fraction': 0.7149885992524333, 'min_sum_hessian_in_leaf': 5.376638637951075, 'reg_alpha': 0.005764962972197511, 'reg_lambda': 0.03969950572380459} scored -0.186580738970828 in 0:00:14.182027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:13:46] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.304262\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.203965\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.188049\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.188776\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.194086\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[343]\tvalid's multi_logloss: 0.187096\n",
            "INFO:optuna.study.study:Trial 11 finished with value: -0.18709572695783924 and parameters: {'feature_fraction': 0.598414301986447, 'num_leaves': 124, 'bagging_fraction': 0.8918148105745085, 'min_sum_hessian_in_leaf': 0.03299263281612611, 'reg_alpha': 1.396577090650596e-08, 'reg_lambda': 0.018162450266967962}. Best is trial 1 with value: -0.18582527777753274.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:14:04] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.598414301986447, 'num_leaves': 124, 'bagging_fraction': 0.8918148105745085, 'min_sum_hessian_in_leaf': 0.03299263281612611, 'reg_alpha': 1.396577090650596e-08, 'reg_lambda': 0.018162450266967962} scored -0.18709572695783924 in 0:00:17.361165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.598414301986447, 'num_leaves': 124, 'bagging_fraction': 0.8918148105745085, 'min_sum_hessian_in_leaf': 0.03299263281612611, 'reg_alpha': 1.396577090650596e-08, 'reg_lambda': 0.018162450266967962} scored -0.18709572695783924 in 0:00:17.361165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:14:04] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.325539\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.220894\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.199448\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.191637\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.188199\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.186382\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.18524\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.184431\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.184078\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's multi_logloss: 0.183844\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's multi_logloss: 0.183776\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's multi_logloss: 0.18464\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1081]\tvalid's multi_logloss: 0.183666\n",
            "INFO:optuna.study.study:Trial 12 finished with value: -0.18366649060909415 and parameters: {'feature_fraction': 0.6064204175155182, 'num_leaves': 28, 'bagging_fraction': 0.7363570033289744, 'min_sum_hessian_in_leaf': 0.03778278504105211, 'reg_alpha': 2.757303879830078e-07, 'reg_lambda': 7.545002454903681}. Best is trial 12 with value: -0.18366649060909415.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:14:23] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.6064204175155182, 'num_leaves': 28, 'bagging_fraction': 0.7363570033289744, 'min_sum_hessian_in_leaf': 0.03778278504105211, 'reg_alpha': 2.757303879830078e-07, 'reg_lambda': 7.545002454903681} scored -0.18366649060909415 in 0:00:19.440716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.6064204175155182, 'num_leaves': 28, 'bagging_fraction': 0.7363570033289744, 'min_sum_hessian_in_leaf': 0.03778278504105211, 'reg_alpha': 2.757303879830078e-07, 'reg_lambda': 7.545002454903681} scored -0.18366649060909415 in 0:00:19.440716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:14:23] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.331401\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.224866\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.202663\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.195186\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.191893\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.190109\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.188731\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.187749\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.187052\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's multi_logloss: 0.186375\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's multi_logloss: 0.186042\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's multi_logloss: 0.185852\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's multi_logloss: 0.185859\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1193]\tvalid's multi_logloss: 0.185774\n",
            "INFO:optuna.study.study:Trial 13 finished with value: -0.18577431592576016 and parameters: {'feature_fraction': 0.5899451536845474, 'num_leaves': 17, 'bagging_fraction': 0.7186907074321097, 'min_sum_hessian_in_leaf': 0.019978833875428263, 'reg_alpha': 0.0001653282123997987, 'reg_lambda': 4.063307662931673}. Best is trial 12 with value: -0.18366649060909415.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:14:43] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.5899451536845474, 'num_leaves': 17, 'bagging_fraction': 0.7186907074321097, 'min_sum_hessian_in_leaf': 0.019978833875428263, 'reg_alpha': 0.0001653282123997987, 'reg_lambda': 4.063307662931673} scored -0.18577431592576016 in 0:00:19.546080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.5899451536845474, 'num_leaves': 17, 'bagging_fraction': 0.7186907074321097, 'min_sum_hessian_in_leaf': 0.019978833875428263, 'reg_alpha': 0.0001653282123997987, 'reg_lambda': 4.063307662931673} scored -0.18577431592576016 in 0:00:19.546080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:14:43] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.329368\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.223009\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.20088\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.193762\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.19014\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.188049\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.186904\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.186013\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.185376\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's multi_logloss: 0.185305\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's multi_logloss: 0.185085\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's multi_logloss: 0.185128\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's multi_logloss: 0.185351\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1120]\tvalid's multi_logloss: 0.184982\n",
            "INFO:optuna.study.study:Trial 14 finished with value: -0.1849816352999857 and parameters: {'feature_fraction': 0.6045508080634426, 'num_leaves': 24, 'bagging_fraction': 0.6922570335484624, 'min_sum_hessian_in_leaf': 0.023506997063237167, 'reg_alpha': 8.99315997667906e-05, 'reg_lambda': 9.133225735789102}. Best is trial 12 with value: -0.18366649060909415.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:01] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.6045508080634426, 'num_leaves': 24, 'bagging_fraction': 0.6922570335484624, 'min_sum_hessian_in_leaf': 0.023506997063237167, 'reg_alpha': 8.99315997667906e-05, 'reg_lambda': 9.133225735789102} scored -0.1849816352999857 in 0:00:18.208354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.6045508080634426, 'num_leaves': 24, 'bagging_fraction': 0.6922570335484624, 'min_sum_hessian_in_leaf': 0.023506997063237167, 'reg_alpha': 8.99315997667906e-05, 'reg_lambda': 9.133225735789102} scored -0.1849816352999857 in 0:00:18.208354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:01] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.306358\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.20686\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.190519\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.189045\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.191115\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[385]\tvalid's multi_logloss: 0.188578\n",
            "INFO:optuna.study.study:Trial 15 finished with value: -0.18857820394377328 and parameters: {'feature_fraction': 0.6184588837830479, 'num_leaves': 98, 'bagging_fraction': 0.6689296145630166, 'min_sum_hessian_in_leaf': 0.021004805863831112, 'reg_alpha': 0.00010692063992984467, 'reg_lambda': 0.2132949659591525}. Best is trial 12 with value: -0.18366649060909415.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:16] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.6184588837830479, 'num_leaves': 98, 'bagging_fraction': 0.6689296145630166, 'min_sum_hessian_in_leaf': 0.021004805863831112, 'reg_alpha': 0.00010692063992984467, 'reg_lambda': 0.2132949659591525} scored -0.18857820394377328 in 0:00:15.119293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.6184588837830479, 'num_leaves': 98, 'bagging_fraction': 0.6689296145630166, 'min_sum_hessian_in_leaf': 0.021004805863831112, 'reg_alpha': 0.00010692063992984467, 'reg_lambda': 0.2132949659591525} scored -0.18857820394377328 in 0:00:15.119293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:16] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.313298\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.220503\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.202848\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.195941\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.193532\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.191877\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's multi_logloss: 0.191053\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's multi_logloss: 0.190784\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's multi_logloss: 0.190527\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's multi_logloss: 0.19045\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's multi_logloss: 0.190107\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's multi_logloss: 0.189614\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's multi_logloss: 0.189665\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1400]\tvalid's multi_logloss: 0.189547\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[1500]\tvalid's multi_logloss: 0.189919\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1324]\tvalid's multi_logloss: 0.189399\n",
            "INFO:optuna.study.study:Trial 16 finished with value: -0.18939880108234716 and parameters: {'feature_fraction': 0.8967572838757637, 'num_leaves': 17, 'bagging_fraction': 0.751700940392858, 'min_sum_hessian_in_leaf': 0.0010713733493980485, 'reg_alpha': 0.09986295928605116, 'reg_lambda': 0.007261918647695887}. Best is trial 12 with value: -0.18366649060909415.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:38] \u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.8967572838757637, 'num_leaves': 17, 'bagging_fraction': 0.751700940392858, 'min_sum_hessian_in_leaf': 0.0010713733493980485, 'reg_alpha': 0.09986295928605116, 'reg_lambda': 0.007261918647695887} scored -0.18939880108234716 in 0:00:21.946333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.8967572838757637, 'num_leaves': 17, 'bagging_fraction': 0.751700940392858, 'min_sum_hessian_in_leaf': 0.0010713733493980485, 'reg_alpha': 0.09986295928605116, 'reg_lambda': 0.007261918647695887} scored -0.18939880108234716 in 0:00:21.946333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:38] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:38] The set of hyperparameters \u001b[1m{'feature_fraction': 0.6064204175155182, 'num_leaves': 28, 'bagging_fraction': 0.7363570033289744, 'min_sum_hessian_in_leaf': 0.03778278504105211, 'reg_alpha': 2.757303879830078e-07, 'reg_lambda': 7.545002454903681}\u001b[0m\n",
            " achieve -0.1837 crossentropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.6064204175155182, 'num_leaves': 28, 'bagging_fraction': 0.7363570033289744, 'min_sum_hessian_in_leaf': 0.03778278504105211, 'reg_alpha': 2.757303879830078e-07, 'reg_lambda': 7.545002454903681}\u001b[0m\n",
            " achieve -0.1837 crossentropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:38] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 28, 'feature_fraction': 0.6064204175155182, 'bagging_fraction': 0.7363570033289744, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 2.757303879830078e-07, 'reg_lambda': 7.545002454903681, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'min_sum_hessian_in_leaf': 0.03778278504105211}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:38] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:38] Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.207631\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.190146\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.187291\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.187035\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[368]\tvalid's multi_logloss: 0.186633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:45] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:45] Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.199645\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.180559\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.178051\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.177884\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[371]\tvalid's multi_logloss: 0.177514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:52] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:52] Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.209761\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.191924\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.190503\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.1907\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[365]\tvalid's multi_logloss: 0.190096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:59] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:15:59] Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.20652\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.189316\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.187506\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.188058\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[327]\tvalid's multi_logloss: 0.187017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:06] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:06] Training until validation scores don't improve for 100 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.20155\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.182984\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.178549\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.177866\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[329]\tvalid's multi_logloss: 0.177559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-0.18376413606674674\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-0.18376413606674674\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:12] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:13] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:13] 0:\tlearn: 1.0615070\ttest: 1.0610822\tbest: 1.0610822 (0)\ttotal: 10.8ms\tremaining: 32.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0615070\ttest: 1.0610822\tbest: 1.0610822 (0)\ttotal: 10.8ms\tremaining: 32.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2792064\ttest: 0.2793484\tbest: 0.2793484 (100)\ttotal: 967ms\tremaining: 27.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2236518\ttest: 0.2293490\tbest: 0.2293490 (200)\ttotal: 1.9s\tremaining: 26.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2037529\ttest: 0.2160761\tbest: 0.2160761 (300)\ttotal: 2.82s\tremaining: 25.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1854735\ttest: 0.2054934\tbest: 0.2054934 (400)\ttotal: 3.74s\tremaining: 24.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1720335\ttest: 0.2005256\tbest: 0.2005256 (500)\ttotal: 4.64s\tremaining: 23.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1615921\ttest: 0.1975990\tbest: 0.1975985 (598)\ttotal: 5.6s\tremaining: 22.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1522361\ttest: 0.1955108\tbest: 0.1955108 (700)\ttotal: 6.52s\tremaining: 21.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1440391\ttest: 0.1938166\tbest: 0.1937562 (799)\ttotal: 7.43s\tremaining: 20.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1368068\ttest: 0.1929872\tbest: 0.1929872 (900)\ttotal: 8.32s\tremaining: 19.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1299621\ttest: 0.1921458\tbest: 0.1921122 (995)\ttotal: 9.24s\tremaining: 18.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1233930\ttest: 0.1908969\tbest: 0.1908931 (1097)\ttotal: 10.2s\tremaining: 17.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1177664\ttest: 0.1906917\tbest: 0.1905710 (1187)\ttotal: 11.1s\tremaining: 16.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1123179\ttest: 0.1899780\tbest: 0.1899392 (1293)\ttotal: 12s\tremaining: 15.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1073473\ttest: 0.1899028\tbest: 0.1898454 (1396)\ttotal: 12.9s\tremaining: 14.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1027065\ttest: 0.1887025\tbest: 0.1886976 (1498)\ttotal: 13.8s\tremaining: 13.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.0981693\ttest: 0.1886104\tbest: 0.1885412 (1575)\ttotal: 14.7s\tremaining: 12.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:28] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:28] bestTest = 0.1885412084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1885412084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:28] bestIteration = 1575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:28] Shrink model to first 1576 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1576 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:28] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:28] 0:\tlearn: 1.0614944\ttest: 1.0614559\tbest: 1.0614559 (0)\ttotal: 10.3ms\tremaining: 30.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0614944\ttest: 1.0614559\tbest: 1.0614559 (0)\ttotal: 10.3ms\tremaining: 30.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2787471\ttest: 0.2783495\tbest: 0.2783495 (100)\ttotal: 975ms\tremaining: 28s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2227955\ttest: 0.2291013\tbest: 0.2291013 (200)\ttotal: 1.95s\tremaining: 27.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2021329\ttest: 0.2151403\tbest: 0.2151403 (300)\ttotal: 2.91s\tremaining: 26.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1852123\ttest: 0.2056642\tbest: 0.2056642 (400)\ttotal: 3.84s\tremaining: 24.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1719763\ttest: 0.2002235\tbest: 0.2002010 (499)\ttotal: 4.76s\tremaining: 23.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1617547\ttest: 0.1973424\tbest: 0.1973424 (600)\ttotal: 5.65s\tremaining: 22.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1522842\ttest: 0.1937029\tbest: 0.1937029 (700)\ttotal: 6.55s\tremaining: 21.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1439249\ttest: 0.1916228\tbest: 0.1916228 (800)\ttotal: 7.46s\tremaining: 20.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1365879\ttest: 0.1897607\tbest: 0.1897607 (900)\ttotal: 8.4s\tremaining: 19.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1296059\ttest: 0.1886631\tbest: 0.1886631 (1000)\ttotal: 9.32s\tremaining: 18.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1229894\ttest: 0.1874562\tbest: 0.1873094 (1084)\ttotal: 10.2s\tremaining: 17.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1171455\ttest: 0.1870888\tbest: 0.1870876 (1198)\ttotal: 11.2s\tremaining: 16.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1113571\ttest: 0.1867135\tbest: 0.1865296 (1286)\ttotal: 12.1s\tremaining: 15.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1063940\ttest: 0.1862961\tbest: 0.1862953 (1399)\ttotal: 13s\tremaining: 14.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1017148\ttest: 0.1861669\tbest: 0.1860634 (1414)\ttotal: 13.9s\tremaining: 13.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:42] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:43] bestTest = 0.1860634149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1860634149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:43] bestIteration = 1414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:43] Shrink model to first 1415 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1415 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:43] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:43] 0:\tlearn: 1.0611852\ttest: 1.0620755\tbest: 1.0620755 (0)\ttotal: 9.66ms\tremaining: 29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0611852\ttest: 1.0620755\tbest: 1.0620755 (0)\ttotal: 9.66ms\tremaining: 29s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2756261\ttest: 0.2905946\tbest: 0.2905946 (100)\ttotal: 968ms\tremaining: 27.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2198026\ttest: 0.2406857\tbest: 0.2406857 (200)\ttotal: 1.88s\tremaining: 26.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1988588\ttest: 0.2266840\tbest: 0.2266840 (300)\ttotal: 2.79s\tremaining: 25s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1813908\ttest: 0.2170816\tbest: 0.2170816 (400)\ttotal: 3.7s\tremaining: 24s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1684695\ttest: 0.2113039\tbest: 0.2113039 (500)\ttotal: 4.63s\tremaining: 23.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1581286\ttest: 0.2084877\tbest: 0.2084583 (598)\ttotal: 5.53s\tremaining: 22.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1489519\ttest: 0.2062568\tbest: 0.2062316 (698)\ttotal: 6.43s\tremaining: 21.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1408210\ttest: 0.2045250\tbest: 0.2044710 (795)\ttotal: 7.35s\tremaining: 20.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1337556\ttest: 0.2035200\tbest: 0.2035145 (899)\ttotal: 8.23s\tremaining: 19.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1272514\ttest: 0.2029969\tbest: 0.2029147 (995)\ttotal: 9.13s\tremaining: 18.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1208799\ttest: 0.2018398\tbest: 0.2017929 (1072)\ttotal: 10s\tremaining: 17.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1151089\ttest: 0.2012646\tbest: 0.2012646 (1200)\ttotal: 11s\tremaining: 16.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1098418\ttest: 0.2004084\tbest: 0.2003760 (1274)\ttotal: 11.9s\tremaining: 15.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1049420\ttest: 0.2000522\tbest: 0.2000522 (1400)\ttotal: 12.7s\tremaining: 14.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1004154\ttest: 0.2003528\tbest: 0.1999794 (1402)\ttotal: 13.6s\tremaining: 13.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:56] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:56] bestTest = 0.1999794341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1999794341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:56] bestIteration = 1402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:56] Shrink model to first 1403 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1403 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:56] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:57] 0:\tlearn: 1.0632510\ttest: 1.0635336\tbest: 1.0635336 (0)\ttotal: 8.83ms\tremaining: 26.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0632510\ttest: 1.0635336\tbest: 1.0635336 (0)\ttotal: 8.83ms\tremaining: 26.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2755537\ttest: 0.2852652\tbest: 0.2852652 (100)\ttotal: 956ms\tremaining: 27.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2202911\ttest: 0.2368706\tbest: 0.2368706 (200)\ttotal: 1.89s\tremaining: 26.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1995501\ttest: 0.2231682\tbest: 0.2231682 (300)\ttotal: 2.78s\tremaining: 24.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1827742\ttest: 0.2135372\tbest: 0.2135372 (400)\ttotal: 3.68s\tremaining: 23.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1699189\ttest: 0.2080171\tbest: 0.2080171 (500)\ttotal: 4.56s\tremaining: 22.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1595797\ttest: 0.2038747\tbest: 0.2038747 (600)\ttotal: 5.47s\tremaining: 21.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1501182\ttest: 0.2007316\tbest: 0.2007010 (696)\ttotal: 6.36s\tremaining: 20.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1417056\ttest: 0.1990067\tbest: 0.1990067 (800)\ttotal: 7.28s\tremaining: 20s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1345320\ttest: 0.1980010\tbest: 0.1980010 (900)\ttotal: 8.21s\tremaining: 19.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1278721\ttest: 0.1965084\tbest: 0.1965084 (1000)\ttotal: 10.1s\tremaining: 20.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1218749\ttest: 0.1958314\tbest: 0.1957895 (1098)\ttotal: 12.5s\tremaining: 21.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1162780\ttest: 0.1949653\tbest: 0.1949653 (1200)\ttotal: 13.4s\tremaining: 20.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1109445\ttest: 0.1945179\tbest: 0.1945179 (1300)\ttotal: 14.3s\tremaining: 18.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1060040\ttest: 0.1937655\tbest: 0.1937576 (1398)\ttotal: 15.2s\tremaining: 17.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1014636\ttest: 0.1933587\tbest: 0.1933432 (1497)\ttotal: 16.1s\tremaining: 16.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.0969611\ttest: 0.1932458\tbest: 0.1931414 (1564)\ttotal: 17s\tremaining: 14.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.0928369\ttest: 0.1926567\tbest: 0.1926286 (1698)\ttotal: 17.9s\tremaining: 13.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.0889656\ttest: 0.1923815\tbest: 0.1923815 (1800)\ttotal: 18.8s\tremaining: 12.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.0852713\ttest: 0.1924060\tbest: 0.1921701 (1817)\ttotal: 19.8s\tremaining: 11.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:17] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:17] bestTest = 0.1921701059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1921701059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:17] bestIteration = 1817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:17] Shrink model to first 1818 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1818 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:17] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:17] 0:\tlearn: 1.0626381\ttest: 1.0623236\tbest: 1.0623236 (0)\ttotal: 11.7ms\tremaining: 35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0626381\ttest: 1.0623236\tbest: 1.0623236 (0)\ttotal: 11.7ms\tremaining: 35s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2799227\ttest: 0.2786810\tbest: 0.2786810 (100)\ttotal: 1.01s\tremaining: 29s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2235011\ttest: 0.2249931\tbest: 0.2249931 (200)\ttotal: 2s\tremaining: 27.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2035205\ttest: 0.2109142\tbest: 0.2109118 (299)\ttotal: 2.9s\tremaining: 26s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1867385\ttest: 0.2013267\tbest: 0.2013267 (400)\ttotal: 3.82s\tremaining: 24.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1734130\ttest: 0.1958832\tbest: 0.1958832 (500)\ttotal: 4.74s\tremaining: 23.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1633401\ttest: 0.1920916\tbest: 0.1920731 (596)\ttotal: 5.64s\tremaining: 22.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1541968\ttest: 0.1883440\tbest: 0.1883440 (700)\ttotal: 6.54s\tremaining: 21.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1462628\ttest: 0.1860760\tbest: 0.1860488 (798)\ttotal: 7.44s\tremaining: 20.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1388465\ttest: 0.1840486\tbest: 0.1839724 (897)\ttotal: 8.35s\tremaining: 19.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1317070\ttest: 0.1819905\tbest: 0.1819905 (1000)\ttotal: 9.23s\tremaining: 18.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1256015\ttest: 0.1809376\tbest: 0.1809376 (1100)\ttotal: 10.1s\tremaining: 17.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1197227\ttest: 0.1800817\tbest: 0.1800817 (1200)\ttotal: 11s\tremaining: 16.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1143279\ttest: 0.1790017\tbest: 0.1789923 (1299)\ttotal: 11.9s\tremaining: 15.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1092923\ttest: 0.1787765\tbest: 0.1787693 (1391)\ttotal: 12.8s\tremaining: 14.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1043683\ttest: 0.1777572\tbest: 0.1777500 (1498)\ttotal: 13.8s\tremaining: 13.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.0998977\ttest: 0.1776658\tbest: 0.1775708 (1581)\ttotal: 14.7s\tremaining: 12.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.0957225\ttest: 0.1774521\tbest: 0.1773048 (1694)\ttotal: 15.7s\tremaining: 12s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.0918074\ttest: 0.1771248\tbest: 0.1771151 (1797)\ttotal: 16.6s\tremaining: 11s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.0881348\ttest: 0.1773482\tbest: 0.1770478 (1807)\ttotal: 17.5s\tremaining: 10.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:35] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:35] bestTest = 0.1770477664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1770477664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:35] bestIteration = 1807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:35] Shrink model to first 1808 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1808 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:35] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.18876099146728398\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.18876099146728398\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:35] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:35] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
            "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-104575b7-b2b8-4efd-8b04-0715e8bdc59a\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:35] 0:\tlearn: 1.0618289\ttest: 1.0614887\tbest: 1.0614887 (0)\ttotal: 9.13ms\tremaining: 27.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0618289\ttest: 1.0614887\tbest: 1.0614887 (0)\ttotal: 9.13ms\tremaining: 27.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2948931\ttest: 0.2936275\tbest: 0.2936275 (100)\ttotal: 797ms\tremaining: 22.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2357962\ttest: 0.2379456\tbest: 0.2379456 (200)\ttotal: 1.57s\tremaining: 21.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2156666\ttest: 0.2224517\tbest: 0.2224517 (300)\ttotal: 2.34s\tremaining: 21s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1997888\ttest: 0.2112335\tbest: 0.2112335 (400)\ttotal: 3.1s\tremaining: 20.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1887773\ttest: 0.2058039\tbest: 0.2057959 (499)\ttotal: 3.84s\tremaining: 19.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1797385\ttest: 0.2020763\tbest: 0.2020763 (600)\ttotal: 4.56s\tremaining: 18.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1717100\ttest: 0.1989090\tbest: 0.1989090 (700)\ttotal: 5.31s\tremaining: 17.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1651072\ttest: 0.1969015\tbest: 0.1969015 (800)\ttotal: 6.05s\tremaining: 16.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1589478\ttest: 0.1959269\tbest: 0.1957942 (891)\ttotal: 6.79s\tremaining: 15.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1529182\ttest: 0.1945331\tbest: 0.1945155 (999)\ttotal: 7.52s\tremaining: 15s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1478277\ttest: 0.1933317\tbest: 0.1933107 (1072)\ttotal: 8.24s\tremaining: 14.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1430465\ttest: 0.1924066\tbest: 0.1924066 (1200)\ttotal: 8.98s\tremaining: 13.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1386475\ttest: 0.1917125\tbest: 0.1916241 (1289)\ttotal: 9.73s\tremaining: 12.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1344409\ttest: 0.1914442\tbest: 0.1914043 (1380)\ttotal: 10.5s\tremaining: 11.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1304811\ttest: 0.1907102\tbest: 0.1906299 (1493)\ttotal: 11.2s\tremaining: 11.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.1265620\ttest: 0.1902653\tbest: 0.1902653 (1600)\ttotal: 12s\tremaining: 10.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.1227956\ttest: 0.1899304\tbest: 0.1899193 (1663)\ttotal: 12.7s\tremaining: 9.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.1195040\ttest: 0.1891866\tbest: 0.1891552 (1797)\ttotal: 13.5s\tremaining: 8.96s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.1161710\ttest: 0.1891714\tbest: 0.1891228 (1813)\ttotal: 14.2s\tremaining: 8.19s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:49] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:49] bestTest = 0.1891227754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1891227754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:49] bestIteration = 1813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:49] Shrink model to first 1814 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1814 iterations.\n",
            "INFO:optuna.study.study:Trial 0 finished with value: -0.18912280810696688 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: -0.18912280810696688.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:49] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -0.18912280810696688 in 0:00:14.605196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -0.18912280810696688 in 0:00:14.605196\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:17:49] 0:\tlearn: 1.0624556\ttest: 1.0620543\tbest: 1.0620543 (0)\ttotal: 6.32ms\tremaining: 18.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0624556\ttest: 1.0620543\tbest: 1.0620543 (0)\ttotal: 6.32ms\tremaining: 18.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3264378\ttest: 0.3229855\tbest: 0.3229855 (100)\ttotal: 662ms\tremaining: 19s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2596542\ttest: 0.2581453\tbest: 0.2581453 (200)\ttotal: 1.32s\tremaining: 18.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2340940\ttest: 0.2348103\tbest: 0.2348103 (300)\ttotal: 1.96s\tremaining: 17.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2185171\ttest: 0.2216748\tbest: 0.2216748 (400)\ttotal: 2.6s\tremaining: 16.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2077914\ttest: 0.2141922\tbest: 0.2141922 (500)\ttotal: 3.21s\tremaining: 16s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2003506\ttest: 0.2102328\tbest: 0.2102328 (600)\ttotal: 3.85s\tremaining: 15.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1939449\ttest: 0.2073025\tbest: 0.2072426 (699)\ttotal: 4.47s\tremaining: 14.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1882742\ttest: 0.2044592\tbest: 0.2044592 (800)\ttotal: 5.07s\tremaining: 13.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1833111\ttest: 0.2023293\tbest: 0.2023168 (899)\ttotal: 5.69s\tremaining: 13.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1788077\ttest: 0.2004554\tbest: 0.2004554 (1000)\ttotal: 6.32s\tremaining: 12.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1744402\ttest: 0.1987730\tbest: 0.1987730 (1100)\ttotal: 6.94s\tremaining: 12s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1705668\ttest: 0.1978270\tbest: 0.1978161 (1195)\ttotal: 7.55s\tremaining: 11.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1671199\ttest: 0.1969814\tbest: 0.1969448 (1294)\ttotal: 8.17s\tremaining: 10.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1636879\ttest: 0.1959962\tbest: 0.1959666 (1396)\ttotal: 8.79s\tremaining: 10s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1604360\ttest: 0.1951836\tbest: 0.1951556 (1492)\ttotal: 9.39s\tremaining: 9.38s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.1575979\ttest: 0.1943290\tbest: 0.1943290 (1600)\ttotal: 10s\tremaining: 8.74s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.1545971\ttest: 0.1937599\tbest: 0.1937524 (1694)\ttotal: 10.6s\tremaining: 8.11s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.1517751\ttest: 0.1932502\tbest: 0.1932218 (1795)\ttotal: 11.2s\tremaining: 7.49s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.1492777\ttest: 0.1928343\tbest: 0.1928184 (1890)\ttotal: 11.9s\tremaining: 6.86s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.1467369\ttest: 0.1927997\tbest: 0.1927789 (1989)\ttotal: 12.5s\tremaining: 6.24s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.1440704\ttest: 0.1921745\tbest: 0.1921745 (2100)\ttotal: 13.1s\tremaining: 5.62s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.1417539\ttest: 0.1917509\tbest: 0.1917271 (2192)\ttotal: 13.8s\tremaining: 5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.1395493\ttest: 0.1911665\tbest: 0.1911665 (2300)\ttotal: 14.4s\tremaining: 4.38s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\tlearn: 0.1374430\ttest: 0.1912695\tbest: 0.1909978 (2360)\ttotal: 15s\tremaining: 3.75s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:05] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:05] bestTest = 0.1909978331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1909978331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:05] bestIteration = 2360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:05] Shrink model to first 2361 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2361 iterations.\n",
            "INFO:optuna.study.study:Trial 1 finished with value: -0.19099786048787096 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 0 with value: -0.18912280810696688.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:05] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -0.19099786048787096 in 0:00:15.776430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -0.19099786048787096 in 0:00:15.776430\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:05] 0:\tlearn: 1.0624554\ttest: 1.0620541\tbest: 1.0620541 (0)\ttotal: 6.04ms\tremaining: 18.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0624554\ttest: 1.0620541\tbest: 1.0620541 (0)\ttotal: 6.04ms\tremaining: 18.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3289384\ttest: 0.3255238\tbest: 0.3255238 (100)\ttotal: 646ms\tremaining: 18.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2596272\ttest: 0.2584164\tbest: 0.2584164 (200)\ttotal: 1.3s\tremaining: 18.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2342258\ttest: 0.2351042\tbest: 0.2351042 (300)\ttotal: 1.94s\tremaining: 17.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2184947\ttest: 0.2218931\tbest: 0.2218931 (400)\ttotal: 2.57s\tremaining: 16.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2079669\ttest: 0.2145449\tbest: 0.2145449 (500)\ttotal: 3.2s\tremaining: 16s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2004692\ttest: 0.2106695\tbest: 0.2106695 (600)\ttotal: 3.83s\tremaining: 15.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1939653\ttest: 0.2072350\tbest: 0.2071800 (699)\ttotal: 4.46s\tremaining: 14.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1883501\ttest: 0.2045734\tbest: 0.2045734 (800)\ttotal: 5.09s\tremaining: 14s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1835038\ttest: 0.2026064\tbest: 0.2026064 (900)\ttotal: 5.71s\tremaining: 13.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1790241\ttest: 0.2007324\tbest: 0.2007261 (995)\ttotal: 6.33s\tremaining: 12.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1747547\ttest: 0.1991993\tbest: 0.1991993 (1100)\ttotal: 6.93s\tremaining: 12s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1708133\ttest: 0.1979733\tbest: 0.1979624 (1195)\ttotal: 7.53s\tremaining: 11.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1672078\ttest: 0.1971758\tbest: 0.1971758 (1300)\ttotal: 8.15s\tremaining: 10.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1636344\ttest: 0.1961600\tbest: 0.1961320 (1396)\ttotal: 8.76s\tremaining: 10s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1603307\ttest: 0.1955764\tbest: 0.1955431 (1492)\ttotal: 9.36s\tremaining: 9.35s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.1574246\ttest: 0.1944669\tbest: 0.1944669 (1600)\ttotal: 9.96s\tremaining: 8.71s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.1543699\ttest: 0.1938956\tbest: 0.1938956 (1700)\ttotal: 10.6s\tremaining: 8.07s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.1516687\ttest: 0.1933394\tbest: 0.1933392 (1799)\ttotal: 11.2s\tremaining: 7.45s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.1491106\ttest: 0.1928617\tbest: 0.1928410 (1890)\ttotal: 11.8s\tremaining: 6.83s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.1465301\ttest: 0.1928534\tbest: 0.1927778 (1978)\ttotal: 12.4s\tremaining: 6.21s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.1439127\ttest: 0.1920448\tbest: 0.1920448 (2100)\ttotal: 13.1s\tremaining: 5.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.1416631\ttest: 0.1918677\tbest: 0.1918543 (2158)\ttotal: 13.7s\tremaining: 4.98s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.1394393\ttest: 0.1911123\tbest: 0.1911123 (2300)\ttotal: 14.3s\tremaining: 4.36s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\tlearn: 0.1372880\ttest: 0.1910142\tbest: 0.1908302 (2360)\ttotal: 15s\tremaining: 3.74s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\tlearn: 0.1351665\ttest: 0.1906967\tbest: 0.1906469 (2494)\ttotal: 15.6s\tremaining: 3.12s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\tlearn: 0.1330816\ttest: 0.1904409\tbest: 0.1904321 (2598)\ttotal: 16.3s\tremaining: 2.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\tlearn: 0.1310238\ttest: 0.1902284\tbest: 0.1902284 (2700)\ttotal: 16.9s\tremaining: 1.87s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\tlearn: 0.1291545\ttest: 0.1900252\tbest: 0.1899858 (2799)\ttotal: 17.5s\tremaining: 1.25s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2900:\tlearn: 0.1272263\ttest: 0.1899149\tbest: 0.1899149 (2900)\ttotal: 18.2s\tremaining: 620ms\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2999:\tlearn: 0.1253463\ttest: 0.1896675\tbest: 0.1895931 (2985)\ttotal: 18.8s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:24] bestTest = 0.1895930882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1895930882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:24] bestIteration = 2985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:24] Shrink model to first 2986 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2986 iterations.\n",
            "INFO:optuna.study.study:Trial 2 finished with value: -0.1895931411542529 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 0 with value: -0.18912280810696688.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:24] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -0.1895931411542529 in 0:00:19.168117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -0.1895931411542529 in 0:00:19.168117\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:24] 0:\tlearn: 1.0624554\ttest: 1.0620541\tbest: 1.0620541 (0)\ttotal: 6.11ms\tremaining: 18.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0624554\ttest: 1.0620541\tbest: 1.0620541 (0)\ttotal: 6.11ms\tremaining: 18.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3264359\ttest: 0.3229839\tbest: 0.3229839 (100)\ttotal: 651ms\tremaining: 18.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2596520\ttest: 0.2581435\tbest: 0.2581435 (200)\ttotal: 1.29s\tremaining: 18s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2340913\ttest: 0.2348082\tbest: 0.2348082 (300)\ttotal: 1.94s\tremaining: 17.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2185102\ttest: 0.2216728\tbest: 0.2216728 (400)\ttotal: 2.57s\tremaining: 16.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2078016\ttest: 0.2142107\tbest: 0.2142107 (500)\ttotal: 3.19s\tremaining: 15.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2004679\ttest: 0.2104344\tbest: 0.2104344 (600)\ttotal: 3.79s\tremaining: 15.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1940048\ttest: 0.2072768\tbest: 0.2072151 (699)\ttotal: 4.39s\tremaining: 14.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1881915\ttest: 0.2043862\tbest: 0.2043862 (800)\ttotal: 5.02s\tremaining: 13.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1832449\ttest: 0.2023329\tbest: 0.2023212 (899)\ttotal: 5.64s\tremaining: 13.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1788385\ttest: 0.2004256\tbest: 0.2003978 (994)\ttotal: 6.29s\tremaining: 12.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1744824\ttest: 0.1986572\tbest: 0.1986572 (1100)\ttotal: 6.92s\tremaining: 11.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1706750\ttest: 0.1975086\tbest: 0.1974977 (1195)\ttotal: 7.53s\tremaining: 11.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1670442\ttest: 0.1965243\tbest: 0.1964960 (1294)\ttotal: 8.16s\tremaining: 10.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1634981\ttest: 0.1955269\tbest: 0.1954963 (1396)\ttotal: 8.8s\tremaining: 10s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1602383\ttest: 0.1947013\tbest: 0.1947013 (1500)\ttotal: 9.44s\tremaining: 9.43s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.1574066\ttest: 0.1939874\tbest: 0.1939874 (1600)\ttotal: 10.1s\tremaining: 8.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.1542789\ttest: 0.1933257\tbest: 0.1933257 (1700)\ttotal: 10.7s\tremaining: 8.16s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.1516845\ttest: 0.1928469\tbest: 0.1928429 (1799)\ttotal: 11.3s\tremaining: 7.53s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.1490575\ttest: 0.1924073\tbest: 0.1923993 (1899)\ttotal: 12s\tremaining: 6.92s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.1465166\ttest: 0.1923198\tbest: 0.1922025 (1967)\ttotal: 12.6s\tremaining: 6.27s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.1438705\ttest: 0.1916908\tbest: 0.1916908 (2100)\ttotal: 13.2s\tremaining: 5.66s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.1415737\ttest: 0.1913522\tbest: 0.1913522 (2200)\ttotal: 13.9s\tremaining: 5.03s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.1393781\ttest: 0.1906186\tbest: 0.1906186 (2300)\ttotal: 14.5s\tremaining: 4.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\tlearn: 0.1373208\ttest: 0.1906925\tbest: 0.1904712 (2360)\ttotal: 15.1s\tremaining: 3.77s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\tlearn: 0.1352184\ttest: 0.1903518\tbest: 0.1903357 (2494)\ttotal: 15.7s\tremaining: 3.14s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\tlearn: 0.1330086\ttest: 0.1901393\tbest: 0.1901312 (2598)\ttotal: 16.4s\tremaining: 2.52s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\tlearn: 0.1308154\ttest: 0.1898799\tbest: 0.1898799 (2700)\ttotal: 17.1s\tremaining: 1.89s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\tlearn: 0.1289951\ttest: 0.1899185\tbest: 0.1898460 (2702)\ttotal: 17.7s\tremaining: 1.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:42] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:42] bestTest = 0.1898460023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1898460023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:42] bestIteration = 2702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:42] Shrink model to first 2703 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2703 iterations.\n",
            "INFO:optuna.study.study:Trial 3 finished with value: -0.189846048155088 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}. Best is trial 0 with value: -0.18912280810696688.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:42] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -0.189846048155088 in 0:00:18.087685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -0.189846048155088 in 0:00:18.087685\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:42] 0:\tlearn: 1.0613718\ttest: 1.0610154\tbest: 1.0610154 (0)\ttotal: 13.3ms\tremaining: 39.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0613718\ttest: 1.0610154\tbest: 1.0610154 (0)\ttotal: 13.3ms\tremaining: 39.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2664819\ttest: 0.2681958\tbest: 0.2681958 (100)\ttotal: 1.25s\tremaining: 35.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2093345\ttest: 0.2203976\tbest: 0.2203976 (200)\ttotal: 2.45s\tremaining: 34.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1863205\ttest: 0.2072185\tbest: 0.2072185 (300)\ttotal: 3.65s\tremaining: 32.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1671637\ttest: 0.1986925\tbest: 0.1986925 (400)\ttotal: 4.81s\tremaining: 31.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1513149\ttest: 0.1935161\tbest: 0.1935137 (499)\ttotal: 5.97s\tremaining: 29.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1378215\ttest: 0.1914067\tbest: 0.1913384 (590)\ttotal: 7.15s\tremaining: 28.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1268067\ttest: 0.1900856\tbest: 0.1900694 (699)\ttotal: 8.31s\tremaining: 27.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1169144\ttest: 0.1885148\tbest: 0.1885148 (800)\ttotal: 9.47s\tremaining: 26s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1082750\ttest: 0.1876412\tbest: 0.1876133 (892)\ttotal: 10.7s\tremaining: 24.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1005003\ttest: 0.1869810\tbest: 0.1869810 (1000)\ttotal: 11.9s\tremaining: 23.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.0934133\ttest: 0.1867951\tbest: 0.1867753 (1097)\ttotal: 13.1s\tremaining: 22.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.0867820\ttest: 0.1865795\tbest: 0.1865449 (1185)\ttotal: 14.3s\tremaining: 21.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.0808684\ttest: 0.1864856\tbest: 0.1862770 (1237)\ttotal: 15.5s\tremaining: 20.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:58] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:58] bestTest = 0.1862770408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1862770408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:58] bestIteration = 1237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:58] Shrink model to first 1238 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1238 iterations.\n",
            "INFO:optuna.study.study:Trial 4 finished with value: -0.18627708877424343 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10}. Best is trial 4 with value: -0.18627708877424343.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:59] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -0.18627708877424343 in 0:00:16.212394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -0.18627708877424343 in 0:00:16.212394\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:59] 0:\tlearn: 1.0613731\ttest: 1.0610162\tbest: 1.0610162 (0)\ttotal: 15.1ms\tremaining: 45.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0613731\ttest: 1.0610162\tbest: 1.0610162 (0)\ttotal: 15.1ms\tremaining: 45.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2664920\ttest: 0.2682033\tbest: 0.2682033 (100)\ttotal: 1.21s\tremaining: 34.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2093658\ttest: 0.2204068\tbest: 0.2204068 (200)\ttotal: 2.41s\tremaining: 33.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1863724\ttest: 0.2072353\tbest: 0.2072353 (300)\ttotal: 3.6s\tremaining: 32.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1671933\ttest: 0.1985342\tbest: 0.1985342 (400)\ttotal: 4.77s\tremaining: 30.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1514784\ttest: 0.1939339\tbest: 0.1939339 (500)\ttotal: 5.94s\tremaining: 29.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1378813\ttest: 0.1920471\tbest: 0.1920442 (599)\ttotal: 7.12s\tremaining: 28.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1267668\ttest: 0.1904390\tbest: 0.1904183 (699)\ttotal: 8.29s\tremaining: 27.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1168327\ttest: 0.1886641\tbest: 0.1886437 (798)\ttotal: 9.52s\tremaining: 26.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1082868\ttest: 0.1876784\tbest: 0.1876784 (900)\ttotal: 10.7s\tremaining: 24.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1003732\ttest: 0.1870078\tbest: 0.1870078 (1000)\ttotal: 11.9s\tremaining: 23.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.0931631\ttest: 0.1867079\tbest: 0.1866356 (1032)\ttotal: 13.1s\tremaining: 22.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:12] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:12] bestTest = 0.1866355845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1866355845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:12] bestIteration = 1032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:12] Shrink model to first 1033 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1033 iterations.\n",
            "INFO:optuna.study.study:Trial 5 finished with value: -0.18663558860887955 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1}. Best is trial 4 with value: -0.18627708877424343.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:12] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -0.18663558860887955 in 0:00:13.887550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -0.18663558860887955 in 0:00:13.887550\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:13] 0:\tlearn: 1.0627856\ttest: 1.0622787\tbest: 1.0622787 (0)\ttotal: 14.1ms\tremaining: 42.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0627856\ttest: 1.0622787\tbest: 1.0622787 (0)\ttotal: 14.1ms\tremaining: 42.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2737183\ttest: 0.2740241\tbest: 0.2740241 (100)\ttotal: 1.25s\tremaining: 36s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2179599\ttest: 0.2241943\tbest: 0.2241943 (200)\ttotal: 2.46s\tremaining: 34.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1994069\ttest: 0.2115260\tbest: 0.2115260 (300)\ttotal: 3.63s\tremaining: 32.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1846030\ttest: 0.2035513\tbest: 0.2035513 (400)\ttotal: 4.79s\tremaining: 31s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1738135\ttest: 0.1989449\tbest: 0.1989449 (500)\ttotal: 5.93s\tremaining: 29.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1644631\ttest: 0.1963892\tbest: 0.1963820 (599)\ttotal: 7.07s\tremaining: 28.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1568324\ttest: 0.1949832\tbest: 0.1949781 (693)\ttotal: 8.2s\tremaining: 26.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1489488\ttest: 0.1933053\tbest: 0.1932956 (797)\ttotal: 9.35s\tremaining: 25.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1418414\ttest: 0.1916671\tbest: 0.1916389 (896)\ttotal: 10.5s\tremaining: 24.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1353715\ttest: 0.1903591\tbest: 0.1903591 (1000)\ttotal: 11.7s\tremaining: 23.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1294419\ttest: 0.1893594\tbest: 0.1893255 (1099)\ttotal: 12.8s\tremaining: 22.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1243627\ttest: 0.1889788\tbest: 0.1888737 (1172)\ttotal: 13.9s\tremaining: 20.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1198125\ttest: 0.1882096\tbest: 0.1882096 (1300)\ttotal: 15.1s\tremaining: 19.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1151022\ttest: 0.1873983\tbest: 0.1873782 (1396)\ttotal: 16.3s\tremaining: 18.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1107083\ttest: 0.1868493\tbest: 0.1868493 (1500)\ttotal: 17.4s\tremaining: 17.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.1067277\ttest: 0.1862826\tbest: 0.1862826 (1600)\ttotal: 18.6s\tremaining: 16.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.1028577\ttest: 0.1863894\tbest: 0.1862683 (1607)\ttotal: 19.8s\tremaining: 15.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:33] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:33] bestTest = 0.1862682797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1862682797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:33] bestIteration = 1607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:33] Shrink model to first 1608 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1608 iterations.\n",
            "INFO:optuna.study.study:Trial 6 finished with value: -0.1862682745140232 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20}. Best is trial 6 with value: -0.1862682745140232.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:33] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -0.1862682745140232 in 0:00:20.225180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -0.1862682745140232 in 0:00:20.225180\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:33] 0:\tlearn: 1.0611981\ttest: 1.0609018\tbest: 1.0609018 (0)\ttotal: 19.2ms\tremaining: 57.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0611981\ttest: 1.0609018\tbest: 1.0609018 (0)\ttotal: 19.2ms\tremaining: 57.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2548184\ttest: 0.2596294\tbest: 0.2596294 (100)\ttotal: 1.68s\tremaining: 48.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1971046\ttest: 0.2158623\tbest: 0.2158623 (200)\ttotal: 3.33s\tremaining: 46.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1712639\ttest: 0.2048724\tbest: 0.2048724 (300)\ttotal: 4.99s\tremaining: 44.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1467017\ttest: 0.1958210\tbest: 0.1958210 (400)\ttotal: 6.62s\tremaining: 42.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1282433\ttest: 0.1927265\tbest: 0.1926277 (480)\ttotal: 8.3s\tremaining: 41.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1129313\ttest: 0.1907426\tbest: 0.1906587 (597)\ttotal: 9.94s\tremaining: 39.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1002274\ttest: 0.1888164\tbest: 0.1887493 (695)\ttotal: 11.6s\tremaining: 37.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.0894417\ttest: 0.1881794\tbest: 0.1881298 (797)\ttotal: 13.2s\tremaining: 36.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.0799248\ttest: 0.1875755\tbest: 0.1874744 (884)\ttotal: 16.4s\tremaining: 38.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.0715149\ttest: 0.1867906\tbest: 0.1867125 (998)\ttotal: 18.8s\tremaining: 37.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.0644412\ttest: 0.1866648\tbest: 0.1863967 (1086)\ttotal: 20.5s\tremaining: 35.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:55] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:55] bestTest = 0.1863967421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1863967421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:55] bestIteration = 1086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:55] Shrink model to first 1087 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1087 iterations.\n",
            "INFO:optuna.study.study:Trial 7 finished with value: -0.1863967365969348 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9}. Best is trial 6 with value: -0.1862682745140232.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:55] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -0.1863967365969348 in 0:00:22.223097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -0.1863967365969348 in 0:00:22.223097\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:55] 0:\tlearn: 1.0625779\ttest: 1.0621807\tbest: 1.0621807 (0)\ttotal: 6.3ms\tremaining: 18.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0625779\ttest: 1.0621807\tbest: 1.0621807 (0)\ttotal: 6.3ms\tremaining: 18.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3279140\ttest: 0.3245684\tbest: 0.3245684 (100)\ttotal: 642ms\tremaining: 18.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2602201\ttest: 0.2586589\tbest: 0.2586589 (200)\ttotal: 1.29s\tremaining: 17.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2353094\ttest: 0.2359388\tbest: 0.2359388 (300)\ttotal: 1.93s\tremaining: 17.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2199854\ttest: 0.2226103\tbest: 0.2226103 (400)\ttotal: 2.57s\tremaining: 16.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2103149\ttest: 0.2152998\tbest: 0.2152998 (500)\ttotal: 3.2s\tremaining: 16s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2038167\ttest: 0.2116669\tbest: 0.2116669 (600)\ttotal: 3.78s\tremaining: 15.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1984224\ttest: 0.2084444\tbest: 0.2084444 (700)\ttotal: 4.37s\tremaining: 14.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1937665\ttest: 0.2058291\tbest: 0.2058291 (800)\ttotal: 5.01s\tremaining: 13.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1895467\ttest: 0.2040841\tbest: 0.2040592 (899)\ttotal: 5.64s\tremaining: 13.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1858108\ttest: 0.2022500\tbest: 0.2022500 (1000)\ttotal: 6.29s\tremaining: 12.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1817576\ttest: 0.2007530\tbest: 0.2007395 (1098)\ttotal: 6.92s\tremaining: 11.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1784450\ttest: 0.1996130\tbest: 0.1995741 (1197)\ttotal: 7.55s\tremaining: 11.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1753862\ttest: 0.1985761\tbest: 0.1985761 (1300)\ttotal: 8.19s\tremaining: 10.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1725860\ttest: 0.1975642\tbest: 0.1975401 (1396)\ttotal: 8.82s\tremaining: 10.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1697961\ttest: 0.1968368\tbest: 0.1968368 (1500)\ttotal: 9.46s\tremaining: 9.45s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.1671869\ttest: 0.1960110\tbest: 0.1960110 (1600)\ttotal: 10.1s\tremaining: 8.81s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.1644508\ttest: 0.1950883\tbest: 0.1950883 (1700)\ttotal: 10.7s\tremaining: 8.17s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.1621008\ttest: 0.1945843\tbest: 0.1945734 (1799)\ttotal: 11.3s\tremaining: 7.54s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.1597800\ttest: 0.1939582\tbest: 0.1939582 (1900)\ttotal: 11.9s\tremaining: 6.89s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2000:\tlearn: 0.1575466\ttest: 0.1936468\tbest: 0.1936331 (1975)\ttotal: 12.5s\tremaining: 6.26s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2100:\tlearn: 0.1551396\ttest: 0.1929154\tbest: 0.1929154 (2100)\ttotal: 13.2s\tremaining: 5.64s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2200:\tlearn: 0.1530884\ttest: 0.1926332\tbest: 0.1926185 (2158)\ttotal: 13.8s\tremaining: 5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2300:\tlearn: 0.1511105\ttest: 0.1920109\tbest: 0.1920016 (2299)\ttotal: 14.4s\tremaining: 4.38s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2400:\tlearn: 0.1492181\ttest: 0.1918064\tbest: 0.1916054 (2360)\ttotal: 15s\tremaining: 3.75s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2500:\tlearn: 0.1472884\ttest: 0.1914198\tbest: 0.1913794 (2494)\ttotal: 15.7s\tremaining: 3.13s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2600:\tlearn: 0.1452994\ttest: 0.1910606\tbest: 0.1910514 (2599)\ttotal: 16.3s\tremaining: 2.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2700:\tlearn: 0.1433244\ttest: 0.1907852\tbest: 0.1907787 (2686)\ttotal: 16.9s\tremaining: 1.87s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2800:\tlearn: 0.1416950\ttest: 0.1903796\tbest: 0.1903739 (2799)\ttotal: 17.5s\tremaining: 1.24s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2900:\tlearn: 0.1399534\ttest: 0.1902084\tbest: 0.1902005 (2870)\ttotal: 18.1s\tremaining: 619ms\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:2999:\tlearn: 0.1381413\ttest: 0.1902319\tbest: 0.1901288 (2977)\ttotal: 18.7s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:14] bestTest = 0.1901287969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1901287969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:14] bestIteration = 2977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:14] Shrink model to first 2978 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2978 iterations.\n",
            "INFO:optuna.study.study:Trial 8 finished with value: -0.19012879122173063 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6}. Best is trial 6 with value: -0.1862682745140232.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:14] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -0.19012879122173063 in 0:00:19.150608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -0.19012879122173063 in 0:00:19.150608\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:14] 0:\tlearn: 1.0613723\ttest: 1.0610157\tbest: 1.0610157 (0)\ttotal: 11.8ms\tremaining: 35.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0613723\ttest: 1.0610157\tbest: 1.0610157 (0)\ttotal: 11.8ms\tremaining: 35.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2664858\ttest: 0.2681987\tbest: 0.2681987 (100)\ttotal: 1.21s\tremaining: 34.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2093467\ttest: 0.2204012\tbest: 0.2204012 (200)\ttotal: 2.4s\tremaining: 33.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1863412\ttest: 0.2072253\tbest: 0.2072253 (300)\ttotal: 3.61s\tremaining: 32.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1673204\ttest: 0.1987868\tbest: 0.1987868 (400)\ttotal: 4.79s\tremaining: 31.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1516538\ttest: 0.1937239\tbest: 0.1937207 (499)\ttotal: 6s\tremaining: 29.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1381163\ttest: 0.1913278\tbest: 0.1913073 (599)\ttotal: 7.19s\tremaining: 28.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1268140\ttest: 0.1894634\tbest: 0.1894482 (699)\ttotal: 8.36s\tremaining: 27.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1168289\ttest: 0.1880487\tbest: 0.1880487 (800)\ttotal: 9.52s\tremaining: 26.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1081946\ttest: 0.1870855\tbest: 0.1870626 (897)\ttotal: 10.7s\tremaining: 24.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1003252\ttest: 0.1862432\tbest: 0.1862432 (1000)\ttotal: 11.9s\tremaining: 23.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.0934418\ttest: 0.1857596\tbest: 0.1857596 (1100)\ttotal: 13s\tremaining: 22.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.0869434\ttest: 0.1857513\tbest: 0.1854801 (1156)\ttotal: 14.2s\tremaining: 21.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.0811201\ttest: 0.1855616\tbest: 0.1854154 (1238)\ttotal: 15.4s\tremaining: 20.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:30] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:30] bestTest = 0.1854153861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1854153861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:30] bestIteration = 1238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:30] Shrink model to first 1239 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1239 iterations.\n",
            "INFO:optuna.study.study:Trial 9 finished with value: -0.18541541921882848 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4}. Best is trial 9 with value: -0.18541541921882848.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:30] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -0.18541541921882848 in 0:00:16.178277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -0.18541541921882848 in 0:00:16.178277\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:30] 0:\tlearn: 1.0615035\ttest: 1.0610793\tbest: 1.0610793 (0)\ttotal: 10ms\tremaining: 30.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0615035\ttest: 1.0610793\tbest: 1.0610793 (0)\ttotal: 10ms\tremaining: 30.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2791703\ttest: 0.2793283\tbest: 0.2793283 (100)\ttotal: 970ms\tremaining: 27.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2235731\ttest: 0.2293205\tbest: 0.2293205 (200)\ttotal: 1.9s\tremaining: 26.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2036401\ttest: 0.2160559\tbest: 0.2160559 (300)\ttotal: 2.81s\tremaining: 25.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1853122\ttest: 0.2054912\tbest: 0.2054912 (400)\ttotal: 3.72s\tremaining: 24.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1720279\ttest: 0.2006599\tbest: 0.2006599 (500)\ttotal: 4.59s\tremaining: 22.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1614156\ttest: 0.1975791\tbest: 0.1975763 (598)\ttotal: 5.5s\tremaining: 21.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1521455\ttest: 0.1956559\tbest: 0.1956559 (700)\ttotal: 6.4s\tremaining: 21s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1438008\ttest: 0.1937014\tbest: 0.1936411 (799)\ttotal: 7.32s\tremaining: 20.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1362636\ttest: 0.1932480\tbest: 0.1932255 (898)\ttotal: 8.23s\tremaining: 19.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1292717\ttest: 0.1922303\tbest: 0.1922303 (1000)\ttotal: 9.13s\tremaining: 18.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1226241\ttest: 0.1906041\tbest: 0.1905834 (1096)\ttotal: 10s\tremaining: 17.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1169566\ttest: 0.1900310\tbest: 0.1899568 (1187)\ttotal: 10.9s\tremaining: 16.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1115296\ttest: 0.1893785\tbest: 0.1893338 (1293)\ttotal: 11.8s\tremaining: 15.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1064728\ttest: 0.1890097\tbest: 0.1888312 (1389)\ttotal: 12.7s\tremaining: 14.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1018624\ttest: 0.1880453\tbest: 0.1879688 (1498)\ttotal: 13.6s\tremaining: 13.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.0972341\ttest: 0.1878491\tbest: 0.1878162 (1599)\ttotal: 14.5s\tremaining: 12.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.0930041\ttest: 0.1878832\tbest: 0.1878144 (1693)\ttotal: 15.4s\tremaining: 11.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:47] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:47] bestTest = 0.1878144098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1878144098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:47] bestIteration = 1693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:47] Shrink model to first 1694 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1694 iterations.\n",
            "INFO:optuna.study.study:Trial 10 finished with value: -0.1878144655921538 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.1692997958212103e-08, 'min_data_in_leaf': 14}. Best is trial 9 with value: -0.18541541921882848.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:47] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.1692997958212103e-08, 'min_data_in_leaf': 14} scored -0.1878144655921538 in 0:00:16.642992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.1692997958212103e-08, 'min_data_in_leaf': 14} scored -0.1878144655921538 in 0:00:16.642992\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:20:47] 0:\tlearn: 1.0635343\ttest: 1.0630124\tbest: 1.0630124 (0)\ttotal: 12.3ms\tremaining: 36.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0635343\ttest: 1.0630124\tbest: 1.0630124 (0)\ttotal: 12.3ms\tremaining: 36.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2792186\ttest: 0.2789002\tbest: 0.2789002 (100)\ttotal: 1.25s\tremaining: 35.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2222617\ttest: 0.2271631\tbest: 0.2271631 (200)\ttotal: 2.45s\tremaining: 34.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2030681\ttest: 0.2138554\tbest: 0.2138554 (300)\ttotal: 3.67s\tremaining: 32.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1888510\ttest: 0.2056869\tbest: 0.2056869 (400)\ttotal: 4.87s\tremaining: 31.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1793095\ttest: 0.2017119\tbest: 0.2017119 (500)\ttotal: 6.02s\tremaining: 30s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1712515\ttest: 0.1991752\tbest: 0.1991752 (600)\ttotal: 7.19s\tremaining: 28.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1638062\ttest: 0.1973500\tbest: 0.1973413 (699)\ttotal: 8.32s\tremaining: 27.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1567977\ttest: 0.1952050\tbest: 0.1951798 (799)\ttotal: 9.46s\tremaining: 26s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1504391\ttest: 0.1935101\tbest: 0.1935101 (900)\ttotal: 10.6s\tremaining: 24.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1445604\ttest: 0.1924499\tbest: 0.1924370 (995)\ttotal: 11.8s\tremaining: 23.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1393687\ttest: 0.1913005\tbest: 0.1912141 (1097)\ttotal: 12.9s\tremaining: 22.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1347750\ttest: 0.1907768\tbest: 0.1907194 (1195)\ttotal: 14.1s\tremaining: 21.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1299993\ttest: 0.1900420\tbest: 0.1900081 (1293)\ttotal: 15.3s\tremaining: 19.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1256304\ttest: 0.1894826\tbest: 0.1894826 (1400)\ttotal: 16.4s\tremaining: 18.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1214506\ttest: 0.1890974\tbest: 0.1890848 (1498)\ttotal: 17.6s\tremaining: 17.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.1176450\ttest: 0.1885093\tbest: 0.1884810 (1598)\ttotal: 18.8s\tremaining: 16.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.1140125\ttest: 0.1883287\tbest: 0.1882024 (1667)\ttotal: 20s\tremaining: 15.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1800:\tlearn: 0.1102840\ttest: 0.1879863\tbest: 0.1879863 (1800)\ttotal: 21.1s\tremaining: 14.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1900:\tlearn: 0.1069529\ttest: 0.1881796\tbest: 0.1879863 (1800)\ttotal: 22.3s\tremaining: 12.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:09] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:10] bestTest = 0.1879862888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1879862888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:10] bestIteration = 1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:10] Shrink model to first 1801 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1801 iterations.\n",
            "INFO:optuna.study.study:Trial 11 finished with value: -0.18798628305633897 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 5.987183831503271, 'min_data_in_leaf': 20}. Best is trial 9 with value: -0.18541541921882848.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:10] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 5.987183831503271, 'min_data_in_leaf': 20} scored -0.18798628305633897 in 0:00:22.653311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 5.987183831503271, 'min_data_in_leaf': 20} scored -0.18798628305633897 in 0:00:22.653311\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:10] 0:\tlearn: 1.0613154\ttest: 1.0609878\tbest: 1.0609878 (0)\ttotal: 17.3ms\tremaining: 52s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0613154\ttest: 1.0609878\tbest: 1.0609878 (0)\ttotal: 17.3ms\tremaining: 52s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2557330\ttest: 0.2601298\tbest: 0.2601298 (100)\ttotal: 1.71s\tremaining: 49s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1980554\ttest: 0.2161508\tbest: 0.2161508 (200)\ttotal: 3.38s\tremaining: 47s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1732977\ttest: 0.2056410\tbest: 0.2056410 (300)\ttotal: 4.98s\tremaining: 44.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1505376\ttest: 0.1975989\tbest: 0.1975989 (400)\ttotal: 6.61s\tremaining: 42.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1325996\ttest: 0.1937657\tbest: 0.1937657 (500)\ttotal: 8.28s\tremaining: 41.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1180859\ttest: 0.1915760\tbest: 0.1915760 (600)\ttotal: 9.96s\tremaining: 39.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1059539\ttest: 0.1895402\tbest: 0.1894637 (698)\ttotal: 11.6s\tremaining: 38s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.0950571\ttest: 0.1885189\tbest: 0.1885189 (800)\ttotal: 13.2s\tremaining: 36.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.0856853\ttest: 0.1883843\tbest: 0.1883843 (900)\ttotal: 14.9s\tremaining: 34.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.0771748\ttest: 0.1878249\tbest: 0.1877082 (997)\ttotal: 16.5s\tremaining: 33s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.0702752\ttest: 0.1875171\tbest: 0.1873922 (1051)\ttotal: 18.1s\tremaining: 31.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:29] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:29] bestTest = 0.1873921866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1873921866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:29] bestIteration = 1051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:29] Shrink model to first 1052 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1052 iterations.\n",
            "INFO:optuna.study.study:Trial 12 finished with value: -0.18739218123111917 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.14169449304267856, 'min_data_in_leaf': 19}. Best is trial 9 with value: -0.18541541921882848.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:29] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.14169449304267856, 'min_data_in_leaf': 19} scored -0.18739218123111917 in 0:00:19.323976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.14169449304267856, 'min_data_in_leaf': 19} scored -0.18739218123111917 in 0:00:19.323976\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:29] 0:\tlearn: 1.0615599\ttest: 1.0611270\tbest: 1.0611270 (0)\ttotal: 9.63ms\tremaining: 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0615599\ttest: 1.0611270\tbest: 1.0611270 (0)\ttotal: 9.63ms\tremaining: 28.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2796156\ttest: 0.2796390\tbest: 0.2796390 (100)\ttotal: 960ms\tremaining: 27.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2242869\ttest: 0.2295636\tbest: 0.2295636 (200)\ttotal: 1.92s\tremaining: 26.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2044611\ttest: 0.2161654\tbest: 0.2161654 (300)\ttotal: 2.83s\tremaining: 25.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1865583\ttest: 0.2057838\tbest: 0.2057838 (400)\ttotal: 3.76s\tremaining: 24.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1738299\ttest: 0.2005662\tbest: 0.2005662 (500)\ttotal: 4.65s\tremaining: 23.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1637320\ttest: 0.1976406\tbest: 0.1976406 (600)\ttotal: 5.56s\tremaining: 22.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1548883\ttest: 0.1955680\tbest: 0.1955524 (699)\ttotal: 6.44s\tremaining: 21.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1467935\ttest: 0.1934992\tbest: 0.1934645 (798)\ttotal: 7.37s\tremaining: 20.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1400082\ttest: 0.1929568\tbest: 0.1929116 (895)\ttotal: 8.25s\tremaining: 19.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1331853\ttest: 0.1919942\tbest: 0.1919921 (994)\ttotal: 9.13s\tremaining: 18.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1267773\ttest: 0.1908634\tbest: 0.1908076 (1094)\ttotal: 10s\tremaining: 17.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1208313\ttest: 0.1900099\tbest: 0.1898541 (1187)\ttotal: 11s\tremaining: 16.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1156643\ttest: 0.1895777\tbest: 0.1895071 (1293)\ttotal: 11.9s\tremaining: 15.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1108131\ttest: 0.1889648\tbest: 0.1888454 (1389)\ttotal: 12.8s\tremaining: 14.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1061921\ttest: 0.1881111\tbest: 0.1880807 (1499)\ttotal: 13.7s\tremaining: 13.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.1018192\ttest: 0.1878156\tbest: 0.1877869 (1599)\ttotal: 14.6s\tremaining: 12.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.0977156\ttest: 0.1878370\tbest: 0.1877068 (1630)\ttotal: 15.4s\tremaining: 11.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:45] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:45] bestTest = 0.1877068022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1877068022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:45] bestIteration = 1630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:45] Shrink model to first 1631 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1631 iterations.\n",
            "INFO:optuna.study.study:Trial 13 finished with value: -0.18770679656088987 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.1664219734579358, 'min_data_in_leaf': 14}. Best is trial 9 with value: -0.18541541921882848.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:45] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.1664219734579358, 'min_data_in_leaf': 14} scored -0.18770679656088987 in 0:00:16.088072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.1664219734579358, 'min_data_in_leaf': 14} scored -0.18770679656088987 in 0:00:16.088072\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:45] 0:\tlearn: 1.0613718\ttest: 1.0610153\tbest: 1.0610153 (0)\ttotal: 13ms\tremaining: 38.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0613718\ttest: 1.0610153\tbest: 1.0610153 (0)\ttotal: 13ms\tremaining: 38.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2664494\ttest: 0.2681863\tbest: 0.2681863 (100)\ttotal: 1.22s\tremaining: 35.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2091915\ttest: 0.2204102\tbest: 0.2204102 (200)\ttotal: 2.45s\tremaining: 34.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1864092\ttest: 0.2076770\tbest: 0.2076770 (300)\ttotal: 3.67s\tremaining: 32.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1666850\ttest: 0.1988321\tbest: 0.1988321 (400)\ttotal: 4.86s\tremaining: 31.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1513635\ttest: 0.1942526\tbest: 0.1942406 (498)\ttotal: 6.06s\tremaining: 30.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1380845\ttest: 0.1923481\tbest: 0.1923155 (592)\ttotal: 7.24s\tremaining: 28.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1271729\ttest: 0.1909325\tbest: 0.1909154 (699)\ttotal: 8.42s\tremaining: 27.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1171429\ttest: 0.1887071\tbest: 0.1886758 (799)\ttotal: 9.61s\tremaining: 26.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1085629\ttest: 0.1879276\tbest: 0.1879276 (900)\ttotal: 10.8s\tremaining: 25.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1005392\ttest: 0.1869621\tbest: 0.1869621 (1000)\ttotal: 12s\tremaining: 23.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.0933536\ttest: 0.1863213\tbest: 0.1862922 (1097)\ttotal: 13.2s\tremaining: 22.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.0868478\ttest: 0.1860482\tbest: 0.1859835 (1189)\ttotal: 14.3s\tremaining: 21.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:01] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:01] bestTest = 0.1859834739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1859834739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:01] bestIteration = 1189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:01] Shrink model to first 1190 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1190 iterations.\n",
            "INFO:optuna.study.study:Trial 14 finished with value: -0.18598352028476264 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 2.528830125346676e-06, 'min_data_in_leaf': 17}. Best is trial 9 with value: -0.18541541921882848.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:01] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 2.528830125346676e-06, 'min_data_in_leaf': 17} scored -0.18598352028476264 in 0:00:15.778631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 2.528830125346676e-06, 'min_data_in_leaf': 17} scored -0.18598352028476264 in 0:00:15.778631\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:01] 0:\tlearn: 1.0611639\ttest: 1.0609382\tbest: 1.0609382 (0)\ttotal: 17.5ms\tremaining: 52.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0611639\ttest: 1.0609382\tbest: 1.0609382 (0)\ttotal: 17.5ms\tremaining: 52.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2545337\ttest: 0.2596147\tbest: 0.2596147 (100)\ttotal: 1.76s\tremaining: 50.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1963123\ttest: 0.2161236\tbest: 0.2161236 (200)\ttotal: 3.48s\tremaining: 48.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1697801\ttest: 0.2047695\tbest: 0.2047695 (300)\ttotal: 5.17s\tremaining: 46.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1457063\ttest: 0.1966156\tbest: 0.1966156 (400)\ttotal: 6.83s\tremaining: 44.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1270047\ttest: 0.1922110\tbest: 0.1921483 (499)\ttotal: 8.55s\tremaining: 42.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1117189\ttest: 0.1898230\tbest: 0.1898230 (600)\ttotal: 10.2s\tremaining: 40.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.0985748\ttest: 0.1881921\tbest: 0.1881559 (698)\ttotal: 11.9s\tremaining: 39s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.0879776\ttest: 0.1872611\tbest: 0.1871685 (792)\ttotal: 13.5s\tremaining: 37.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.0785104\ttest: 0.1867218\tbest: 0.1866475 (875)\ttotal: 15.2s\tremaining: 35.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.0700470\ttest: 0.1863285\tbest: 0.1862905 (970)\ttotal: 16.9s\tremaining: 33.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.0627549\ttest: 0.1866866\tbest: 0.1862629 (1036)\ttotal: 18.6s\tremaining: 32.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20] bestTest = 0.1862629295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1862629295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20] bestIteration = 1036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20] Shrink model to first 1037 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1037 iterations.\n",
            "INFO:optuna.study.study:Trial 15 finished with value: -0.18626297894034008 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 2.5297723748825442e-06, 'min_data_in_leaf': 17}. Best is trial 9 with value: -0.18541541921882848.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 2.5297723748825442e-06, 'min_data_in_leaf': 17} scored -0.18626297894034008 in 0:00:19.586979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 2.5297723748825442e-06, 'min_data_in_leaf': 17} scored -0.18626297894034008 in 0:00:19.586979\n",
            "/usr/local/lib/python3.7/dist-packages/lightautoml/ml_algo/tuning/optuna.py:232: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  name=parameter, **SearchSpace.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:21] 0:\tlearn: 1.0615035\ttest: 1.0610793\tbest: 1.0610793 (0)\ttotal: 9.81ms\tremaining: 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0615035\ttest: 1.0610793\tbest: 1.0610793 (0)\ttotal: 9.81ms\tremaining: 29.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2791703\ttest: 0.2793283\tbest: 0.2793283 (100)\ttotal: 981ms\tremaining: 28.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2235731\ttest: 0.2293205\tbest: 0.2293205 (200)\ttotal: 1.93s\tremaining: 26.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2036401\ttest: 0.2160559\tbest: 0.2160559 (300)\ttotal: 2.88s\tremaining: 25.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1853122\ttest: 0.2054912\tbest: 0.2054912 (400)\ttotal: 3.8s\tremaining: 24.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1720279\ttest: 0.2006599\tbest: 0.2006599 (500)\ttotal: 4.76s\tremaining: 23.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1614156\ttest: 0.1975791\tbest: 0.1975763 (598)\ttotal: 5.63s\tremaining: 22.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1521455\ttest: 0.1956559\tbest: 0.1956559 (700)\ttotal: 6.53s\tremaining: 21.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1438009\ttest: 0.1937014\tbest: 0.1936411 (799)\ttotal: 7.45s\tremaining: 20.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1362636\ttest: 0.1932480\tbest: 0.1932255 (898)\ttotal: 8.58s\tremaining: 20s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1292717\ttest: 0.1922303\tbest: 0.1922303 (1000)\ttotal: 10.8s\tremaining: 21.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.1226241\ttest: 0.1906041\tbest: 0.1905834 (1096)\ttotal: 12.6s\tremaining: 21.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.1169566\ttest: 0.1900310\tbest: 0.1899568 (1187)\ttotal: 13.5s\tremaining: 20.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.1115296\ttest: 0.1893785\tbest: 0.1893338 (1293)\ttotal: 14.4s\tremaining: 18.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.1064728\ttest: 0.1890097\tbest: 0.1888312 (1389)\ttotal: 15.3s\tremaining: 17.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.1018624\ttest: 0.1880457\tbest: 0.1879691 (1498)\ttotal: 16.2s\tremaining: 16.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1600:\tlearn: 0.0972341\ttest: 0.1878494\tbest: 0.1878165 (1599)\ttotal: 17.1s\tremaining: 15s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1700:\tlearn: 0.0930041\ttest: 0.1878835\tbest: 0.1878148 (1693)\ttotal: 18s\tremaining: 13.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:40] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:40] bestTest = 0.1878147724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1878147724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:40] bestIteration = 1693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:40] Shrink model to first 1694 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1694 iterations.\n",
            "INFO:optuna.study.study:Trial 16 finished with value: -0.18781482872364635 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 8.505946250821973e-08, 'min_data_in_leaf': 12}. Best is trial 9 with value: -0.18541541921882848.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:40] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 8.505946250821973e-08, 'min_data_in_leaf': 12} scored -0.18781482872364635 in 0:00:19.245279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 8.505946250821973e-08, 'min_data_in_leaf': 12} scored -0.18781482872364635 in 0:00:19.245279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:40] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:40] The set of hyperparameters \u001b[1m{'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4}\u001b[0m\n",
            " achieve -0.1854 crossentropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4}\u001b[0m\n",
            " achieve -0.1854 crossentropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.0008325158565947976, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 6, 'min_data_in_leaf': 4, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:40] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:40] 0:\tlearn: 1.0613723\ttest: 1.0610157\tbest: 1.0610157 (0)\ttotal: 12.7ms\tremaining: 38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0613723\ttest: 1.0610157\tbest: 1.0610157 (0)\ttotal: 12.7ms\tremaining: 38s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2664858\ttest: 0.2681987\tbest: 0.2681987 (100)\ttotal: 1.26s\tremaining: 36.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2093467\ttest: 0.2204012\tbest: 0.2204012 (200)\ttotal: 2.5s\tremaining: 34.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1863412\ttest: 0.2072253\tbest: 0.2072253 (300)\ttotal: 3.7s\tremaining: 33.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1673204\ttest: 0.1987868\tbest: 0.1987868 (400)\ttotal: 4.86s\tremaining: 31.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1516538\ttest: 0.1937239\tbest: 0.1937207 (499)\ttotal: 6.06s\tremaining: 30.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1381163\ttest: 0.1913278\tbest: 0.1913073 (599)\ttotal: 7.26s\tremaining: 29s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1268140\ttest: 0.1894634\tbest: 0.1894482 (699)\ttotal: 8.47s\tremaining: 27.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1168289\ttest: 0.1880487\tbest: 0.1880487 (800)\ttotal: 9.68s\tremaining: 26.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1081946\ttest: 0.1870855\tbest: 0.1870626 (897)\ttotal: 10.9s\tremaining: 25.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1003252\ttest: 0.1862432\tbest: 0.1862432 (1000)\ttotal: 12.1s\tremaining: 24.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.0934418\ttest: 0.1857596\tbest: 0.1857596 (1100)\ttotal: 13.3s\tremaining: 22.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.0869434\ttest: 0.1857513\tbest: 0.1854801 (1156)\ttotal: 14.5s\tremaining: 21.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.0811201\ttest: 0.1855616\tbest: 0.1854154 (1238)\ttotal: 15.7s\tremaining: 20.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:56] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:56] bestTest = 0.1854153861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1854153861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:56] bestIteration = 1238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:56] Shrink model to first 1239 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1239 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:56] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:56] 0:\tlearn: 1.0613650\ttest: 1.0613828\tbest: 1.0613828 (0)\ttotal: 12.9ms\tremaining: 38.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0613650\ttest: 1.0613828\tbest: 1.0613828 (0)\ttotal: 12.9ms\tremaining: 38.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2650523\ttest: 0.2672807\tbest: 0.2672807 (100)\ttotal: 1.22s\tremaining: 35s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2083764\ttest: 0.2203734\tbest: 0.2203734 (200)\ttotal: 2.41s\tremaining: 33.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1864333\ttest: 0.2096935\tbest: 0.2096935 (300)\ttotal: 3.58s\tremaining: 32.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1671033\ttest: 0.2015516\tbest: 0.2015516 (400)\ttotal: 4.72s\tremaining: 30.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1518256\ttest: 0.1962405\tbest: 0.1962405 (500)\ttotal: 5.9s\tremaining: 29.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1386964\ttest: 0.1926297\tbest: 0.1926297 (600)\ttotal: 7.07s\tremaining: 28.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1275408\ttest: 0.1904861\tbest: 0.1904861 (700)\ttotal: 8.24s\tremaining: 27s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1178773\ttest: 0.1891318\tbest: 0.1891318 (800)\ttotal: 9.41s\tremaining: 25.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1091038\ttest: 0.1878205\tbest: 0.1876912 (895)\ttotal: 10.6s\tremaining: 24.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1009501\ttest: 0.1865399\tbest: 0.1864886 (995)\ttotal: 11.8s\tremaining: 23.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.0938286\ttest: 0.1857829\tbest: 0.1856514 (1086)\ttotal: 12.9s\tremaining: 22.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.0872945\ttest: 0.1854111\tbest: 0.1853467 (1168)\ttotal: 14.1s\tremaining: 21.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.0813949\ttest: 0.1853253\tbest: 0.1851815 (1275)\ttotal: 15.3s\tremaining: 19.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.0758732\ttest: 0.1852311\tbest: 0.1851013 (1389)\ttotal: 16.4s\tremaining: 18.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:14] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:14] bestTest = 0.1851013262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1851013262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:14] bestIteration = 1389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:14] Shrink model to first 1390 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1390 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:14] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:14] 0:\tlearn: 1.0609774\ttest: 1.0619728\tbest: 1.0619728 (0)\ttotal: 12.3ms\tremaining: 36.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0609774\ttest: 1.0619728\tbest: 1.0619728 (0)\ttotal: 12.3ms\tremaining: 36.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2629740\ttest: 0.2800701\tbest: 0.2800701 (100)\ttotal: 1.24s\tremaining: 35.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2055640\ttest: 0.2326025\tbest: 0.2326025 (200)\ttotal: 2.44s\tremaining: 34s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1829962\ttest: 0.2213721\tbest: 0.2213721 (300)\ttotal: 3.64s\tremaining: 32.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1636936\ttest: 0.2130183\tbest: 0.2130183 (400)\ttotal: 4.81s\tremaining: 31.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1481538\ttest: 0.2089178\tbest: 0.2089178 (500)\ttotal: 5.98s\tremaining: 29.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1356963\ttest: 0.2057987\tbest: 0.2057787 (596)\ttotal: 7.14s\tremaining: 28.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1251158\ttest: 0.2043712\tbest: 0.2042815 (696)\ttotal: 8.28s\tremaining: 27.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1156427\ttest: 0.2030518\tbest: 0.2030296 (793)\ttotal: 9.47s\tremaining: 26s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1072102\ttest: 0.2018847\tbest: 0.2017879 (894)\ttotal: 10.6s\tremaining: 24.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.0994282\ttest: 0.2012485\tbest: 0.2012485 (1000)\ttotal: 11.7s\tremaining: 23.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.0924403\ttest: 0.2005635\tbest: 0.2005342 (1097)\ttotal: 12.9s\tremaining: 22.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.0857328\ttest: 0.2003317\tbest: 0.2002045 (1186)\ttotal: 14s\tremaining: 21s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.0794579\ttest: 0.1996419\tbest: 0.1996419 (1300)\ttotal: 15.2s\tremaining: 19.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.0739766\ttest: 0.1997878\tbest: 0.1996419 (1300)\ttotal: 16.4s\tremaining: 18.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:31] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:31] bestTest = 0.1996418679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1996418679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:31] bestIteration = 1300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:31] Shrink model to first 1301 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1301 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:31] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:31] 0:\tlearn: 1.0631822\ttest: 1.0634556\tbest: 1.0634556 (0)\ttotal: 11.1ms\tremaining: 33.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0631822\ttest: 1.0634556\tbest: 1.0634556 (0)\ttotal: 11.1ms\tremaining: 33.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2639646\ttest: 0.2761027\tbest: 0.2761027 (100)\ttotal: 1.22s\tremaining: 35.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2086735\ttest: 0.2314248\tbest: 0.2314248 (200)\ttotal: 2.44s\tremaining: 33.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1863603\ttest: 0.2187230\tbest: 0.2187230 (300)\ttotal: 3.65s\tremaining: 32.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1644074\ttest: 0.2081956\tbest: 0.2081956 (400)\ttotal: 4.83s\tremaining: 31.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1490822\ttest: 0.2031083\tbest: 0.2031083 (500)\ttotal: 6.01s\tremaining: 30s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1363061\ttest: 0.2005076\tbest: 0.2005076 (600)\ttotal: 7.19s\tremaining: 28.7s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1254144\ttest: 0.1990899\tbest: 0.1990621 (698)\ttotal: 8.32s\tremaining: 27.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1157100\ttest: 0.1971311\tbest: 0.1971311 (800)\ttotal: 9.47s\tremaining: 26s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1072226\ttest: 0.1949370\tbest: 0.1949030 (895)\ttotal: 10.6s\tremaining: 24.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.0993055\ttest: 0.1941009\tbest: 0.1941009 (1000)\ttotal: 11.8s\tremaining: 23.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.0923348\ttest: 0.1932640\tbest: 0.1932529 (1097)\ttotal: 12.9s\tremaining: 22.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.0859900\ttest: 0.1929531\tbest: 0.1928899 (1161)\ttotal: 14.1s\tremaining: 21.2s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.0800107\ttest: 0.1926468\tbest: 0.1923989 (1285)\ttotal: 15.3s\tremaining: 20s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.0744056\ttest: 0.1921475\tbest: 0.1920912 (1391)\ttotal: 16.5s\tremaining: 18.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1500:\tlearn: 0.0693857\ttest: 0.1922610\tbest: 0.1920497 (1406)\ttotal: 17.7s\tremaining: 17.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:49] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:49] bestTest = 0.1920497232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1920497232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:49] bestIteration = 1406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:49] Shrink model to first 1407 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1407 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:49] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:49] 0:\tlearn: 1.0625641\ttest: 1.0623348\tbest: 1.0623348 (0)\ttotal: 12.1ms\tremaining: 36.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 1.0625641\ttest: 1.0623348\tbest: 1.0623348 (0)\ttotal: 12.1ms\tremaining: 36.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2662121\ttest: 0.2657666\tbest: 0.2657666 (100)\ttotal: 1.25s\tremaining: 35.8s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2106617\ttest: 0.2173841\tbest: 0.2173841 (200)\ttotal: 2.45s\tremaining: 34.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1895272\ttest: 0.2055029\tbest: 0.2055029 (300)\ttotal: 3.61s\tremaining: 32.4s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1696828\ttest: 0.1959680\tbest: 0.1959071 (399)\ttotal: 4.77s\tremaining: 30.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1533593\ttest: 0.1907460\tbest: 0.1907460 (500)\ttotal: 5.94s\tremaining: 29.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1411700\ttest: 0.1869593\tbest: 0.1869593 (600)\ttotal: 7.09s\tremaining: 28.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.1308611\ttest: 0.1838710\tbest: 0.1838710 (700)\ttotal: 8.27s\tremaining: 27.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:800:\tlearn: 0.1213086\ttest: 0.1823688\tbest: 0.1823688 (800)\ttotal: 9.43s\tremaining: 25.9s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:900:\tlearn: 0.1125498\ttest: 0.1806159\tbest: 0.1806159 (900)\ttotal: 10.6s\tremaining: 24.6s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1000:\tlearn: 0.1049642\ttest: 0.1795042\tbest: 0.1794834 (998)\ttotal: 11.8s\tremaining: 23.5s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1100:\tlearn: 0.0975400\ttest: 0.1791459\tbest: 0.1791085 (1099)\ttotal: 12.9s\tremaining: 22.3s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1200:\tlearn: 0.0910074\ttest: 0.1779109\tbest: 0.1778962 (1198)\ttotal: 14.1s\tremaining: 21.1s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1300:\tlearn: 0.0846756\ttest: 0.1773474\tbest: 0.1773029 (1296)\ttotal: 15.3s\tremaining: 20s\n",
            "DEBUG:lightautoml.ml_algo.boost_cb:1400:\tlearn: 0.0786766\ttest: 0.1769169\tbest: 0.1768142 (1395)\ttotal: 16.5s\tremaining: 18.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:07] Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:07] bestTest = 0.1768142009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.1768142009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:07] bestIteration = 1395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:07] Shrink model to first 1396 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1396 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:07] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.18780501587656914\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.18780501587656914\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:07] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:07] Time left 27838.89 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 27838.89 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:07] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:07] Layer \u001b[1m2\u001b[0m train process start. Time left 27838.84 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m2\u001b[0m train process start. Time left 27838.84 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:08] Start fitting \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [79, 80, 81, 82, 83, 84, 85, 86, 87], 'embed_sizes': array([ 9,  4, 20, 11,  9, 34, 44, 13,  8], dtype=int32), 'data_size': 88}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:08] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:08] Linear model: C = 1e-05 score = -0.5871444961722986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.5871444961722986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:09] Linear model: C = 5e-05 score = -0.3387896797661017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.3387896797661017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:09] Linear model: C = 0.0001 score = -0.2761803146035085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.2761803146035085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:09] Linear model: C = 0.0005 score = -0.20461960368423324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.20461960368423324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:10] Linear model: C = 0.001 score = -0.19257215590716037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.19257215590716037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:11] Linear model: C = 0.005 score = -0.184438186674624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.184438186674624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:11] Linear model: C = 0.01 score = -0.18499704431340824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.18499704431340824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:12] Linear model: C = 0.05 score = -0.1874016144720319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.1874016144720319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:12] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:13] Linear model: C = 1e-05 score = -0.5908838435791071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.5908838435791071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:13] Linear model: C = 5e-05 score = -0.34288720868747025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.34288720868747025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:13] Linear model: C = 0.0001 score = -0.2791710629874601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.2791710629874601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:14] Linear model: C = 0.0005 score = -0.20495539605813662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.20495539605813662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:15] Linear model: C = 0.001 score = -0.1918965376193962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.1918965376193962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:15] Linear model: C = 0.005 score = -0.18027676127489126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.18027676127489126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:16] Linear model: C = 0.01 score = -0.1791666520616643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.1791666520616643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:17] Linear model: C = 0.05 score = -0.17796006813177773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.17796006813177773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:18] Linear model: C = 0.1 score = -0.17676946750126307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.17676946750126307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:19] Linear model: C = 0.5 score = -0.17103090122916648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.17103090122916648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:19] Linear model: C = 1 score = -0.17103090122916648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.17103090122916648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:19] Linear model: C = 5 score = -0.17103090122916648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = -0.17103090122916648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:19] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:20] Linear model: C = 1e-05 score = -0.6011968749043036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.6011968749043036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:20] Linear model: C = 5e-05 score = -0.361313601788715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.361313601788715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:21] Linear model: C = 0.0001 score = -0.29898264716306977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.29898264716306977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:21] Linear model: C = 0.0005 score = -0.22507962135024187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.22507962135024187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:22] Linear model: C = 0.001 score = -0.21110845793208707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.21110845793208707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:23] Linear model: C = 0.005 score = -0.19834719547845212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.19834719547845212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:23] Linear model: C = 0.01 score = -0.19658075004197192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.19658075004197192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:24] Linear model: C = 0.05 score = -0.19336099604871404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.19336099604871404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:25] Linear model: C = 0.1 score = -0.1912073829694925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.1912073829694925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:26] Linear model: C = 0.5 score = -0.18354551288755772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.18354551288755772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:26] Linear model: C = 1 score = -0.18354551288755772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.18354551288755772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:26] Linear model: C = 5 score = -0.18354551288755772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = -0.18354551288755772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:26] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:27] Linear model: C = 1e-05 score = -0.595317295149288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.595317295149288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:27] Linear model: C = 5e-05 score = -0.3501760110974886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.3501760110974886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:28] Linear model: C = 0.0001 score = -0.2871094986632645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.2871094986632645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:28] Linear model: C = 0.0005 score = -0.2139135243617576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.2139135243617576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:29] Linear model: C = 0.001 score = -0.20118794682246416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.20118794682246416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:29] Linear model: C = 0.005 score = -0.19105649825179385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.19105649825179385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:30] Linear model: C = 0.01 score = -0.1904527815959323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.1904527815959323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:31] Linear model: C = 0.05 score = -0.19010252424813068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.19010252424813068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:32] Linear model: C = 0.1 score = -0.18986283067827983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.18986283067827983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:33] Linear model: C = 0.5 score = -0.19009070524617735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.19009070524617735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:33] Linear model: C = 1 score = -0.19009070524617735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.19009070524617735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:33] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:33] Linear model: C = 1e-05 score = -0.5903020338864055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.5903020338864055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:34] Linear model: C = 5e-05 score = -0.34200639474515887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.34200639474515887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:34] Linear model: C = 0.0001 score = -0.2778729702089939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.2778729702089939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:35] Linear model: C = 0.0005 score = -0.20253016213991987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.20253016213991987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:35] Linear model: C = 0.001 score = -0.1889200511709141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.1889200511709141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:36] Linear model: C = 0.005 score = -0.17694194350306672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.17694194350306672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:37] Linear model: C = 0.01 score = -0.17596486644911766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.17596486644911766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:38] Linear model: C = 0.05 score = -0.1756932331329693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = -0.1756932331329693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:39] Linear model: C = 0.1 score = -0.1750089648241162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = -0.1750089648241162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:40] Linear model: C = 0.5 score = -0.17038338618680754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = -0.17038338618680754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:40] Linear model: C = 1 score = -0.17038338618680754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = -0.17038338618680754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:40] Linear model: C = 5 score = -0.17038338618680754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = -0.17038338618680754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:40] Fitting \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.17985212417264368\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.17985212417264368\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:40] \u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_1_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:40] Time left 27805.40 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 27805.40 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:41] Start fitting \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.02, 'num_leaves': 64, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.2, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:41] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:42] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.30338\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.207843\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.191629\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.187924\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.187356\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.189153\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[488]\tvalid's multi_logloss: 0.187164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:57] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:57] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.297187\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.200536\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.181889\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.177735\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.17835\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.180565\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[440]\tvalid's multi_logloss: 0.177107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:11] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:11] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.30535\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.208093\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.189522\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.186393\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.186572\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.187832\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[441]\tvalid's multi_logloss: 0.185876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:28] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:28] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.301236\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.206015\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.188776\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.185464\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.186098\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.188199\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[419]\tvalid's multi_logloss: 0.185233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:42] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:42] Training until validation scores don't improve for 200 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's multi_logloss: 0.297517\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's multi_logloss: 0.201975\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's multi_logloss: 0.183593\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's multi_logloss: 0.178615\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's multi_logloss: 0.177375\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's multi_logloss: 0.178233\n",
            "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[487]\tvalid's multi_logloss: 0.177175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:57] Fitting \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.18251124682227582\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.18251124682227582\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:57] \u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_1_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:57] Time left 27728.15 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 27728.15 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:57] \u001b[1mLayer 2 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 2 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:57] Blending: optimization starts with equal weights and score \u001b[1m-0.1779014503375406\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.1779014503375406\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:57] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.17779151154370001\u001b[0m, weights = \u001b[1m[0.6005623  0.39943776]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.17779151154370001\u001b[0m, weights = \u001b[1m[0.6005623  0.39943776]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:58] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.17779151154370001\u001b[0m, weights = \u001b[1m[0.6005623  0.39943776]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.17779151154370001\u001b[0m, weights = \u001b[1m[0.6005623  0.39943776]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:58] Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:58] \u001b[1mAutoml preset training completed in 1072.04 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 1072.04 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:58] Model description:\n",
            "Models on level 0:\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost\n",
            "\n",
            "Final prediction for new objects (level 1) = \n",
            "\t 0.60056 * (5 averaged models Lvl_1_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.39944 * (5 averaged models Lvl_1_Pipe_1_Mod_0_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Models on level 0:\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost\n",
            "\t 5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost\n",
            "\n",
            "Final prediction for new objects (level 1) = \n",
            "\t 0.60056 * (5 averaged models Lvl_1_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.39944 * (5 averaged models Lvl_1_Pipe_1_Mod_0_LightGBM) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = automl.predict(df_test)"
      ],
      "metadata": {
        "id": "qEbUEXgEtqsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUhSXTh0Ye21",
        "outputId": "d365467a-d79b-4dd7-820a-0a7f5ba2af07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9509639 , 0.03376318, 0.01527287],\n",
              "       [0.974772  , 0.02224623, 0.00298176],\n",
              "       [0.16340417, 0.6961456 , 0.14045021],\n",
              "       ...,\n",
              "       [0.96781385, 0.02933476, 0.00285132],\n",
              "       [0.9301461 , 0.06469881, 0.00515505],\n",
              "       [0.20181322, 0.7956005 , 0.00258632]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "automl.reader.class_mapping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw6NPkwPlPL3",
        "outputId": "66e0b8d6-f3cb-499d-827c-0442a70ac1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 0, 3: 1, -1: 2}"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n7GhB5NTJgl"
      },
      "source": [
        "#  Saving submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj73xWP0TJgl"
      },
      "outputs": [],
      "source": [
        "subm_file = \"/content/drive/MyDrive/Алтай/sample_submission.csv\"\n",
        "submission = pd.read_csv(subm_file)\n",
        "submission['Статус'] = np.argmax(test_pred.data, axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission['Статус'] = submission['Статус'].map({0: 4, 1: 3, 2: -1})"
      ],
      "metadata": {
        "id": "RNdUW5Xdm_Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "w88W47iimfOn",
        "outputId": "76ee07af-4b3f-442b-d97a-09d04b783903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         ID  Статус\n",
              "0     64996       4\n",
              "1     71837       4\n",
              "2     86587       3\n",
              "3     73673      -1\n",
              "4     54709       4\n",
              "...     ...     ...\n",
              "6686  74342       4\n",
              "6687  54876       4\n",
              "6688  66879       4\n",
              "6689  64982       4\n",
              "6690  69975       3\n",
              "\n",
              "[6691 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6622e21b-229a-4409-a59e-7f6e1f1286a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Статус</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>64996</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>71837</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>86587</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73673</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54709</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6686</th>\n",
              "      <td>74342</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6687</th>\n",
              "      <td>54876</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6688</th>\n",
              "      <td>66879</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6689</th>\n",
              "      <td>64982</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6690</th>\n",
              "      <td>69975</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6691 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6622e21b-229a-4409-a59e-7f6e1f1286a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6622e21b-229a-4409-a59e-7f6e1f1286a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6622e21b-229a-4409-a59e-7f6e1f1286a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZFA9ig3TJgl"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "time_str = datetime.now().strftime('%d-%m-%Y_%H-%M-%S')\n",
        "\n",
        "# Saving the submission\n",
        "filename = \"ALT_subm_{}\".format(time_str)\n",
        "if not os.path.exists(\"Submissions\"):\n",
        "    os.mkdir(\"Submissions\")\n",
        "submission.to_csv(\"Submissions/{}.csv\".format(filename), sep=',', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "id": "1fQAvjLaXFNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0tsv1WNY_zjJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}